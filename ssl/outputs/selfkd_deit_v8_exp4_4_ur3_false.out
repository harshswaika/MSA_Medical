[2024-03-06 12:37:01,195 INFO] Use GPU: None for training
[2024-03-06 12:37:01,195 INFO] 

[2024-03-06 12:37:02,109 INFO] Total params: 109.04M
[2024-03-06 12:37:08,732 INFO] acc: 0.90
[2024-03-06 12:37:08,744 INFO] Victim model accuracy = 0.9016, spec = 0.90, sens = 0.93
[2024-03-06 12:37:08,744 INFO] Loading thief dataset ...
[2024-03-06 12:37:08,750 INFO] 
Initializing thief model ...


Loaded supervised labeled set of length  900
Labeled set expanded to length  3600 , unique indices  900
dataset root /home/deepankar/mnt/vision3_data_ckpts_msa_medical/GBUSV-Shared
Num of videos 64 frames 15800
15800
15800
Num of videos 64 frames 15800
  0%|          | 0/29 [00:00<?, ?it/s]  3%|â–Ž         | 1/29 [00:06<02:52,  6.16s/it]  7%|â–‹         | 2/29 [00:08<01:39,  3.69s/it] 10%|â–ˆ         | 3/29 [00:10<01:15,  2.89s/it] 14%|â–ˆâ–        | 4/29 [00:11<01:02,  2.50s/it] 17%|â–ˆâ–‹        | 5/29 [00:13<00:54,  2.28s/it] 21%|â–ˆâ–ˆ        | 6/29 [00:15<00:49,  2.15s/it] 24%|â–ˆâ–ˆâ–       | 7/29 [00:17<00:45,  2.07s/it] 28%|â–ˆâ–ˆâ–Š       | 8/29 [00:19<00:42,  2.02s/it] 31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:21<00:39,  1.99s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 10/29 [00:23<00:37,  1.97s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:25<00:35,  1.95s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/29 [00:27<00:33,  1.95s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/29 [00:29<00:31,  1.94s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:31<00:29,  1.95s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:33<00:27,  1.94s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:35<00:25,  1.94s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 17/29 [00:36<00:23,  1.94s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/29 [00:38<00:21,  1.94s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 19/29 [00:40<00:19,  1.93s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 20/29 [00:42<00:17,  1.92s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 21/29 [00:44<00:15,  1.93s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 22/29 [00:46<00:13,  1.92s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 23/29 [00:48<00:11,  1.92s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 24/29 [00:50<00:09,  1.92s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 25/29 [00:52<00:07,  1.91s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 26/29 [00:54<00:05,  1.91s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:56<00:03,  1.91s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 28/29 [00:58<00:01,  1.91s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:59<00:00,  1.79s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:59<00:00,  2.06s/it]
Num of videos 64 frames 15800
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.73s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.80s/it]
[2024-03-06 12:38:13,213 INFO] unlabeled data number: 15800, labeled data number 3600
[2024-03-06 12:38:13,213 INFO] Create train and test data loaders
[2024-03-06 12:38:13,213 INFO] [!] data loader keys: dict_keys(['train_lb', 'train_ulb', 'eval', 'test'])
[2024-03-06 12:38:16,213 INFO] Create optimizer and scheduler
[2024-03-06 12:38:16,219 INFO] Number of Trainable Params: 85800963
Num of videos 64 frames 15800
Load pretrained model for initializing the thief from  /home/deepankar/scratch/MSA_Medical/activethief/pretrained/deit_base_patch16_224-b5f2ef4d.pth
key not found head.weight
key not found head.bias
Common keys pretrained model:  150
Load anchor model /home/deepankar/mnt/vision1_outputs/gbusg_radformer/GBUSV_deit/SGD/1000_val100/random_v1_transforms/trial_4_cycle_1_best.pth
thief state:  ['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight']
pretrained state:  ['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight']
Common keys anchor model:  152
[2024-03-06 12:38:25,341 INFO] Anchor model on target dataset: acc = 0.6803, spec = 0.72, sens = 0.83
[2024-03-06 12:38:25,772 INFO] Arguments: Namespace(T=0.5, algorithm='selfkd', amp=False, batch_size=16, c='configs/gbc/selfkd_deit.yaml', clip=0.0, clip_grad=0, crop_ratio=0.875, data_dir='./data', dataset='GBUSV', device=device(type='cuda'), dist_backend='nccl', dist_url='tcp://127.0.0.1:25870', distributed=False, ds_seed=123, ema_m=0.999, epoch=100, eval_batch_size=16, eval_step=234, expand_labels=True, gpu=None, hard_label=True, imb_algorithm=None, img_size=224, include_lb_to_ulb=True, kd_alpha=0.4, kd_alpha_ulb=0.5, kd_temp=1.5, kd_temp_ulb=1.5, la=False, labeled_set_path='/home/deepankar/mnt/vision1_outputs/gbusg_radformer/GBUSV_deit/SGD/1000_val100/random_v1_transforms/X_trial_4_cycle_1_labeled_set.npy', layer_decay=0.5, lb_dest_len=3600, lb_imb_ratio=1, load_labeled_set=True, load_path=None, local_rank=-1, lr=0.01, max_length=512, max_length_seconds=4.0, momentum=0.9, multiprocessing_distributed=False, net='deit_base_patch16_224', net_from_name=False, no_progress=True, num_classes=3, num_eval_iter=234, num_labels=1000, num_log_iter=234, num_train_iter=900000, num_warmup_iter=5120, num_workers=4, optim='SGD', overwrite=True, p_cutoff=0.95, pretrain_path='', pretrained_dir='/home/deepankar/scratch/MSA_Medical/activethief/pretrained/deit_base_patch16_224-b5f2ef4d.pth', rank=0, resume=False, sample_rate=16000, save_dir='/home/deepankar/mnt/vision03_ssl/radformer', save_name='selfkd_deit_v8_exp4_4_ur3_false', scheduler_type='cosine', seed=5, subset=128116, thief_root='/home/deepankar/mnt/vision3_data_ckpts_msa_medical/GBUSV-Shared', train_sampler='RandomSampler', tro=1, ulb_dest_len=15800, ulb_imb_ratio=1, ulb_loss_ratio=1.0, ulb_num_labels=None, uratio=3, use_aim=False, use_cat=True, use_pretrain=True, use_tensorboard=True, use_wandb=True, val_set_path='/home/deepankar/mnt/vision1_outputs/gbusg_radformer/GBUSV_deit/SGD/1000_val100/random_v1_transforms/X_trial_4_cycle_1_val_set.npy', victim_arch='radformer', victim_data_root='/home/deepankar/mnt/vision3_data_ckpts_msa_medical/GBCU-Shared', victim_dataset='gbusg', victim_model_path='/home/deepankar/mnt/vision3_data_ckpts_msa_medical/victim_models/radformer/radformer.pkl', warmstart=False, warmstart_dir='/home/deepankar/mnt/vision1_outputs/gbusg_radformer/GBUSV_deit/SGD/1000_val100/random_v1_transforms/trial_4_cycle_1_best.pth', warmup=0, warmup_epoch=10, weight_decay=0.0005, world_size=1)
[2024-03-06 12:38:25,772 INFO] Validation set distribution: 
anchor model temp =  1.0
Number of samples  100
[2024-03-06 12:38:26,576 INFO] {0: 19, 1: 24, 2: 57}
[2024-03-06 12:38:26,576 INFO] Labeled set distribution: 
Number of samples  3600
[2024-03-06 12:38:32,673 INFO] {0: 456, 1: 840, 2: 2304}
[2024-03-06 12:38:36,830 INFO] Initial model on target dataset (without EMA): acc = 0.3934, agreement = 0.3689, spec = 0.74, sens = 0.31
[2024-03-06 12:38:36,830 INFO] Resume load path None does not exist
[2024-03-06 12:38:36,830 INFO] 
Model training
wandb: Currently logged in as: satwikdpshrit. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.16.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.3
wandb: Run data is saved locally in /home/deepankar/mnt/vision03_ssl/radformer/wandb/selfkd_deit_v8_exp4_4_ur3_false/wandb/run-20240306_123839-f68okdc2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run selfkd_deit_v8_exp4_4_ur3_false
wandb: â­ï¸ View project at https://wandb.ai/satwikdpshrit/radformer
wandb: ðŸš€ View run at https://wandb.ai/satwikdpshrit/radformer/runs/f68okdc2
[2024-03-06 12:38:42,420 INFO] 

epoch 0
[2024-03-06 12:44:22,906 INFO] validating...
[2024-03-06 12:44:35,495 INFO] model saved: /home/deepankar/mnt/vision03_ssl/radformer/selfkd_deit_v8_exp4_4_ur3_false/latest_model.pth
[2024-03-06 12:44:44,462 INFO] model saved: /home/deepankar/mnt/vision03_ssl/radformer/selfkd_deit_v8_exp4_4_ur3_false/model_best.pth
[2024-03-06 12:44:44,464 INFO] 226 iteration, USE_EMA: True, train/sup_loss: 1.51335, train/unsup_loss: 0.87806, train/total_loss: 2.39141, train/util_ratio: 0.79167, train/run_time: 1.47398, lr: 0.00000, train/prefecth_time: 0.01170, eval/loss: 1.12722, eval/top-1-acc: 0.31000, eval/balanced_acc: 0.36184, eval/precision: 0.42273, eval/recall: 0.36184, eval/F1: 0.24564, eval/spec: 0.95349, eval/sens: 0.15789, test/loss: 1.04015, test/top-1-acc: 0.39344, test/balanced_acc: 0.34522, test/precision: 0.42590, test/recall: 0.34522, test/F1: 0.30214, test/spec: 0.73750, test/sens: 0.30952 BEST_EVAL_ACC: 0.3100, at 226 iters BEST_TEST_ACC: 0.3934, at 226 iters
[2024-03-06 12:44:44,477 INFO] 

epoch 1
