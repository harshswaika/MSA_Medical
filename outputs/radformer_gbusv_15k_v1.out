nohup: ignoring input
[24/02/19 13:15:52] [conf.py:  298]: PyTorch Version: torch=1.11.0, cuda=11.3, cudnn=8200
[24/02/19 13:15:52] [conf.py:  300]: ACTIVE:
  ADDENDUM: 0
  ALPHA: 0.2
  AUGMENT: None
  BETA: 1.0
  BUDGET: 15800
  CUTMIX_PROB: 0.0
  CYCLES: 1
  INITIAL: 14220
  LA: False
  METHOD: random
  PRETRAINED_PATH: /home/ankita/scratch/MSA_results/ckpts/resnet50-imagenet1k.pth
  TEMP: 1.0
  TRO: 1.0
  USE_PRETRAINED: True
  VAL: 1580
AM:
  SGR: 1000
  THRESHOLD: 0.5
CUDNN_BENCHMARK: True
DS_SEED: 123
EDM:
  HASH: /home/harsh_s/scratch/msacopy/exp/hash/alpha.pt
  NUM_MODELS: 5
  PATH1: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T0.pt
  PATH2: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T1.pt
  PATH3: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T2.pt
  PATH4: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T3.pt
  PATH5: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T4.pt
GR:
  EPSILON: 0.1
  SUR_PATH: /home/harsh_s/scratch/msacopy/GRAD2/batch_training/outputs/trained_models/imagenet_cifar10_to_cifar10_surrogate_10epochs.pt
LOG_DEST: radformer_gbusv_240219_131552.txt
LOG_TIME: 240219_131552
METHOD_NAME: v1
OUT_DIR: results
PL:
  CLASS_BLNC: 10
  ITERATIONS: 20
  KAPPA_N: 0.005
  KAPPA_P: 0.05
  NO_PROGRESS: False
  NO_UNCERTAINTY: False
  TAU_N: 0.05
  TAU_P: 0.7
  TEMP_NL: 2.0
RNG_SEED: 1
SAVE_DIR: results/gbusg_radformer/GBUSV_resnet50/SGD/15800_val1580/random_v1
THIEF:
  ARCH: resnet50
  DATASET: GBUSV
  DATA_ROOT: /home/ankita/scratch/Datasets/GBUSV-Shared
  HARD_LABELS: True
  NUM_TRAIN: 1281167
  SUBSET: 128116
TRAIN:
  BATCH: 128
  EPOCH: 50
  GAMMA: 0.1
  LR: 0.02
  MILESTONES: [60, 120, 180]
  MOMENTUM: 0.9
  OPTIMIZER: SGD
  WDECAY: 0.0005
VICTIM:
  ARCH: radformer
  DATASET: gbusg
  DATA_ROOT: /home/ankita/scratch/Datasets/GBCU-Shared
  HEIGHT: 224
  NUM_CLASSES: 10
  PATH: victim_models/radformer/radformer.pkl
  PATHIN: /home/harsh_s/scratch/msacopy/ckpts/cifar10-resnet32-inaccurate/checkpoint.pth.tar
  WIDTH: 224
Loaded target dataset of size 122 with 3 classes
target model keys:  695
checkpoint keys:  695
specificity = 72/80
sensitivity = 39/42

Target model acc = 0.9016393442622951
Val-Acc: 0.9016 Val-Spec: 0.9000 Val-Sens: 0.9286
/home/ankita/scratch/Datasets/GBUSV-Shared/all_names.pkl
Num of videos 64 frames 15800
/home/ankita/scratch/Datasets/GBUSV-Shared/all_names.pkl
Num of videos 64 frames 15800
replacing labeled set labels with victim labels
  0%|          | 0/112 [00:00<?, ?it/s]  1%|          | 1/112 [00:02<04:19,  2.34s/it]  2%|▏         | 2/112 [00:03<03:14,  1.77s/it]  3%|▎         | 3/112 [00:05<02:57,  1.62s/it]  4%|▎         | 4/112 [00:06<02:50,  1.58s/it]  4%|▍         | 5/112 [00:08<02:43,  1.53s/it]  5%|▌         | 6/112 [00:09<02:37,  1.48s/it]  6%|▋         | 7/112 [00:10<02:31,  1.44s/it]  7%|▋         | 8/112 [00:12<02:31,  1.45s/it]  8%|▊         | 9/112 [00:13<02:32,  1.48s/it]  9%|▉         | 10/112 [00:15<02:29,  1.47s/it] 10%|▉         | 11/112 [00:16<02:27,  1.46s/it] 11%|█         | 12/112 [00:18<02:26,  1.47s/it] 12%|█▏        | 13/112 [00:19<02:25,  1.47s/it] 12%|█▎        | 14/112 [00:23<03:19,  2.04s/it] 13%|█▎        | 15/112 [00:24<03:11,  1.97s/it] 14%|█▍        | 16/112 [00:26<02:53,  1.81s/it] 15%|█▌        | 17/112 [00:27<02:39,  1.68s/it] 16%|█▌        | 18/112 [00:29<02:30,  1.60s/it] 17%|█▋        | 19/112 [00:30<02:23,  1.54s/it] 18%|█▊        | 20/112 [00:31<02:18,  1.51s/it] 19%|█▉        | 21/112 [00:33<02:14,  1.48s/it] 20%|█▉        | 22/112 [00:34<02:10,  1.45s/it] 21%|██        | 23/112 [00:36<02:07,  1.44s/it] 21%|██▏       | 24/112 [00:37<02:04,  1.42s/it] 22%|██▏       | 25/112 [00:38<02:02,  1.41s/it] 23%|██▎       | 26/112 [00:40<02:01,  1.41s/it] 24%|██▍       | 27/112 [00:41<01:58,  1.40s/it] 25%|██▌       | 28/112 [00:43<01:57,  1.40s/it] 26%|██▌       | 29/112 [00:44<01:55,  1.40s/it] 27%|██▋       | 30/112 [00:45<01:54,  1.40s/it] 28%|██▊       | 31/112 [00:47<01:55,  1.43s/it] 29%|██▊       | 32/112 [00:48<01:54,  1.43s/it] 29%|██▉       | 33/112 [00:50<01:52,  1.43s/it] 30%|███       | 34/112 [00:51<01:49,  1.41s/it] 31%|███▏      | 35/112 [00:52<01:47,  1.39s/it] 32%|███▏      | 36/112 [00:54<01:46,  1.40s/it] 33%|███▎      | 37/112 [00:55<01:44,  1.39s/it] 34%|███▍      | 38/112 [00:57<01:42,  1.38s/it] 35%|███▍      | 39/112 [00:58<01:41,  1.39s/it] 36%|███▌      | 40/112 [00:59<01:39,  1.38s/it] 37%|███▋      | 41/112 [01:01<01:38,  1.39s/it] 38%|███▊      | 42/112 [01:02<01:36,  1.38s/it] 38%|███▊      | 43/112 [01:04<01:35,  1.39s/it] 39%|███▉      | 44/112 [01:05<01:34,  1.39s/it] 40%|████      | 45/112 [01:06<01:33,  1.40s/it] 41%|████      | 46/112 [01:08<01:31,  1.39s/it] 42%|████▏     | 47/112 [01:09<01:29,  1.37s/it] 43%|████▎     | 48/112 [01:10<01:26,  1.36s/it] 44%|████▍     | 49/112 [01:12<01:25,  1.36s/it] 45%|████▍     | 50/112 [01:13<01:25,  1.38s/it] 46%|████▌     | 51/112 [01:15<01:24,  1.38s/it] 46%|████▋     | 52/112 [01:16<01:25,  1.42s/it] 47%|████▋     | 53/112 [01:18<01:24,  1.43s/it] 48%|████▊     | 54/112 [01:19<01:24,  1.46s/it] 49%|████▉     | 55/112 [01:20<01:21,  1.43s/it] 50%|█████     | 56/112 [01:22<01:19,  1.41s/it] 51%|█████     | 57/112 [01:23<01:17,  1.41s/it] 52%|█████▏    | 58/112 [01:25<01:16,  1.41s/it] 53%|█████▎    | 59/112 [01:26<01:15,  1.42s/it] 54%|█████▎    | 60/112 [01:27<01:13,  1.42s/it] 54%|█████▍    | 61/112 [01:29<01:11,  1.40s/it] 55%|█████▌    | 62/112 [01:30<01:09,  1.38s/it] 56%|█████▋    | 63/112 [01:32<01:08,  1.39s/it] 57%|█████▋    | 64/112 [01:33<01:08,  1.42s/it] 58%|█████▊    | 65/112 [01:34<01:06,  1.42s/it] 59%|█████▉    | 66/112 [01:36<01:05,  1.43s/it] 60%|█████▉    | 67/112 [01:37<01:03,  1.40s/it] 61%|██████    | 68/112 [01:39<01:01,  1.40s/it] 62%|██████▏   | 69/112 [01:40<00:59,  1.38s/it] 62%|██████▎   | 70/112 [01:41<00:57,  1.37s/it] 63%|██████▎   | 71/112 [01:43<00:56,  1.39s/it] 64%|██████▍   | 72/112 [01:44<00:56,  1.41s/it] 65%|██████▌   | 73/112 [01:46<00:55,  1.41s/it] 66%|██████▌   | 74/112 [01:47<00:53,  1.40s/it] 67%|██████▋   | 75/112 [01:48<00:50,  1.38s/it] 68%|██████▊   | 76/112 [01:50<00:50,  1.39s/it] 69%|██████▉   | 77/112 [01:51<00:49,  1.42s/it] 70%|██████▉   | 78/112 [01:53<00:47,  1.41s/it] 71%|███████   | 79/112 [01:54<00:46,  1.42s/it] 71%|███████▏  | 80/112 [01:56<00:45,  1.43s/it] 72%|███████▏  | 81/112 [01:57<00:43,  1.41s/it] 73%|███████▎  | 82/112 [01:58<00:41,  1.39s/it] 74%|███████▍  | 83/112 [02:00<00:40,  1.40s/it] 75%|███████▌  | 84/112 [02:01<00:39,  1.42s/it] 76%|███████▌  | 85/112 [02:03<00:38,  1.41s/it] 77%|███████▋  | 86/112 [02:04<00:36,  1.41s/it] 78%|███████▊  | 87/112 [02:05<00:35,  1.41s/it] 79%|███████▊  | 88/112 [02:07<00:33,  1.41s/it] 79%|███████▉  | 89/112 [02:08<00:34,  1.49s/it] 80%|████████  | 90/112 [02:10<00:32,  1.47s/it] 81%|████████▏ | 91/112 [02:11<00:30,  1.47s/it] 82%|████████▏ | 92/112 [02:13<00:28,  1.44s/it] 83%|████████▎ | 93/112 [02:14<00:27,  1.43s/it] 84%|████████▍ | 94/112 [02:15<00:25,  1.42s/it] 85%|████████▍ | 95/112 [02:17<00:24,  1.45s/it] 86%|████████▌ | 96/112 [02:18<00:23,  1.44s/it] 87%|████████▋ | 97/112 [02:20<00:21,  1.42s/it] 88%|████████▊ | 98/112 [02:21<00:19,  1.43s/it] 88%|████████▊ | 99/112 [02:23<00:18,  1.43s/it] 89%|████████▉ | 100/112 [02:24<00:17,  1.42s/it] 90%|█████████ | 101/112 [02:26<00:15,  1.43s/it] 91%|█████████ | 102/112 [02:27<00:14,  1.43s/it] 92%|█████████▏| 103/112 [02:28<00:12,  1.44s/it] 93%|█████████▎| 104/112 [02:30<00:11,  1.44s/it] 94%|█████████▍| 105/112 [02:31<00:09,  1.42s/it] 95%|█████████▍| 106/112 [02:33<00:08,  1.42s/it] 96%|█████████▌| 107/112 [02:34<00:07,  1.41s/it] 96%|█████████▋| 108/112 [02:35<00:05,  1.38s/it] 97%|█████████▋| 109/112 [02:37<00:04,  1.38s/it] 98%|█████████▊| 110/112 [02:38<00:02,  1.40s/it] 99%|█████████▉| 111/112 [02:40<00:01,  1.39s/it]100%|██████████| 112/112 [02:40<00:00,  1.02s/it]100%|██████████| 112/112 [02:40<00:00,  1.43s/it]
replacing val labels with victim labels
  0%|          | 0/13 [00:00<?, ?it/s]  8%|▊         | 1/13 [00:02<00:28,  2.37s/it] 15%|█▌        | 2/13 [00:03<00:19,  1.76s/it] 23%|██▎       | 3/13 [00:05<00:16,  1.60s/it] 31%|███       | 4/13 [00:06<00:13,  1.53s/it] 38%|███▊      | 5/13 [00:07<00:11,  1.48s/it] 46%|████▌     | 6/13 [00:09<00:10,  1.44s/it] 54%|█████▍    | 7/13 [00:10<00:08,  1.41s/it] 62%|██████▏   | 8/13 [00:11<00:06,  1.38s/it] 69%|██████▉   | 9/13 [00:13<00:05,  1.37s/it] 77%|███████▋  | 10/13 [00:14<00:04,  1.37s/it] 85%|████████▍ | 11/13 [00:16<00:02,  1.36s/it] 92%|█████████▏| 12/13 [00:17<00:01,  1.43s/it]100%|██████████| 13/13 [00:18<00:00,  1.15s/it]100%|██████████| 13/13 [00:18<00:00,  1.41s/it]Validation set distribution: 
Number of samples  1580

{0: 214, 1: 393, 2: 973}
Labeled set distribution: 
Number of samples  14220
{0: 1748, 1: 3315, 2: 9157}
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.weight', 'fc.bias'])
thief state:  None
Load pretrained model for initializing the thief
pretrained state:  dict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked'])
Thief model initialized successfully
specificity = 79/80
sensitivity = 0/42
Initial model on target dataset: acc = 0.3934, agreement = 0.3689, f1 = 0.1882, spec = 0.9875, sens = 0.0000
specificity = 544/607
sensitivity = 81/973
Initial model on validation dataset: acc = 0.2734, agreement = 0.2734, f1 = 0.1763, spec = 0.8962, sens = 0.0832
la:  None
>> Train a Model.
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:20<16:58, 20.79s/it]  4%|▍         | 2/50 [00:44<18:00, 22.51s/it]  6%|▌         | 3/50 [01:05<17:02, 21.75s/it]  8%|▊         | 4/50 [01:29<17:23, 22.69s/it] 10%|█         | 5/50 [02:08<21:27, 28.61s/it]Epoch 5: Train acc/f1 = 0.9730 / 0.9663 / 0.9471 / 0.9931 
                Val acc/f1/spec/sens = 0.8937 / 0.8781 / 0.9720 / 0.8839
                Test acc/f1/spec/sens = 0.6803 / 0.6893 / 0.7375 / 0.7857
 12%|█▏        | 6/50 [02:32<19:50, 27.07s/it] 14%|█▍        | 7/50 [02:53<17:58, 25.07s/it] 16%|█▌        | 8/50 [03:17<17:17, 24.70s/it] 18%|█▊        | 9/50 [03:38<16:08, 23.61s/it] 20%|██        | 10/50 [04:20<19:34, 29.35s/it]Epoch 10: Train acc/f1 = 0.9534 / 0.9477 / 0.9943 / 0.9411 
                Val acc/f1/spec/sens = 0.8753 / 0.8618 / 0.9456 / 0.8664
                Test acc/f1/spec/sens = 0.6721 / 0.6736 / 0.9375 / 0.4762
 22%|██▏       | 11/50 [04:41<17:25, 26.81s/it] 24%|██▍       | 12/50 [05:05<16:22, 25.86s/it] 26%|██▌       | 13/50 [05:26<15:04, 24.44s/it] 28%|██▊       | 14/50 [05:50<14:36, 24.34s/it] 30%|███       | 15/50 [06:30<16:51, 28.91s/it]Epoch 15: Train acc/f1 = 0.9984 / 0.9971 / 0.9996 / 0.9995 
                Val acc/f1/spec/sens = 0.9133 / 0.9013 / 0.9489 / 0.9157
                Test acc/f1/spec/sens = 0.7541 / 0.7604 / 0.9250 / 0.6429
 32%|███▏      | 16/50 [06:54<15:31, 27.39s/it] 34%|███▍      | 17/50 [07:15<14:02, 25.53s/it] 36%|███▌      | 18/50 [07:39<13:24, 25.14s/it] 38%|███▊      | 19/50 [08:00<12:20, 23.90s/it] 40%|████      | 20/50 [08:43<14:43, 29.45s/it]Epoch 20: Train acc/f1 = 0.9997 / 0.9997 / 0.9992 / 1.0000 
                Val acc/f1/spec/sens = 0.9171 / 0.9006 / 0.9127 / 0.9466
                Test acc/f1/spec/sens = 0.7377 / 0.7384 / 0.8250 / 0.7619
 42%|████▏     | 21/50 [09:04<13:02, 26.98s/it] 44%|████▍     | 22/50 [09:28<12:08, 26.01s/it] 46%|████▌     | 23/50 [09:49<11:01, 24.51s/it] 48%|████▊     | 24/50 [10:12<10:30, 24.26s/it] 50%|█████     | 25/50 [10:52<11:59, 28.78s/it]Epoch 25: Train acc/f1 = 0.9942 / 0.9918 / 0.9976 / 0.9951 
                Val acc/f1/spec/sens = 0.8930 / 0.8732 / 0.9572 / 0.8911
                Test acc/f1/spec/sens = 0.6967 / 0.6938 / 0.9000 / 0.5476
 52%|█████▏    | 26/50 [11:15<10:53, 27.24s/it] 54%|█████▍    | 27/50 [11:36<09:44, 25.41s/it] 56%|█████▌    | 28/50 [12:00<09:06, 24.86s/it] 58%|█████▊    | 29/50 [12:21<08:17, 23.71s/it] 60%|██████    | 30/50 [13:03<09:42, 29.11s/it]Epoch 30: Train acc/f1 = 0.9937 / 0.9923 / 0.9872 / 0.9987 
                Val acc/f1/spec/sens = 0.9089 / 0.8895 / 0.8814 / 0.9538
                Test acc/f1/spec/sens = 0.7295 / 0.7357 / 0.8500 / 0.7381
 62%|██████▏   | 31/50 [13:24<08:27, 26.72s/it] 64%|██████▍   | 32/50 [13:48<07:45, 25.87s/it] 66%|██████▌   | 33/50 [14:09<06:55, 24.42s/it] 68%|██████▊   | 34/50 [14:33<06:27, 24.22s/it] 70%|███████   | 35/50 [15:12<07:11, 28.77s/it]Epoch 35: Train acc/f1 = 0.9994 / 0.9993 / 1.0000 / 0.9990 
                Val acc/f1/spec/sens = 0.9158 / 0.8988 / 0.9028 / 0.9517
                Test acc/f1/spec/sens = 0.7213 / 0.7286 / 0.8500 / 0.6905
 72%|███████▏  | 36/50 [15:36<06:22, 27.32s/it] 74%|███████▍  | 37/50 [15:57<05:30, 25.44s/it] 76%|███████▌  | 38/50 [16:21<04:59, 24.97s/it] 78%|███████▊  | 39/50 [16:42<04:22, 23.82s/it] 80%|████████  | 40/50 [17:24<04:51, 29.17s/it]Epoch 40: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.9196 / 0.9001 / 0.9160 / 0.9527
                Test acc/f1/spec/sens = 0.6967 / 0.7044 / 0.8875 / 0.6429
 82%|████████▏ | 41/50 [17:45<04:00, 26.73s/it] 84%|████████▍ | 42/50 [18:08<03:26, 25.84s/it] 86%|████████▌ | 43/50 [18:30<02:51, 24.48s/it] 88%|████████▊ | 44/50 [18:53<02:25, 24.21s/it] 90%|█████████ | 45/50 [19:33<02:23, 28.76s/it]Epoch 45: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.9228 / 0.9057 / 0.9390 / 0.9445
                Test acc/f1/spec/sens = 0.7213 / 0.7330 / 0.8500 / 0.6429
 92%|█████████▏| 46/50 [19:57<01:49, 27.38s/it] 94%|█████████▍| 47/50 [20:18<01:16, 25.49s/it] 96%|█████████▌| 48/50 [20:42<00:49, 24.99s/it] 98%|█████████▊| 49/50 [21:03<00:23, 23.85s/it]100%|██████████| 50/50 [21:45<00:00, 29.22s/it]                                               Epoch 50: Train acc/f1 = 0.9743 / 0.9644 / 0.9723 / 0.9863 
                Val acc/f1/spec/sens = 0.8880 / 0.8604 / 0.8863 / 0.9322
                Test acc/f1/spec/sens = 0.6885 / 0.6996 / 0.7625 / 0.7381
specificity = 4923/5063
sensitivity = 9032/9157
specificity = 538/607
sensitivity = 907/973
specificity = 61/80
sensitivity = 31/42
Trial 1, Cycle 1
Train acc/f1/spec/sens = 0.9743 / 0.9644 / 0.9723 / 0.9863
Val acc/f1/spec/sens = 0.8880 / 0.8604 / 0.8863 / 0.9322
Test acc/f1/spec/sens = 0.6885 / 0.6996 / 0.7625 / 0.7381
>> Finished.
specificity = 61/80
sensitivity = 31/42
Acc, agreement for latest model:  0.6885245901639344 0.7295081967213115
Load best checkpoint for thief model
specificity = 72/80
sensitivity = 25/42
Acc, agreement for best model:  0.6885245901639344 0.7049180327868853
Trial 0/1 || Cycle 1/1 || Label set size 14220 || Test acc 0.6885 || Test agreement 0.7049 || Spec 0.9000 || Sens 0.5952
**************************************************************************************************** 

specificity = 72/80
sensitivity = 25/42
Number of samples  14220
0.7049180327868853 0.0
        acc       agr  spec      sens                   label dist
0  0.688525  0.704918   0.9  0.595238  {0: 1748, 1: 3315, 2: 9157}
Results saved to  results/gbusg_radformer/GBUSV_resnet50/SGD/15800_val1580/random_v1
