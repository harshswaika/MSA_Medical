nohup: ignoring input
[24/02/14 13:33:18] [conf.py:  281]: PyTorch Version: torch=1.11.0, cuda=11.3, cudnn=8200
[24/02/14 13:33:18] [conf.py:  283]: ACTIVE:
  ADDENDUM: 0
  ALPHA: 0.0
  AUGMENT: None
  BETA: 1.0
  BUDGET: 5000
  CUTMIX_PROB: 0.0
  CYCLES: 1
  INITIAL: 4500
  LA: False
  METHOD: random
  PRETRAINED_PATH: /home/ankita/scratch/MSA_results/ckpts/resnet50-imagenet1k.pth
  TEMP: 1.0
  TRO: 1.0
  USE_PRETRAINED: False
  VAL: 500
AM:
  SGR: 1000
  THRESHOLD: 0.5
CUDNN_BENCHMARK: True
DS_SEED: 123
EDM:
  HASH: /home/harsh_s/scratch/msacopy/exp/hash/alpha.pt
  NUM_MODELS: 5
  PATH1: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T0.pt
  PATH2: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T1.pt
  PATH3: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T2.pt
  PATH4: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T3.pt
  PATH5: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T4.pt
GR:
  EPSILON: 0.1
  SUR_PATH: /home/harsh_s/scratch/msacopy/GRAD2/batch_training/outputs/trained_models/imagenet_cifar10_to_cifar10_surrogate_10epochs.pt
LOG_DEST: radformer_gbusv_radformer_240214_133318.txt
LOG_TIME: 240214_133318
METHOD_NAME: v4
OUT_DIR: results
RNG_SEED: 1
SAVE_DIR: results/gbusg_radformer/GBUSV_radformer/SGD/5000_val500/random_v4
THIEF:
  ARCH: radformer
  DATASET: GBUSV
  DATA_ROOT: /home/ankita/scratch/Datasets/GBUSV-Shared
  HARD_LABELS: True
  NUM_TRAIN: 1281167
  SUBSET: 128116
TRAIN:
  BATCH: 32
  EPOCH: 50
  GAMMA: 0.1
  LR: 0.003
  MILESTONES: [10, 20, 30, 40]
  MOMENTUM: 0.9
  OPTIMIZER: SGD
  WDECAY: 0.0005
VICTIM:
  ARCH: radformer
  DATASET: gbusg
  DATA_ROOT: /home/ankita/scratch/Datasets/GBCU-Shared
  HEIGHT: 224
  PATH: victim_models/radformer/radformer.pkl
  PATHIN: /home/harsh_s/scratch/msacopy/ckpts/cifar10-resnet32-inaccurate/checkpoint.pth.tar
  WIDTH: 224
Loaded target dataset of size 122 with 3 classes
target model keys:  695
checkpoint keys:  695
specificity = 72/80
sensitivity = 39/42

Target model acc = 0.9016393442622951
Val-Acc: 0.9016 Val-Spec: 0.9000 Val-Sens: 0.9286
Num of videos 64 frames 15800
Num of videos 64 frames 15800
replacing labeled set labels with victim labels
  0%|          | 0/141 [00:00<?, ?it/s]  1%|          | 1/141 [00:02<04:42,  2.02s/it]  1%|▏         | 2/141 [00:02<03:11,  1.38s/it]  2%|▏         | 3/141 [00:03<02:41,  1.17s/it]  3%|▎         | 4/141 [00:05<02:48,  1.23s/it]  4%|▎         | 5/141 [00:06<02:51,  1.26s/it]  4%|▍         | 6/141 [00:07<02:40,  1.19s/it]  5%|▍         | 7/141 [00:08<02:23,  1.07s/it]  6%|▌         | 8/141 [00:09<02:20,  1.05s/it]  6%|▋         | 9/141 [00:10<02:24,  1.09s/it]  7%|▋         | 10/141 [00:11<02:13,  1.02s/it]  8%|▊         | 11/141 [00:12<02:11,  1.01s/it]  9%|▊         | 12/141 [00:13<02:14,  1.04s/it]  9%|▉         | 13/141 [00:14<02:29,  1.16s/it] 10%|▉         | 14/141 [00:16<02:45,  1.30s/it] 11%|█         | 15/141 [00:18<02:49,  1.34s/it] 11%|█▏        | 16/141 [00:19<03:06,  1.49s/it] 12%|█▏        | 17/141 [00:21<03:11,  1.55s/it] 13%|█▎        | 18/141 [00:23<03:13,  1.57s/it] 13%|█▎        | 19/141 [00:24<03:11,  1.57s/it] 14%|█▍        | 20/141 [00:26<03:27,  1.72s/it] 15%|█▍        | 21/141 [00:28<03:14,  1.62s/it] 16%|█▌        | 22/141 [00:29<03:04,  1.55s/it] 16%|█▋        | 23/141 [00:31<03:04,  1.56s/it] 17%|█▋        | 24/141 [00:32<03:10,  1.63s/it] 18%|█▊        | 25/141 [00:34<03:22,  1.75s/it] 18%|█▊        | 26/141 [00:36<03:26,  1.79s/it] 19%|█▉        | 27/141 [00:38<03:30,  1.84s/it] 20%|█▉        | 28/141 [00:40<03:23,  1.80s/it] 21%|██        | 29/141 [00:42<03:24,  1.82s/it] 21%|██▏       | 30/141 [00:44<03:39,  1.98s/it] 22%|██▏       | 31/141 [00:46<03:19,  1.81s/it] 23%|██▎       | 32/141 [00:47<03:15,  1.80s/it] 23%|██▎       | 33/141 [00:49<03:21,  1.86s/it] 24%|██▍       | 34/141 [00:51<03:16,  1.84s/it] 25%|██▍       | 35/141 [00:53<03:24,  1.93s/it] 26%|██▌       | 36/141 [00:56<03:29,  1.99s/it] 26%|██▌       | 37/141 [00:58<03:36,  2.08s/it] 27%|██▋       | 38/141 [01:00<03:37,  2.11s/it] 28%|██▊       | 39/141 [01:02<03:39,  2.15s/it] 28%|██▊       | 40/141 [01:05<03:47,  2.26s/it] 29%|██▉       | 41/141 [01:06<03:26,  2.06s/it] 30%|██▉       | 42/141 [01:08<03:16,  1.99s/it] 30%|███       | 43/141 [01:10<03:06,  1.90s/it] 31%|███       | 44/141 [01:12<03:03,  1.89s/it] 32%|███▏      | 45/141 [01:14<03:11,  2.00s/it] 33%|███▎      | 46/141 [01:15<02:56,  1.86s/it] 33%|███▎      | 47/141 [01:17<02:42,  1.73s/it] 34%|███▍      | 48/141 [01:19<02:40,  1.73s/it] 35%|███▍      | 49/141 [01:21<02:47,  1.82s/it] 35%|███▌      | 50/141 [01:23<03:02,  2.01s/it] 36%|███▌      | 51/141 [01:26<03:10,  2.12s/it] 37%|███▋      | 52/141 [01:28<03:08,  2.12s/it] 38%|███▊      | 53/141 [01:31<03:35,  2.45s/it] 38%|███▊      | 54/141 [01:33<03:34,  2.47s/it] 39%|███▉      | 55/141 [01:36<03:30,  2.45s/it] 40%|███▉      | 56/141 [01:38<03:25,  2.42s/it] 40%|████      | 57/141 [01:40<03:22,  2.41s/it] 41%|████      | 58/141 [01:43<03:27,  2.50s/it] 42%|████▏     | 59/141 [01:46<03:35,  2.63s/it] 43%|████▎     | 60/141 [01:48<03:25,  2.54s/it] 43%|████▎     | 61/141 [01:51<03:24,  2.55s/it] 44%|████▍     | 62/141 [01:54<03:26,  2.61s/it] 45%|████▍     | 63/141 [01:56<03:12,  2.47s/it] 45%|████▌     | 64/141 [01:59<03:22,  2.62s/it] 46%|████▌     | 65/141 [02:01<03:06,  2.45s/it] 47%|████▋     | 66/141 [02:04<03:10,  2.54s/it] 48%|████▊     | 67/141 [02:06<03:04,  2.49s/it] 48%|████▊     | 68/141 [02:09<03:12,  2.64s/it] 49%|████▉     | 69/141 [02:12<03:17,  2.74s/it] 50%|████▉     | 70/141 [02:15<03:09,  2.67s/it] 50%|█████     | 71/141 [02:17<02:57,  2.54s/it] 51%|█████     | 72/141 [02:18<02:28,  2.15s/it] 52%|█████▏    | 73/141 [02:21<02:34,  2.27s/it] 52%|█████▏    | 74/141 [02:23<02:40,  2.40s/it] 53%|█████▎    | 75/141 [02:26<02:36,  2.37s/it] 54%|█████▍    | 76/141 [02:28<02:38,  2.43s/it] 55%|█████▍    | 77/141 [02:31<02:34,  2.41s/it] 55%|█████▌    | 78/141 [02:33<02:35,  2.47s/it] 56%|█████▌    | 79/141 [02:36<02:36,  2.53s/it] 57%|█████▋    | 80/141 [02:39<02:39,  2.62s/it] 57%|█████▋    | 81/141 [02:41<02:35,  2.58s/it] 58%|█████▊    | 82/141 [02:43<02:26,  2.48s/it] 59%|█████▉    | 83/141 [02:46<02:22,  2.46s/it] 60%|█████▉    | 84/141 [02:48<02:23,  2.51s/it] 60%|██████    | 85/141 [02:51<02:22,  2.54s/it] 61%|██████    | 86/141 [02:53<02:16,  2.49s/it] 62%|██████▏   | 87/141 [02:55<01:59,  2.22s/it] 62%|██████▏   | 88/141 [02:57<01:55,  2.17s/it] 63%|██████▎   | 89/141 [02:59<01:52,  2.17s/it] 64%|██████▍   | 90/141 [03:01<01:43,  2.02s/it] 65%|██████▍   | 91/141 [03:03<01:36,  1.93s/it] 65%|██████▌   | 92/141 [03:05<01:44,  2.12s/it] 66%|██████▌   | 93/141 [03:08<01:45,  2.21s/it] 67%|██████▋   | 94/141 [03:10<01:47,  2.28s/it] 67%|██████▋   | 95/141 [03:12<01:46,  2.31s/it] 68%|██████▊   | 96/141 [03:15<01:48,  2.41s/it] 69%|██████▉   | 97/141 [03:17<01:44,  2.38s/it] 70%|██████▉   | 98/141 [03:20<01:44,  2.43s/it] 70%|███████   | 99/141 [03:23<01:44,  2.49s/it] 71%|███████   | 100/141 [03:25<01:43,  2.51s/it] 72%|███████▏  | 101/141 [03:27<01:37,  2.44s/it] 72%|███████▏  | 102/141 [03:29<01:30,  2.31s/it] 73%|███████▎  | 103/141 [03:32<01:31,  2.41s/it] 74%|███████▍  | 104/141 [03:35<01:30,  2.43s/it] 74%|███████▍  | 105/141 [03:37<01:29,  2.48s/it] 75%|███████▌  | 106/141 [03:39<01:24,  2.40s/it] 76%|███████▌  | 107/141 [03:42<01:21,  2.38s/it] 77%|███████▋  | 108/141 [03:44<01:15,  2.30s/it] 77%|███████▋  | 109/141 [03:46<01:16,  2.38s/it] 78%|███████▊  | 110/141 [03:49<01:14,  2.40s/it] 79%|███████▊  | 111/141 [03:51<01:13,  2.45s/it] 79%|███████▉  | 112/141 [03:54<01:14,  2.56s/it] 80%|████████  | 113/141 [03:57<01:15,  2.68s/it] 81%|████████  | 114/141 [04:00<01:10,  2.62s/it] 82%|████████▏ | 115/141 [04:01<00:59,  2.28s/it] 82%|████████▏ | 116/141 [04:03<00:57,  2.30s/it] 83%|████████▎ | 117/141 [04:06<00:56,  2.35s/it] 84%|████████▎ | 118/141 [04:08<00:53,  2.31s/it] 84%|████████▍ | 119/141 [04:11<00:52,  2.36s/it] 85%|████████▌ | 120/141 [04:13<00:49,  2.34s/it] 86%|████████▌ | 121/141 [04:15<00:45,  2.29s/it] 87%|████████▋ | 122/141 [04:17<00:43,  2.29s/it] 87%|████████▋ | 123/141 [04:20<00:41,  2.31s/it] 88%|████████▊ | 124/141 [04:21<00:36,  2.15s/it] 89%|████████▊ | 125/141 [04:24<00:34,  2.19s/it] 89%|████████▉ | 126/141 [04:26<00:34,  2.31s/it] 90%|█████████ | 127/141 [04:29<00:32,  2.33s/it] 91%|█████████ | 128/141 [04:31<00:28,  2.22s/it] 91%|█████████▏| 129/141 [04:33<00:26,  2.22s/it] 92%|█████████▏| 130/141 [04:35<00:24,  2.26s/it] 93%|█████████▎| 131/141 [04:38<00:24,  2.41s/it] 94%|█████████▎| 132/141 [04:41<00:22,  2.54s/it] 94%|█████████▍| 133/141 [04:43<00:19,  2.40s/it] 95%|█████████▌| 134/141 [04:45<00:16,  2.31s/it] 96%|█████████▌| 135/141 [04:47<00:12,  2.14s/it] 96%|█████████▋| 136/141 [04:49<00:10,  2.13s/it] 97%|█████████▋| 137/141 [04:51<00:08,  2.20s/it] 98%|█████████▊| 138/141 [04:53<00:06,  2.15s/it] 99%|█████████▊| 139/141 [04:56<00:04,  2.23s/it] 99%|█████████▉| 140/141 [04:58<00:02,  2.24s/it]100%|██████████| 141/141 [05:00<00:00,  2.06s/it]100%|██████████| 141/141 [05:00<00:00,  2.13s/it]
replacing val labels with victim labels
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:02<00:39,  2.64s/it] 12%|█▎        | 2/16 [00:04<00:28,  2.05s/it] 19%|█▉        | 3/16 [00:06<00:27,  2.11s/it] 25%|██▌       | 4/16 [00:08<00:26,  2.24s/it] 31%|███▏      | 5/16 [00:11<00:25,  2.31s/it] 38%|███▊      | 6/16 [00:13<00:22,  2.25s/it] 44%|████▍     | 7/16 [00:15<00:19,  2.17s/it] 50%|█████     | 8/16 [00:17<00:17,  2.23s/it] 56%|█████▋    | 9/16 [00:20<00:15,  2.27s/it] 62%|██████▎   | 10/16 [00:22<00:13,  2.33s/it] 69%|██████▉   | 11/16 [00:24<00:11,  2.28s/it] 75%|███████▌  | 12/16 [00:27<00:09,  2.33s/it] 81%|████████▏ | 13/16 [00:29<00:07,  2.37s/it] 88%|████████▊ | 14/16 [00:32<00:04,  2.37s/it] 94%|█████████▍| 15/16 [00:34<00:02,  2.36s/it]100%|██████████| 16/16 [00:35<00:00,  2.11s/it]100%|██████████| 16/16 [00:36<00:00,  2.26s/it]Validation set distribution: 
Number of samples  500

{0: 89, 1: 118, 2: 293}
Labeled set distribution: 
Number of samples  4500
{0: 678, 1: 1049, 2: 2773}
Thief model initialized successfully
specificity = 80/80
sensitivity = 0/42
Initial model on target dataset: acc = 0.4016, agreement = 0.3770, f1 = 0.1910, spec = 1.0000, sens = 0.0000
specificity = 207/207
sensitivity = 0/293
Initial model on validation dataset: acc = 0.2360, agreement = 0.2360, f1 = 0.1273, spec = 1.0000, sens = 0.0000
la:  None
>> Train a Model.
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [06:34<5:21:52, 394.14s/it]epoch 0, loss = 29.86770248413086
epoch 1, loss = 25.6077938079834
  4%|▍         | 2/50 [19:05<8:03:22, 604.23s/it]Epoch 2: Train acc/f1 = 0.8733 / 0.8314 / 0.8743 / 0.9380 
                Val acc/f1/spec/sens = 0.8680 / 0.8332 / 0.8937 / 0.9283
                Test acc/f1/spec/sens = 0.8197 / 0.8223 / 0.9500 / 0.7143
  6%|▌         | 3/50 [23:50<5:59:06, 458.44s/it]epoch 2, loss = 21.69064712524414
epoch 3, loss = 21.13461685180664
  8%|▊         | 4/50 [33:52<6:34:50, 515.02s/it]Epoch 4: Train acc/f1 = 0.9127 / 0.8838 / 0.9079 / 0.9603 
                Val acc/f1/spec/sens = 0.8740 / 0.8431 / 0.9082 / 0.9249
                Test acc/f1/spec/sens = 0.7705 / 0.7781 / 0.9250 / 0.6667
 10%|█         | 5/50 [38:37<5:24:10, 432.23s/it]epoch 4, loss = 21.04088020324707
epoch 5, loss = 20.66386604309082
 12%|█▏        | 6/50 [51:29<6:41:36, 547.64s/it]Epoch 6: Train acc/f1 = 0.8902 / 0.8581 / 0.8668 / 0.9484 
                Val acc/f1/spec/sens = 0.8560 / 0.8167 / 0.8647 / 0.9283
                Test acc/f1/spec/sens = 0.7295 / 0.7204 / 0.9125 / 0.7143
 14%|█▍        | 7/50 [58:08<5:57:46, 499.22s/it]epoch 6, loss = 20.77730941772461
epoch 7, loss = 20.33557891845703
 16%|█▌        | 8/50 [1:11:26<6:55:52, 594.10s/it]Epoch 8: Train acc/f1 = 0.9149 / 0.8934 / 0.9178 / 0.9470 
                Val acc/f1/spec/sens = 0.8440 / 0.8137 / 0.8986 / 0.8840
                Test acc/f1/spec/sens = 0.7705 / 0.7769 / 0.9750 / 0.5476
 18%|█▊        | 9/50 [1:16:38<5:45:47, 506.05s/it]epoch 8, loss = 20.369932174682617
epoch 9, loss = 20.209476470947266
 20%|██        | 10/50 [1:28:59<6:25:39, 578.49s/it]Epoch 10: Train acc/f1 = 0.9398 / 0.9232 / 0.9253 / 0.9733 
                Val acc/f1/spec/sens = 0.8880 / 0.8584 / 0.9130 / 0.9386
                Test acc/f1/spec/sens = 0.7705 / 0.7783 / 0.9625 / 0.5714
 22%|██▏       | 11/50 [1:35:32<5:39:11, 521.84s/it]epoch 10, loss = 19.64472770690918
epoch 11, loss = 19.55519676208496
 24%|██▍       | 12/50 [1:42:50<5:14:14, 496.18s/it]Epoch 12: Train acc/f1 = 0.9480 / 0.9329 / 0.9328 / 0.9794 
                Val acc/f1/spec/sens = 0.8940 / 0.8673 / 0.9179 / 0.9386
                Test acc/f1/spec/sens = 0.7869 / 0.7956 / 0.9625 / 0.5714
 26%|██▌       | 13/50 [1:44:11<3:48:32, 370.60s/it]epoch 12, loss = 19.446332931518555
epoch 13, loss = 19.35401725769043
 28%|██▊       | 14/50 [1:46:55<3:04:57, 308.25s/it]Epoch 14: Train acc/f1 = 0.9531 / 0.9401 / 0.9351 / 0.9827 
                Val acc/f1/spec/sens = 0.8960 / 0.8700 / 0.9179 / 0.9386
                Test acc/f1/spec/sens = 0.7951 / 0.8040 / 0.9625 / 0.5952
 30%|███       | 15/50 [1:48:22<2:20:49, 241.42s/it]epoch 14, loss = 19.304584503173828
epoch 15, loss = 19.254777908325195
 32%|███▏      | 16/50 [1:51:09<2:04:07, 219.05s/it]Epoch 16: Train acc/f1 = 0.9560 / 0.9432 / 0.9386 / 0.9849 
                Val acc/f1/spec/sens = 0.8980 / 0.8734 / 0.9179 / 0.9386
                Test acc/f1/spec/sens = 0.8033 / 0.8120 / 0.9625 / 0.6429
 34%|███▍      | 17/50 [1:52:38<1:38:53, 179.82s/it]epoch 16, loss = 19.23739242553711
epoch 17, loss = 19.15375518798828
 36%|███▌      | 18/50 [1:55:29<1:34:31, 177.22s/it]Epoch 18: Train acc/f1 = 0.9580 / 0.9465 / 0.9461 / 0.9816 
                Val acc/f1/spec/sens = 0.8980 / 0.8754 / 0.9227 / 0.9317
                Test acc/f1/spec/sens = 0.8033 / 0.8124 / 0.9625 / 0.6190
 38%|███▊      | 19/50 [1:57:06<1:19:08, 153.19s/it]epoch 18, loss = 19.153478622436523
epoch 19, loss = 18.99639320373535
 40%|████      | 20/50 [1:59:59<1:19:38, 159.28s/it]Epoch 20: Train acc/f1 = 0.9604 / 0.9494 / 0.9427 / 0.9867 
                Val acc/f1/spec/sens = 0.8960 / 0.8709 / 0.9082 / 0.9420
                Test acc/f1/spec/sens = 0.8033 / 0.8120 / 0.9625 / 0.6429
 42%|████▏     | 21/50 [2:01:28<1:06:43, 138.06s/it]epoch 20, loss = 19.09032440185547
epoch 21, loss = 19.024320602416992
 44%|████▍     | 22/50 [2:04:28<1:10:19, 150.70s/it]Epoch 22: Train acc/f1 = 0.9622 / 0.9518 / 0.9473 / 0.9863 
                Val acc/f1/spec/sens = 0.9040 / 0.8819 / 0.9179 / 0.9420
                Test acc/f1/spec/sens = 0.8033 / 0.8120 / 0.9625 / 0.6429
 46%|████▌     | 23/50 [2:06:02<1:00:04, 133.51s/it]epoch 22, loss = 18.96831512451172
epoch 23, loss = 19.004257202148438
 48%|████▊     | 24/50 [2:08:49<1:02:12, 143.56s/it]Epoch 24: Train acc/f1 = 0.9616 / 0.9508 / 0.9456 / 0.9863 
                Val acc/f1/spec/sens = 0.9020 / 0.8774 / 0.9179 / 0.9454
                Test acc/f1/spec/sens = 0.8033 / 0.8120 / 0.9625 / 0.6429
 50%|█████     | 25/50 [2:10:15<52:40, 126.40s/it]  epoch 24, loss = 19.01051902770996
epoch 25, loss = 18.99505043029785
 52%|█████▏    | 26/50 [2:14:33<1:06:22, 165.93s/it]Epoch 26: Train acc/f1 = 0.9607 / 0.9499 / 0.9415 / 0.9870 
                Val acc/f1/spec/sens = 0.9040 / 0.8804 / 0.9130 / 0.9488
                Test acc/f1/spec/sens = 0.8279 / 0.8358 / 0.9625 / 0.7143
 54%|█████▍    | 27/50 [2:16:33<58:20, 152.21s/it]  epoch 26, loss = 18.92706871032715
epoch 27, loss = 18.90497398376465
 56%|█████▌    | 28/50 [2:19:21<57:30, 156.82s/it]Epoch 28: Train acc/f1 = 0.9618 / 0.9511 / 0.9456 / 0.9863 
                Val acc/f1/spec/sens = 0.9000 / 0.8764 / 0.9130 / 0.9420
                Test acc/f1/spec/sens = 0.8115 / 0.8200 / 0.9625 / 0.6667
 58%|█████▊    | 29/50 [2:20:47<47:29, 135.68s/it]epoch 28, loss = 18.97147560119629
epoch 29, loss = 18.928016662597656
 60%|██████    | 30/50 [2:23:26<47:31, 142.56s/it]Epoch 30: Train acc/f1 = 0.9622 / 0.9516 / 0.9473 / 0.9863 
                Val acc/f1/spec/sens = 0.9000 / 0.8772 / 0.9179 / 0.9386
                Test acc/f1/spec/sens = 0.7951 / 0.8039 / 0.9625 / 0.6190
 62%|██████▏   | 31/50 [2:25:44<44:45, 141.32s/it]epoch 30, loss = 18.96434783935547
epoch 31, loss = 18.887605667114258
 64%|██████▍   | 32/50 [2:28:27<44:16, 147.60s/it]Epoch 32: Train acc/f1 = 0.9622 / 0.9516 / 0.9467 / 0.9867 
                Val acc/f1/spec/sens = 0.9000 / 0.8753 / 0.9130 / 0.9454
                Test acc/f1/spec/sens = 0.8033 / 0.8120 / 0.9625 / 0.6429
 66%|██████▌   | 33/50 [2:29:54<36:44, 129.65s/it]epoch 32, loss = 18.926410675048828
epoch 33, loss = 18.972152709960938
 68%|██████▊   | 34/50 [2:32:41<37:30, 140.64s/it]Epoch 34: Train acc/f1 = 0.9618 / 0.9510 / 0.9444 / 0.9870 
                Val acc/f1/spec/sens = 0.9020 / 0.8786 / 0.9130 / 0.9454
                Test acc/f1/spec/sens = 0.8033 / 0.8120 / 0.9625 / 0.6429
 70%|███████   | 35/50 [2:34:59<34:58, 139.91s/it]epoch 34, loss = 18.968568801879883
epoch 35, loss = 18.90395164489746
 72%|███████▏  | 36/50 [2:39:10<40:27, 173.42s/it]Epoch 36: Train acc/f1 = 0.9627 / 0.9524 / 0.9485 / 0.9859 
                Val acc/f1/spec/sens = 0.8980 / 0.8766 / 0.9179 / 0.9317
                Test acc/f1/spec/sens = 0.8033 / 0.8124 / 0.9625 / 0.6190
 74%|███████▍  | 37/50 [2:40:37<31:57, 147.49s/it]epoch 36, loss = 18.975183486938477
epoch 37, loss = 18.952348709106445
 76%|███████▌  | 38/50 [2:43:23<30:36, 153.02s/it]Epoch 38: Train acc/f1 = 0.9627 / 0.9522 / 0.9479 / 0.9863 
                Val acc/f1/spec/sens = 0.9020 / 0.8801 / 0.9179 / 0.9386
                Test acc/f1/spec/sens = 0.8115 / 0.8206 / 0.9625 / 0.6429
 78%|███████▊  | 39/50 [2:44:48<24:16, 132.42s/it]epoch 38, loss = 18.92018699645996
epoch 39, loss = 18.924549102783203
 80%|████████  | 40/50 [2:47:30<23:34, 141.42s/it]Epoch 40: Train acc/f1 = 0.9622 / 0.9516 / 0.9473 / 0.9863 
                Val acc/f1/spec/sens = 0.9020 / 0.8785 / 0.9179 / 0.9420
                Test acc/f1/spec/sens = 0.8115 / 0.8206 / 0.9625 / 0.6429
 82%|████████▏ | 41/50 [2:48:56<18:41, 124.64s/it]epoch 40, loss = 18.878679275512695
epoch 41, loss = 18.97838020324707
 84%|████████▍ | 42/50 [2:51:36<18:01, 135.22s/it]Epoch 42: Train acc/f1 = 0.9627 / 0.9522 / 0.9473 / 0.9867 
                Val acc/f1/spec/sens = 0.9000 / 0.8768 / 0.9130 / 0.9420
                Test acc/f1/spec/sens = 0.8033 / 0.8120 / 0.9625 / 0.6429
 86%|████████▌ | 43/50 [2:52:58<13:55, 119.34s/it]epoch 42, loss = 18.966907501220703
epoch 43, loss = 18.933500289916992
 88%|████████▊ | 44/50 [2:55:33<13:01, 130.22s/it]Epoch 44: Train acc/f1 = 0.9620 / 0.9512 / 0.9473 / 0.9863 
                Val acc/f1/spec/sens = 0.9020 / 0.8773 / 0.9179 / 0.9454
                Test acc/f1/spec/sens = 0.7951 / 0.8039 / 0.9625 / 0.6190
 90%|█████████ | 45/50 [2:56:59<09:43, 116.69s/it]epoch 44, loss = 18.90215301513672
epoch 45, loss = 18.928207397460938
 92%|█████████▏| 46/50 [2:59:43<08:44, 131.11s/it]Epoch 46: Train acc/f1 = 0.9624 / 0.9519 / 0.9479 / 0.9863 
                Val acc/f1/spec/sens = 0.9000 / 0.8768 / 0.9179 / 0.9386
                Test acc/f1/spec/sens = 0.8033 / 0.8120 / 0.9625 / 0.6429
 94%|█████████▍| 47/50 [3:02:13<06:50, 136.78s/it]epoch 46, loss = 18.91506004333496
epoch 47, loss = 18.98355484008789
 96%|█████████▌| 48/50 [3:05:10<04:57, 148.79s/it]Epoch 48: Train acc/f1 = 0.9622 / 0.9516 / 0.9473 / 0.9863 
                Val acc/f1/spec/sens = 0.8980 / 0.8750 / 0.9179 / 0.9352
                Test acc/f1/spec/sens = 0.8033 / 0.8120 / 0.9625 / 0.6429
 98%|█████████▊| 49/50 [3:07:38<02:28, 148.51s/it]epoch 48, loss = 19.0279598236084
epoch 49, loss = 18.958667755126953
100%|██████████| 50/50 [3:10:32<00:00, 156.10s/it]                                                  Epoch 50: Train acc/f1 = 0.9627 / 0.9523 / 0.9479 / 0.9863 
                Val acc/f1/spec/sens = 0.9000 / 0.8784 / 0.9179 / 0.9352
                Test acc/f1/spec/sens = 0.8033 / 0.8120 / 0.9625 / 0.6429
specificity = 1637/1727
sensitivity = 2735/2773
specificity = 190/207
sensitivity = 274/293
specificity = 77/80
sensitivity = 27/42
Trial 1, Cycle 1
Train acc/f1/spec/sens = 0.9627 / 0.9523 / 0.9479 / 0.9863
Val acc/f1/spec/sens = 0.9000 / 0.8784 / 0.9179 / 0.9352
Test acc/f1/spec/sens = 0.8033 / 0.8120 / 0.9625 / 0.6429
>> Finished.
specificity = 77/80
sensitivity = 27/42
Acc, agreement for latest model:  0.8032786885245902 0.819672131147541
Load best checkpoint for thief model
specificity = 77/80
sensitivity = 27/42
Acc, agreement for best model:  0.8032786885245902 0.819672131147541
Trial 0/1 || Cycle 1/1 || Label set size 4500 || Test acc 0.8033 || Test agreement 0.8197 || Spec 0.9625 || Sens 0.6429
**************************************************************************************************** 

specificity = 77/80
sensitivity = 27/42
Number of samples  4500
0.819672131147541 0.0
        acc       agr    spec      sens                  label dist
0  0.803279  0.819672  0.9625  0.642857  {0: 678, 1: 1049, 2: 2773}
Results saved to  results/gbusg_radformer/GBUSV_radformer/SGD/5000_val500/random_v4
