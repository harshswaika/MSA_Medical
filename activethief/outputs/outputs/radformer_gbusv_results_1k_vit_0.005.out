[24/02/29 21:59:42] [conf.py:  298]: PyTorch Version: torch=1.11.0, cuda=11.3, cudnn=8200
[24/02/29 21:59:42] [conf.py:  300]: ACTIVE:
  ADDENDUM: 0
  ALPHA: 0.2
  AUGMENT: None
  BETA: 1.0
  BUDGET: 1000
  CUTMIX_PROB: 0.0
  CYCLES: 1
  INITIAL: 900
  LA: False
  METHOD: random
  PRETRAINED_PATH: /home/deepankar/mnt/vision3_ckpts/vit_b_16-imagenet1k.pth
  TEMP: 1.0
  TRO: 1.0
  USE_PRETRAINED: True
  VAL: 100
AM:
  SGR: 1000
  THRESHOLD: 0.5
CUDNN_BENCHMARK: True
DS_SEED: 123
EDM:
  HASH: /home/harsh_s/scratch/msacopy/exp/hash/alpha.pt
  NUM_MODELS: 5
  PATH1: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T0.pt
  PATH2: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T1.pt
  PATH3: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T2.pt
  PATH4: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T3.pt
  PATH5: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T4.pt
GR:
  EPSILON: 0.1
  SUR_PATH: /home/harsh_s/scratch/msacopy/GRAD2/batch_training/outputs/trained_models/imagenet_cifar10_to_cifar10_surrogate_10epochs.pt
LOG_DEST: radformer_vit_gbusv_240229_215942.txt
LOG_TIME: 240229_215942
METHOD_NAME: v1
OUT_DIR: /home/deepankar/scratch/MSA_Medical/results_1k
PL:
  CLASS_BLNC: 10
  ITERATIONS: 20
  KAPPA_N: 0.005
  KAPPA_P: 0.05
  NO_PROGRESS: False
  NO_UNCERTAINTY: False
  TAU_N: 0.05
  TAU_P: 0.7
  TEMP_NL: 2.0
RNG_SEED: 5
SAVE_DIR: /home/deepankar/scratch/MSA_Medical/results_1k/gbusg_radformer/GBUSV_vit/SGD/1000_val100/random_v1
THIEF:
  ARCH: vit
  DATASET: GBUSV
  DATA_ROOT: /home/deepankar/mnt/vision3_data_ckpts_msa_medical/GBUSV-Shared
  HARD_LABELS: True
  NUM_TRAIN: 1281167
  SUBSET: 128116
TRAIN:
  BATCH: 16
  EPOCH: 100
  GAMMA: 0.1
  LR: 0.005
  MILESTONES: [20, 40, 60, 80]
  MOMENTUM: 0.9
  OPTIMIZER: SGD
  WDECAY: 0.0005
VICTIM:
  ARCH: radformer
  DATASET: gbusg
  DATA_ROOT: /home/deepankar/mnt/vision3_data_ckpts_msa_medical/GBCU-Shared
  HEIGHT: 224
  PATH: /home/deepankar/mnt/vision3_data_ckpts_msa_medical/victim_models/radformer/radformer.pkl
  PATHIN: /home/harsh_s/scratch/msacopy/ckpts/cifar10-resnet32-inaccurate/checkpoint.pth.tar
  WIDTH: 224
Loaded target dataset of size 122 with 3 classes
target model keys:  695
checkpoint keys:  695
specificity = 72/80
sensitivity = 39/42

Target model acc = 0.9016393442622951
Val-Acc: 0.9016 Val-Spec: 0.9000 Val-Sens: 0.9286
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
replacing labeled set labels with victim labels
  0%|          | 0/57 [00:00<?, ?it/s]  2%|▏         | 1/57 [00:00<00:35,  1.56it/s]  4%|▎         | 2/57 [00:00<00:21,  2.61it/s]  5%|▌         | 3/57 [00:01<00:16,  3.34it/s]  7%|▋         | 4/57 [00:01<00:13,  3.83it/s]  9%|▉         | 5/57 [00:01<00:13,  3.98it/s] 11%|█         | 6/57 [00:01<00:11,  4.30it/s] 12%|█▏        | 7/57 [00:01<00:11,  4.51it/s] 14%|█▍        | 8/57 [00:02<00:10,  4.69it/s] 16%|█▌        | 9/57 [00:02<00:10,  4.79it/s] 18%|█▊        | 10/57 [00:02<00:09,  4.87it/s] 19%|█▉        | 11/57 [00:02<00:09,  4.65it/s] 21%|██        | 12/57 [00:02<00:09,  4.78it/s] 23%|██▎       | 13/57 [00:03<00:09,  4.81it/s] 25%|██▍       | 14/57 [00:03<00:08,  4.86it/s] 26%|██▋       | 15/57 [00:03<00:08,  4.90it/s] 28%|██▊       | 16/57 [00:03<00:08,  4.96it/s] 30%|██▉       | 17/57 [00:03<00:08,  4.99it/s] 32%|███▏      | 18/57 [00:04<00:07,  5.05it/s] 33%|███▎      | 19/57 [00:04<00:07,  5.07it/s] 35%|███▌      | 20/57 [00:04<00:07,  5.03it/s] 37%|███▋      | 21/57 [00:04<00:07,  5.03it/s] 39%|███▊      | 22/57 [00:04<00:06,  5.05it/s] 40%|████      | 23/57 [00:05<00:06,  5.03it/s] 42%|████▏     | 24/57 [00:05<00:06,  5.03it/s] 44%|████▍     | 25/57 [00:05<00:06,  5.01it/s] 46%|████▌     | 26/57 [00:05<00:06,  4.97it/s] 47%|████▋     | 27/57 [00:05<00:06,  4.99it/s] 49%|████▉     | 28/57 [00:06<00:05,  5.01it/s] 51%|█████     | 29/57 [00:06<00:06,  4.57it/s] 53%|█████▎    | 30/57 [00:06<00:06,  4.22it/s] 54%|█████▍    | 31/57 [00:06<00:06,  4.11it/s] 56%|█████▌    | 32/57 [00:07<00:06,  3.99it/s] 58%|█████▊    | 33/57 [00:07<00:06,  3.96it/s] 60%|█████▉    | 34/57 [00:07<00:05,  3.91it/s] 61%|██████▏   | 35/57 [00:07<00:05,  3.86it/s] 63%|██████▎   | 36/57 [00:08<00:05,  3.82it/s] 65%|██████▍   | 37/57 [00:08<00:05,  3.82it/s] 67%|██████▋   | 38/57 [00:08<00:04,  3.82it/s] 68%|██████▊   | 39/57 [00:09<00:04,  3.78it/s] 70%|███████   | 40/57 [00:09<00:04,  3.70it/s] 72%|███████▏  | 41/57 [00:09<00:04,  3.73it/s] 74%|███████▎  | 42/57 [00:09<00:03,  3.80it/s] 75%|███████▌  | 43/57 [00:10<00:03,  3.71it/s] 77%|███████▋  | 44/57 [00:10<00:03,  3.67it/s] 79%|███████▉  | 45/57 [00:10<00:03,  3.71it/s] 81%|████████  | 46/57 [00:10<00:02,  3.75it/s] 82%|████████▏ | 47/57 [00:11<00:02,  3.81it/s] 84%|████████▍ | 48/57 [00:11<00:02,  3.79it/s] 86%|████████▌ | 49/57 [00:11<00:02,  3.84it/s] 88%|████████▊ | 50/57 [00:11<00:01,  3.84it/s] 89%|████████▉ | 51/57 [00:12<00:01,  3.84it/s] 91%|█████████ | 52/57 [00:12<00:01,  3.87it/s] 93%|█████████▎| 53/57 [00:12<00:01,  3.88it/s] 95%|█████████▍| 54/57 [00:12<00:00,  3.86it/s] 96%|█████████▋| 55/57 [00:13<00:00,  3.79it/s] 98%|█████████▊| 56/57 [00:13<00:00,  3.98it/s]100%|██████████| 57/57 [00:13<00:00,  4.17it/s]
replacing val labels with victim labels
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:00<00:03,  1.60it/s] 29%|██▊       | 2/7 [00:00<00:02,  2.42it/s] 43%|████▎     | 3/7 [00:01<00:01,  2.94it/s] 57%|█████▋    | 4/7 [00:01<00:00,  3.28it/s] 71%|███████▏  | 5/7 [00:01<00:00,  3.40it/s] 86%|████████▌ | 6/7 [00:01<00:00,  3.57it/s]100%|██████████| 7/7 [00:02<00:00,  3.35it/s]Validation set distribution: 
Number of samples  100

{0: 9, 1: 18, 2: 73}
Labeled set distribution: 
Number of samples  900
{0: 111, 1: 200, 2: 589}
odict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias', 'heads.head.weight', 'heads.head.bias'])
thief state:  None
pretrained state:  dict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias'])
Thief model initialized successfully
specificity = 80/80
sensitivity = 0/42
Initial model on target dataset: acc = 0.2541, agreement = 0.2377, f1 = 0.1351, spec = 1.0000, sens = 0.0000
specificity = 27/27
sensitivity = 0/73
Initial model on validation dataset: acc = 0.0900, agreement = 0.0900, f1 = 0.0550, spec = 1.0000, sens = 0.0000
la:  None
>> Train a Model.
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:09<16:18,  9.88s/it]  2%|▏         | 2/100 [00:21<17:47, 10.89s/it]  3%|▎         | 3/100 [00:31<16:54, 10.45s/it]  4%|▍         | 4/100 [00:43<17:28, 10.92s/it]  5%|▌         | 5/100 [00:59<20:38, 13.04s/it]Epoch 5: Train acc/f1 = 0.8278 / 0.6357 / 0.7492 / 0.9643 
                Val acc/f1/spec/sens = 0.8100 / 0.6289 / 0.7037 / 0.9452
                Test acc/f1/spec/sens = 0.4672 / 0.3521 / 0.4750 / 0.8333
  6%|▌         | 6/100 [01:11<19:35, 12.51s/it]  7%|▋         | 7/100 [01:21<18:04, 11.66s/it]  8%|▊         | 8/100 [01:32<17:29, 11.41s/it]  9%|▉         | 9/100 [01:42<16:35, 10.94s/it] 10%|█         | 10/100 [02:01<20:08, 13.43s/it]Epoch 10: Train acc/f1 = 0.9756 / 0.9680 / 0.9807 / 0.9779 
                Val acc/f1/spec/sens = 0.8100 / 0.7084 / 0.8148 / 0.8630
                Test acc/f1/spec/sens = 0.4016 / 0.3691 / 0.5250 / 0.6667
 11%|█         | 11/100 [02:11<18:24, 12.41s/it] 12%|█▏        | 12/100 [02:21<17:30, 11.93s/it] 13%|█▎        | 13/100 [02:31<16:27, 11.35s/it] 14%|█▍        | 14/100 [02:42<16:03, 11.20s/it] 15%|█▌        | 15/100 [03:00<18:40, 13.18s/it]Epoch 15: Train acc/f1 = 0.9911 / 0.9880 / 0.9968 / 0.9915 
                Val acc/f1/spec/sens = 0.8000 / 0.6722 / 0.9259 / 0.8493
                Test acc/f1/spec/sens = 0.4016 / 0.3145 / 0.5000 / 0.6905
 16%|█▌        | 16/100 [03:11<17:31, 12.52s/it] 17%|█▋        | 17/100 [03:21<16:17, 11.77s/it] 18%|█▊        | 18/100 [03:32<15:49, 11.58s/it] 19%|█▉        | 19/100 [03:42<15:02, 11.14s/it] 20%|██        | 20/100 [04:02<18:04, 13.55s/it]Epoch 20: Train acc/f1 = 0.9900 / 0.9886 / 0.9743 / 1.0000 
                Val acc/f1/spec/sens = 0.7800 / 0.6444 / 0.7407 / 0.8767
                Test acc/f1/spec/sens = 0.3525 / 0.3058 / 0.3250 / 0.7381
 21%|██        | 21/100 [04:12<16:31, 12.55s/it] 22%|██▏       | 22/100 [04:23<15:50, 12.19s/it] 23%|██▎       | 23/100 [04:33<14:52, 11.59s/it] 24%|██▍       | 24/100 [04:44<14:32, 11.48s/it] 25%|██▌       | 25/100 [05:02<16:43, 13.38s/it]Epoch 25: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8000 / 0.6844 / 0.8148 / 0.8630
                Test acc/f1/spec/sens = 0.3197 / 0.2888 / 0.4500 / 0.5476
 26%|██▌       | 26/100 [05:14<15:49, 12.83s/it] 27%|██▋       | 27/100 [05:24<14:40, 12.06s/it] 28%|██▊       | 28/100 [05:35<14:06, 11.75s/it] 29%|██▉       | 29/100 [05:45<13:19, 11.25s/it] 30%|███       | 30/100 [06:04<15:48, 13.55s/it]Epoch 30: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8000 / 0.6844 / 0.8148 / 0.8630
                Test acc/f1/spec/sens = 0.3197 / 0.2898 / 0.4250 / 0.5952
 31%|███       | 31/100 [06:14<14:24, 12.53s/it] 32%|███▏      | 32/100 [06:25<13:42, 12.10s/it] 33%|███▎      | 33/100 [06:35<12:47, 11.46s/it] 34%|███▍      | 34/100 [06:46<12:25, 11.30s/it] 35%|███▌      | 35/100 [07:04<14:13, 13.12s/it]Epoch 35: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8000 / 0.6844 / 0.8148 / 0.8630
                Test acc/f1/spec/sens = 0.3197 / 0.2894 / 0.4125 / 0.5952
 36%|███▌      | 36/100 [07:15<13:19, 12.49s/it] 37%|███▋      | 37/100 [07:25<12:19, 11.74s/it] 38%|███▊      | 38/100 [07:36<11:53, 11.51s/it] 39%|███▉      | 39/100 [07:46<11:16, 11.08s/it] 40%|████      | 40/100 [08:04<13:16, 13.27s/it]Epoch 40: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8000 / 0.6844 / 0.8148 / 0.8630
                Test acc/f1/spec/sens = 0.3197 / 0.2894 / 0.4125 / 0.5952
 41%|████      | 41/100 [08:14<12:06, 12.31s/it] 42%|████▏     | 42/100 [08:25<11:33, 11.96s/it] 43%|████▎     | 43/100 [08:35<10:48, 11.37s/it] 44%|████▍     | 44/100 [08:46<10:30, 11.26s/it] 45%|████▌     | 45/100 [09:03<11:53, 12.97s/it]Epoch 45: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8000 / 0.6844 / 0.8148 / 0.8630
                Test acc/f1/spec/sens = 0.3197 / 0.2894 / 0.4125 / 0.5952
 46%|████▌     | 46/100 [09:15<11:12, 12.46s/it] 47%|████▋     | 47/100 [09:25<10:24, 11.78s/it] 48%|████▊     | 48/100 [09:36<10:05, 11.65s/it] 49%|████▉     | 49/100 [09:46<09:30, 11.19s/it] 50%|█████     | 50/100 [10:05<11:20, 13.61s/it]Epoch 50: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8000 / 0.6844 / 0.8148 / 0.8630
                Test acc/f1/spec/sens = 0.3197 / 0.2894 / 0.4125 / 0.5952
 51%|█████     | 51/100 [10:16<10:18, 12.61s/it] 52%|█████▏    | 52/100 [10:27<09:46, 12.21s/it] 53%|█████▎    | 53/100 [10:37<09:05, 11.62s/it] 54%|█████▍    | 54/100 [10:48<08:47, 11.47s/it] 55%|█████▌    | 55/100 [11:06<09:56, 13.25s/it]Epoch 55: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8000 / 0.6844 / 0.8148 / 0.8630
                Test acc/f1/spec/sens = 0.3197 / 0.2894 / 0.4125 / 0.5952
 56%|█████▌    | 56/100 [11:17<09:14, 12.59s/it] 57%|█████▋    | 57/100 [11:27<08:29, 11.84s/it] 58%|█████▊    | 58/100 [11:38<08:07, 11.60s/it] 59%|█████▉    | 59/100 [11:48<07:35, 11.12s/it] 60%|██████    | 60/100 [12:06<08:51, 13.28s/it]Epoch 60: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8000 / 0.6844 / 0.8148 / 0.8630
                Test acc/f1/spec/sens = 0.3197 / 0.2890 / 0.4000 / 0.5952
 61%|██████    | 61/100 [12:16<07:59, 12.30s/it] 62%|██████▏   | 62/100 [12:27<07:33, 11.92s/it] 63%|██████▎   | 63/100 [12:37<07:00, 11.36s/it] 64%|██████▍   | 64/100 [12:48<06:45, 11.26s/it] 65%|██████▌   | 65/100 [13:05<07:34, 12.99s/it]Epoch 65: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8000 / 0.6844 / 0.8148 / 0.8630
                Test acc/f1/spec/sens = 0.3197 / 0.2890 / 0.4000 / 0.5952
 66%|██████▌   | 66/100 [13:17<07:02, 12.41s/it] 67%|██████▋   | 67/100 [13:27<06:26, 11.70s/it] 68%|██████▊   | 68/100 [13:38<06:08, 11.52s/it] 69%|██████▉   | 69/100 [13:48<05:43, 11.08s/it] 70%|███████   | 70/100 [14:06<06:35, 13.20s/it]Epoch 70: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8000 / 0.6844 / 0.8148 / 0.8630
                Test acc/f1/spec/sens = 0.3197 / 0.2890 / 0.4000 / 0.5952
 71%|███████   | 71/100 [14:16<05:55, 12.27s/it] 72%|███████▏  | 72/100 [14:27<05:33, 11.92s/it] 73%|███████▎  | 73/100 [14:37<05:06, 11.35s/it] 74%|███████▍  | 74/100 [14:48<04:52, 11.24s/it] 75%|███████▌  | 75/100 [15:05<05:26, 13.05s/it]Epoch 75: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8000 / 0.6844 / 0.8148 / 0.8630
                Test acc/f1/spec/sens = 0.3197 / 0.2890 / 0.4000 / 0.5952
 76%|███████▌  | 76/100 [15:16<04:58, 12.43s/it] 77%|███████▋  | 77/100 [15:26<04:29, 11.71s/it] 78%|███████▊  | 78/100 [15:37<04:13, 11.53s/it] 79%|███████▉  | 79/100 [15:48<03:52, 11.09s/it] 80%|████████  | 80/100 [16:05<04:22, 13.13s/it]Epoch 80: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8000 / 0.6844 / 0.8148 / 0.8630
                Test acc/f1/spec/sens = 0.3197 / 0.2890 / 0.4000 / 0.5952
 81%|████████  | 81/100 [16:15<03:51, 12.20s/it] 82%|████████▏ | 82/100 [16:27<03:33, 11.86s/it] 83%|████████▎ | 83/100 [16:36<03:12, 11.29s/it] 84%|████████▍ | 84/100 [16:48<03:00, 11.26s/it] 85%|████████▌ | 85/100 [17:05<03:17, 13.17s/it]Epoch 85: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8000 / 0.6844 / 0.8148 / 0.8630
                Test acc/f1/spec/sens = 0.3197 / 0.2890 / 0.4000 / 0.5952
 86%|████████▌ | 86/100 [17:16<02:55, 12.53s/it] 87%|████████▋ | 87/100 [17:26<02:33, 11.79s/it] 88%|████████▊ | 88/100 [17:38<02:19, 11.62s/it] 89%|████████▉ | 89/100 [17:48<02:02, 11.16s/it] 90%|█████████ | 90/100 [18:06<02:13, 13.33s/it]Epoch 90: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8000 / 0.6844 / 0.8148 / 0.8630
                Test acc/f1/spec/sens = 0.3197 / 0.2890 / 0.4000 / 0.5952
 91%|█████████ | 91/100 [18:16<01:51, 12.34s/it] 92%|█████████▏| 92/100 [18:27<01:35, 11.97s/it] 93%|█████████▎| 93/100 [18:37<01:19, 11.42s/it] 94%|█████████▍| 94/100 [18:49<01:08, 11.35s/it] 95%|█████████▌| 95/100 [19:06<01:06, 13.23s/it]Epoch 95: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8000 / 0.6844 / 0.8148 / 0.8630
                Test acc/f1/spec/sens = 0.3197 / 0.2890 / 0.4000 / 0.5952
 96%|█████████▌| 96/100 [19:17<00:50, 12.62s/it] 97%|█████████▋| 97/100 [19:27<00:35, 11.86s/it] 98%|█████████▊| 98/100 [19:39<00:23, 11.62s/it] 99%|█████████▉| 99/100 [19:49<00:11, 11.18s/it]100%|██████████| 100/100 [20:07<00:00, 13.33s/it]                                                 Epoch 100: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8000 / 0.6844 / 0.8148 / 0.8630
                Test acc/f1/spec/sens = 0.3197 / 0.2890 / 0.4000 / 0.5952
specificity = 311/311
sensitivity = 589/589
specificity = 22/27
sensitivity = 63/73
specificity = 32/80
sensitivity = 25/42
Trial 1, Cycle 1
Train acc/f1/spec/sens = 1.0000 / 1.0000 / 1.0000 / 1.0000
Val acc/f1/spec/sens = 0.8000 / 0.6844 / 0.8148 / 0.8630
Test acc/f1/spec/sens = 0.3197 / 0.2890 / 0.4000 / 0.5952
>> Finished.
specificity = 32/80
sensitivity = 25/42
Acc, agreement for latest model:  0.319672131147541 0.36885245901639346
Load best checkpoint for thief model
specificity = 42/80
sensitivity = 28/42
Acc, agreement for best model:  0.4016393442622951 0.3770491803278688
Trial 0/5 || Cycle 1/1 || Label set size 900 || Test acc 0.4016 || Test agreement 0.3770 || Spec 0.5250 || Sens 0.6667
**************************************************************************************************** 

specificity = 42/80
sensitivity = 28/42
Number of samples  900
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
replacing labeled set labels with victim labels
  0%|          | 0/57 [00:00<?, ?it/s]  2%|▏         | 1/57 [00:01<00:56,  1.00s/it]  4%|▎         | 2/57 [00:01<00:34,  1.59it/s]  5%|▌         | 3/57 [00:01<00:25,  2.12it/s]  7%|▋         | 4/57 [00:01<00:20,  2.54it/s]  9%|▉         | 5/57 [00:02<00:18,  2.88it/s] 11%|█         | 6/57 [00:02<00:16,  3.13it/s] 12%|█▏        | 7/57 [00:02<00:14,  3.48it/s] 14%|█▍        | 8/57 [00:02<00:12,  3.83it/s] 16%|█▌        | 9/57 [00:03<00:12,  3.97it/s] 18%|█▊        | 10/57 [00:03<00:11,  4.20it/s] 19%|█▉        | 11/57 [00:03<00:11,  4.12it/s] 21%|██        | 12/57 [00:03<00:10,  4.20it/s] 23%|██▎       | 13/57 [00:04<00:11,  3.97it/s] 25%|██▍       | 14/57 [00:04<00:10,  3.95it/s] 26%|██▋       | 15/57 [00:04<00:10,  3.92it/s] 28%|██▊       | 16/57 [00:04<00:10,  3.88it/s] 30%|██▉       | 17/57 [00:05<00:10,  3.88it/s] 32%|███▏      | 18/57 [00:05<00:10,  3.86it/s] 33%|███▎      | 19/57 [00:05<00:09,  3.83it/s] 35%|███▌      | 20/57 [00:05<00:09,  3.88it/s] 37%|███▋      | 21/57 [00:06<00:09,  3.91it/s] 39%|███▊      | 22/57 [00:06<00:08,  4.18it/s] 40%|████      | 23/57 [00:06<00:07,  4.41it/s] 42%|████▏     | 24/57 [00:06<00:07,  4.14it/s] 44%|████▍     | 25/57 [00:07<00:07,  4.06it/s] 46%|████▌     | 26/57 [00:07<00:07,  4.27it/s] 47%|████▋     | 27/57 [00:07<00:06,  4.48it/s] 49%|████▉     | 28/57 [00:07<00:06,  4.62it/s] 51%|█████     | 29/57 [00:07<00:05,  4.73it/s] 53%|█████▎    | 30/57 [00:08<00:05,  4.83it/s] 54%|█████▍    | 31/57 [00:08<00:05,  4.90it/s] 56%|█████▌    | 32/57 [00:08<00:05,  4.96it/s] 58%|█████▊    | 33/57 [00:08<00:04,  5.00it/s] 60%|█████▉    | 34/57 [00:08<00:04,  4.96it/s] 61%|██████▏   | 35/57 [00:09<00:04,  5.00it/s] 63%|██████▎   | 36/57 [00:09<00:04,  4.99it/s] 65%|██████▍   | 37/57 [00:09<00:04,  4.78it/s] 67%|██████▋   | 38/57 [00:09<00:03,  4.87it/s] 68%|██████▊   | 39/57 [00:09<00:03,  4.81it/s] 70%|███████   | 40/57 [00:10<00:03,  4.85it/s] 72%|███████▏  | 41/57 [00:10<00:03,  4.68it/s] 74%|███████▎  | 42/57 [00:10<00:03,  4.49it/s] 75%|███████▌  | 43/57 [00:10<00:03,  4.61it/s] 77%|███████▋  | 44/57 [00:10<00:02,  4.74it/s] 79%|███████▉  | 45/57 [00:11<00:02,  4.57it/s] 81%|████████  | 46/57 [00:11<00:02,  4.50it/s] 82%|████████▏ | 47/57 [00:11<00:02,  4.35it/s] 84%|████████▍ | 48/57 [00:11<00:02,  4.11it/s] 86%|████████▌ | 49/57 [00:12<00:01,  4.18it/s] 88%|████████▊ | 50/57 [00:12<00:01,  4.40it/s] 89%|████████▉ | 51/57 [00:12<00:01,  4.24it/s] 91%|█████████ | 52/57 [00:12<00:01,  4.32it/s] 93%|█████████▎| 53/57 [00:13<00:00,  4.54it/s] 95%|█████████▍| 54/57 [00:13<00:00,  4.31it/s] 96%|█████████▋| 55/57 [00:13<00:00,  4.42it/s] 98%|█████████▊| 56/57 [00:13<00:00,  4.54it/s]100%|██████████| 57/57 [00:13<00:00,  4.08it/s]
replacing val labels with victim labels
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:00<00:04,  1.49it/s] 29%|██▊       | 2/7 [00:00<00:02,  2.47it/s] 43%|████▎     | 3/7 [00:01<00:01,  3.11it/s] 57%|█████▋    | 4/7 [00:01<00:00,  3.56it/s] 71%|███████▏  | 5/7 [00:01<00:00,  3.87it/s] 86%|████████▌ | 6/7 [00:01<00:00,  4.15it/s]100%|██████████| 7/7 [00:01<00:00,  3.68it/s]Validation set distribution: 
Number of samples  100

{0: 16, 1: 21, 2: 63}
Labeled set distribution: 
Number of samples  900
{0: 102, 1: 220, 2: 578}
odict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias', 'heads.head.weight', 'heads.head.bias'])
thief state:  None
pretrained state:  dict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias'])
Thief model initialized successfully
specificity = 80/80
sensitivity = 0/42
Initial model on target dataset: acc = 0.2541, agreement = 0.2377, f1 = 0.1351, spec = 1.0000, sens = 0.0000
specificity = 37/37
sensitivity = 0/63
Initial model on validation dataset: acc = 0.1600, agreement = 0.1600, f1 = 0.0920, spec = 1.0000, sens = 0.0000
la:  None
>> Train a Model.
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:09<16:20,  9.91s/it]  2%|▏         | 2/100 [00:21<17:43, 10.85s/it]  3%|▎         | 3/100 [00:31<16:55, 10.47s/it]  4%|▍         | 4/100 [00:42<17:04, 10.67s/it]  5%|▌         | 5/100 [01:00<21:14, 13.41s/it]Epoch 5: Train acc/f1 = 0.8633 / 0.7862 / 0.9658 / 0.9308 
                Val acc/f1/spec/sens = 0.7300 / 0.6028 / 0.8378 / 0.8571
                Test acc/f1/spec/sens = 0.4508 / 0.4297 / 0.7500 / 0.4286
  6%|▌         | 6/100 [01:12<20:19, 12.97s/it]  7%|▋         | 7/100 [01:22<18:34, 11.99s/it]  8%|▊         | 8/100 [01:33<17:53, 11.66s/it]  9%|▉         | 9/100 [01:43<16:56, 11.17s/it] 10%|█         | 10/100 [02:02<20:10, 13.45s/it]Epoch 10: Train acc/f1 = 0.9078 / 0.8102 / 0.9783 / 0.9619 
                Val acc/f1/spec/sens = 0.7200 / 0.5138 / 0.7297 / 0.8889
                Test acc/f1/spec/sens = 0.4016 / 0.2994 / 0.6125 / 0.4048
 11%|█         | 11/100 [02:12<18:24, 12.41s/it] 12%|█▏        | 12/100 [02:23<17:35, 12.00s/it] 13%|█▎        | 13/100 [02:33<16:32, 11.41s/it] 14%|█▍        | 14/100 [02:45<16:35, 11.57s/it] 15%|█▌        | 15/100 [03:03<19:02, 13.44s/it]Epoch 15: Train acc/f1 = 0.9578 / 0.9300 / 0.8851 / 0.9983 
                Val acc/f1/spec/sens = 0.8000 / 0.7182 / 0.8108 / 0.9048
                Test acc/f1/spec/sens = 0.3770 / 0.2582 / 0.2125 / 0.8810
 16%|█▌        | 16/100 [03:14<17:50, 12.75s/it] 17%|█▋        | 17/100 [03:24<16:30, 11.94s/it] 18%|█▊        | 18/100 [03:36<16:16, 11.90s/it] 19%|█▉        | 19/100 [03:46<15:17, 11.33s/it] 20%|██        | 20/100 [04:04<17:54, 13.43s/it]Epoch 20: Train acc/f1 = 0.9911 / 0.9867 / 1.0000 / 0.9913 
                Val acc/f1/spec/sens = 0.7800 / 0.7135 / 0.7838 / 0.8730
                Test acc/f1/spec/sens = 0.3607 / 0.3064 / 0.4750 / 0.4524
 21%|██        | 21/100 [04:14<16:22, 12.43s/it] 22%|██▏       | 22/100 [04:25<15:40, 12.06s/it] 23%|██▎       | 23/100 [04:36<14:43, 11.48s/it] 24%|██▍       | 24/100 [04:47<14:28, 11.43s/it] 25%|██▌       | 25/100 [05:06<17:02, 13.63s/it]Epoch 25: Train acc/f1 = 0.9989 / 0.9990 / 1.0000 / 0.9983 
                Val acc/f1/spec/sens = 0.7900 / 0.7072 / 0.7297 / 0.9206
                Test acc/f1/spec/sens = 0.3770 / 0.3362 / 0.3500 / 0.6429
 26%|██▌       | 26/100 [05:17<16:02, 13.01s/it] 27%|██▋       | 27/100 [05:27<14:49, 12.19s/it] 28%|██▊       | 28/100 [05:40<14:38, 12.20s/it] 29%|██▉       | 29/100 [05:50<13:53, 11.75s/it] 30%|███       | 30/100 [06:09<16:14, 13.93s/it]Epoch 30: Train acc/f1 = 0.9989 / 0.9990 / 1.0000 / 0.9983 
                Val acc/f1/spec/sens = 0.8100 / 0.7298 / 0.7568 / 0.9365
                Test acc/f1/spec/sens = 0.3770 / 0.3360 / 0.3625 / 0.6429
 31%|███       | 31/100 [06:19<14:41, 12.78s/it] 32%|███▏      | 32/100 [06:31<13:56, 12.30s/it] 33%|███▎      | 33/100 [06:41<12:59, 11.63s/it] 34%|███▍      | 34/100 [06:52<12:37, 11.48s/it] 35%|███▌      | 35/100 [07:09<14:23, 13.29s/it]Epoch 35: Train acc/f1 = 0.9989 / 0.9990 / 1.0000 / 0.9983 
                Val acc/f1/spec/sens = 0.8100 / 0.7298 / 0.7568 / 0.9365
                Test acc/f1/spec/sens = 0.3770 / 0.3360 / 0.3625 / 0.6429
 36%|███▌      | 36/100 [07:20<13:27, 12.62s/it] 37%|███▋      | 37/100 [07:30<12:26, 11.84s/it] 38%|███▊      | 38/100 [07:42<12:02, 11.66s/it] 39%|███▉      | 39/100 [07:52<11:23, 11.21s/it] 40%|████      | 40/100 [08:11<13:43, 13.72s/it]Epoch 40: Train acc/f1 = 0.9989 / 0.9990 / 1.0000 / 0.9983 
                Val acc/f1/spec/sens = 0.8200 / 0.7498 / 0.7568 / 0.9365
                Test acc/f1/spec/sens = 0.3689 / 0.3303 / 0.3625 / 0.6190
 41%|████      | 41/100 [08:21<12:24, 12.62s/it] 42%|████▏     | 42/100 [08:33<11:45, 12.16s/it] 43%|████▎     | 43/100 [08:43<10:56, 11.52s/it] 44%|████▍     | 44/100 [08:54<10:37, 11.39s/it] 45%|████▌     | 45/100 [09:11<11:57, 13.05s/it]Epoch 45: Train acc/f1 = 0.9989 / 0.9990 / 1.0000 / 0.9983 
                Val acc/f1/spec/sens = 0.8200 / 0.7498 / 0.7568 / 0.9365
                Test acc/f1/spec/sens = 0.3689 / 0.3303 / 0.3625 / 0.6190
 46%|████▌     | 46/100 [09:22<11:15, 12.51s/it] 47%|████▋     | 47/100 [09:32<10:25, 11.79s/it] 48%|████▊     | 48/100 [09:43<10:04, 11.63s/it] 49%|████▉     | 49/100 [09:53<09:30, 11.19s/it] 50%|█████     | 50/100 [10:13<11:30, 13.80s/it]Epoch 50: Train acc/f1 = 0.9989 / 0.9990 / 1.0000 / 0.9983 
                Val acc/f1/spec/sens = 0.8200 / 0.7498 / 0.7568 / 0.9365
                Test acc/f1/spec/sens = 0.3607 / 0.3246 / 0.3625 / 0.5952
 51%|█████     | 51/100 [10:24<10:24, 12.74s/it] 52%|█████▏    | 52/100 [10:35<09:50, 12.30s/it] 53%|█████▎    | 53/100 [10:45<09:07, 11.65s/it] 54%|█████▍    | 54/100 [10:56<08:50, 11.54s/it] 55%|█████▌    | 55/100 [11:14<09:57, 13.28s/it]Epoch 55: Train acc/f1 = 0.9989 / 0.9990 / 1.0000 / 0.9983 
                Val acc/f1/spec/sens = 0.8200 / 0.7498 / 0.7568 / 0.9365
                Test acc/f1/spec/sens = 0.3607 / 0.3246 / 0.3625 / 0.5952
 56%|█████▌    | 56/100 [11:25<09:14, 12.61s/it] 57%|█████▋    | 57/100 [11:35<08:29, 11.86s/it] 58%|█████▊    | 58/100 [11:46<08:10, 11.67s/it] 59%|█████▉    | 59/100 [11:56<07:39, 11.20s/it] 60%|██████    | 60/100 [12:15<08:55, 13.39s/it]Epoch 60: Train acc/f1 = 0.9989 / 0.9990 / 1.0000 / 0.9983 
                Val acc/f1/spec/sens = 0.8200 / 0.7498 / 0.7568 / 0.9365
                Test acc/f1/spec/sens = 0.3607 / 0.3246 / 0.3625 / 0.5952
 61%|██████    | 61/100 [12:25<08:04, 12.43s/it] 62%|██████▏   | 62/100 [12:36<07:37, 12.03s/it] 63%|██████▎   | 63/100 [12:46<07:05, 11.50s/it] 64%|██████▍   | 64/100 [12:57<06:48, 11.36s/it] 65%|██████▌   | 65/100 [13:14<07:40, 13.17s/it]Epoch 65: Train acc/f1 = 0.9989 / 0.9990 / 1.0000 / 0.9983 
                Val acc/f1/spec/sens = 0.8200 / 0.7498 / 0.7568 / 0.9365
                Test acc/f1/spec/sens = 0.3607 / 0.3246 / 0.3625 / 0.5952
 66%|██████▌   | 66/100 [13:26<07:06, 12.54s/it] 67%|██████▋   | 67/100 [13:36<06:29, 11.80s/it] 68%|██████▊   | 68/100 [13:47<06:10, 11.58s/it] 69%|██████▉   | 69/100 [13:57<05:45, 11.13s/it] 70%|███████   | 70/100 [14:15<06:40, 13.34s/it]Epoch 70: Train acc/f1 = 0.9989 / 0.9990 / 1.0000 / 0.9983 
                Val acc/f1/spec/sens = 0.8200 / 0.7498 / 0.7568 / 0.9365
                Test acc/f1/spec/sens = 0.3607 / 0.3246 / 0.3625 / 0.5952
 71%|███████   | 71/100 [14:25<05:58, 12.36s/it] 72%|███████▏  | 72/100 [14:36<05:35, 11.97s/it] 73%|███████▎  | 73/100 [14:46<05:07, 11.39s/it] 74%|███████▍  | 74/100 [14:57<04:53, 11.27s/it] 75%|███████▌  | 75/100 [15:15<05:30, 13.23s/it]Epoch 75: Train acc/f1 = 0.9989 / 0.9990 / 1.0000 / 0.9983 
                Val acc/f1/spec/sens = 0.8200 / 0.7498 / 0.7568 / 0.9365
                Test acc/f1/spec/sens = 0.3607 / 0.3246 / 0.3625 / 0.5952
 76%|███████▌  | 76/100 [15:26<05:02, 12.58s/it] 77%|███████▋  | 77/100 [15:36<04:31, 11.82s/it] 78%|███████▊  | 78/100 [15:47<04:15, 11.61s/it] 79%|███████▉  | 79/100 [15:58<03:54, 11.15s/it] 80%|████████  | 80/100 [16:17<04:31, 13.56s/it]Epoch 80: Train acc/f1 = 0.9989 / 0.9990 / 1.0000 / 0.9983 
                Val acc/f1/spec/sens = 0.8200 / 0.7498 / 0.7568 / 0.9365
                Test acc/f1/spec/sens = 0.3607 / 0.3246 / 0.3625 / 0.5952
 81%|████████  | 81/100 [16:27<03:57, 12.51s/it] 82%|████████▏ | 82/100 [16:38<03:37, 12.08s/it] 83%|████████▎ | 83/100 [16:48<03:15, 11.47s/it] 84%|████████▍ | 84/100 [16:59<03:01, 11.36s/it] 85%|████████▌ | 85/100 [17:17<03:19, 13.32s/it]Epoch 85: Train acc/f1 = 0.9989 / 0.9990 / 1.0000 / 0.9983 
                Val acc/f1/spec/sens = 0.8200 / 0.7498 / 0.7568 / 0.9365
                Test acc/f1/spec/sens = 0.3607 / 0.3246 / 0.3625 / 0.5952
 86%|████████▌ | 86/100 [17:28<02:57, 12.67s/it] 87%|████████▋ | 87/100 [17:38<02:34, 11.90s/it] 88%|████████▊ | 88/100 [17:49<02:19, 11.65s/it] 89%|████████▉ | 89/100 [17:59<02:03, 11.20s/it] 90%|█████████ | 90/100 [18:18<02:15, 13.53s/it]Epoch 90: Train acc/f1 = 0.9989 / 0.9990 / 1.0000 / 0.9983 
                Val acc/f1/spec/sens = 0.8200 / 0.7498 / 0.7568 / 0.9365
                Test acc/f1/spec/sens = 0.3607 / 0.3246 / 0.3625 / 0.5952
 91%|█████████ | 91/100 [18:28<01:52, 12.51s/it] 92%|█████████▏| 92/100 [18:40<01:36, 12.08s/it] 93%|█████████▎| 93/100 [18:50<01:20, 11.49s/it] 94%|█████████▍| 94/100 [19:01<01:08, 11.38s/it] 95%|█████████▌| 95/100 [19:19<01:06, 13.35s/it]Epoch 95: Train acc/f1 = 0.9989 / 0.9990 / 1.0000 / 0.9983 
                Val acc/f1/spec/sens = 0.8200 / 0.7498 / 0.7568 / 0.9365
                Test acc/f1/spec/sens = 0.3607 / 0.3246 / 0.3625 / 0.5952
 96%|█████████▌| 96/100 [19:30<00:50, 12.70s/it] 97%|█████████▋| 97/100 [19:40<00:35, 11.92s/it] 98%|█████████▊| 98/100 [19:51<00:23, 11.67s/it] 99%|█████████▉| 99/100 [20:01<00:11, 11.19s/it]100%|██████████| 100/100 [20:20<00:00, 13.55s/it]                                                 Epoch 100: Train acc/f1 = 0.9989 / 0.9990 / 1.0000 / 0.9983 
                Val acc/f1/spec/sens = 0.8200 / 0.7498 / 0.7568 / 0.9365
                Test acc/f1/spec/sens = 0.3607 / 0.3246 / 0.3625 / 0.5952
specificity = 322/322
sensitivity = 577/578
specificity = 28/37
sensitivity = 59/63
specificity = 29/80
sensitivity = 25/42
Trial 2, Cycle 1
Train acc/f1/spec/sens = 0.9989 / 0.9990 / 1.0000 / 0.9983
Val acc/f1/spec/sens = 0.8200 / 0.7498 / 0.7568 / 0.9365
Test acc/f1/spec/sens = 0.3607 / 0.3246 / 0.3625 / 0.5952
>> Finished.
specificity = 29/80
sensitivity = 25/42
Acc, agreement for latest model:  0.36065573770491804 0.4016393442622951
Load best checkpoint for thief model
specificity = 29/80
sensitivity = 26/42
Acc, agreement for best model:  0.36885245901639346 0.4098360655737705
Trial 1/5 || Cycle 1/1 || Label set size 900 || Test acc 0.3689 || Test agreement 0.4098 || Spec 0.3625 || Sens 0.6190
**************************************************************************************************** 

specificity = 29/80
sensitivity = 26/42
Number of samples  900
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
replacing labeled set labels with victim labels
  0%|          | 0/57 [00:00<?, ?it/s]  2%|▏         | 1/57 [00:00<00:39,  1.42it/s]  4%|▎         | 2/57 [00:00<00:24,  2.23it/s]  5%|▌         | 3/57 [00:01<00:20,  2.59it/s]  7%|▋         | 4/57 [00:01<00:18,  2.84it/s]  9%|▉         | 5/57 [00:01<00:16,  3.10it/s] 11%|█         | 6/57 [00:02<00:15,  3.27it/s] 12%|█▏        | 7/57 [00:02<00:14,  3.44it/s] 14%|█▍        | 8/57 [00:02<00:13,  3.53it/s] 16%|█▌        | 9/57 [00:02<00:13,  3.61it/s] 18%|█▊        | 10/57 [00:03<00:12,  3.65it/s] 19%|█▉        | 11/57 [00:03<00:12,  3.65it/s] 21%|██        | 12/57 [00:03<00:12,  3.73it/s] 23%|██▎       | 13/57 [00:03<00:11,  3.77it/s] 25%|██▍       | 14/57 [00:04<00:11,  3.80it/s] 26%|██▋       | 15/57 [00:04<00:11,  3.82it/s] 28%|██▊       | 16/57 [00:04<00:10,  3.81it/s] 30%|██▉       | 17/57 [00:05<00:10,  3.75it/s] 32%|███▏      | 18/57 [00:05<00:10,  3.77it/s] 33%|███▎      | 19/57 [00:05<00:10,  3.73it/s] 35%|███▌      | 20/57 [00:05<00:10,  3.70it/s] 37%|███▋      | 21/57 [00:06<00:09,  3.93it/s] 39%|███▊      | 22/57 [00:06<00:08,  3.98it/s] 40%|████      | 23/57 [00:06<00:08,  4.01it/s] 42%|████▏     | 24/57 [00:06<00:08,  4.03it/s] 44%|████▍     | 25/57 [00:06<00:07,  4.25it/s] 46%|████▌     | 26/57 [00:07<00:07,  4.41it/s] 47%|████▋     | 27/57 [00:07<00:06,  4.46it/s] 49%|████▉     | 28/57 [00:07<00:06,  4.41it/s] 51%|█████     | 29/57 [00:07<00:06,  4.39it/s] 53%|█████▎    | 30/57 [00:08<00:05,  4.54it/s] 54%|█████▍    | 31/57 [00:08<00:05,  4.46it/s] 56%|█████▌    | 32/57 [00:08<00:05,  4.29it/s] 58%|█████▊    | 33/57 [00:08<00:05,  4.09it/s] 60%|█████▉    | 34/57 [00:09<00:05,  4.01it/s] 61%|██████▏   | 35/57 [00:09<00:05,  3.99it/s] 63%|██████▎   | 36/57 [00:09<00:05,  3.98it/s] 65%|██████▍   | 37/57 [00:09<00:05,  3.97it/s] 67%|██████▋   | 38/57 [00:10<00:04,  3.95it/s] 68%|██████▊   | 39/57 [00:10<00:04,  3.94it/s] 70%|███████   | 40/57 [00:10<00:04,  3.92it/s] 72%|███████▏  | 41/57 [00:10<00:04,  3.94it/s] 74%|███████▎  | 42/57 [00:11<00:03,  4.14it/s] 75%|███████▌  | 43/57 [00:11<00:03,  4.14it/s] 77%|███████▋  | 44/57 [00:11<00:03,  3.73it/s] 79%|███████▉  | 45/57 [00:12<00:03,  3.47it/s] 81%|████████  | 46/57 [00:12<00:03,  3.60it/s] 82%|████████▏ | 47/57 [00:12<00:02,  3.57it/s] 84%|████████▍ | 48/57 [00:12<00:02,  3.44it/s] 86%|████████▌ | 49/57 [00:13<00:02,  3.51it/s] 88%|████████▊ | 50/57 [00:13<00:01,  3.58it/s] 89%|████████▉ | 51/57 [00:13<00:01,  3.62it/s] 91%|█████████ | 52/57 [00:13<00:01,  3.67it/s] 93%|█████████▎| 53/57 [00:14<00:01,  3.91it/s] 95%|█████████▍| 54/57 [00:14<00:00,  4.15it/s] 96%|█████████▋| 55/57 [00:14<00:00,  4.24it/s] 98%|█████████▊| 56/57 [00:14<00:00,  4.45it/s]100%|██████████| 57/57 [00:14<00:00,  3.80it/s]
replacing val labels with victim labels
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:00<00:04,  1.34it/s] 29%|██▊       | 2/7 [00:01<00:02,  2.13it/s] 43%|████▎     | 3/7 [00:01<00:01,  2.68it/s] 57%|█████▋    | 4/7 [00:01<00:00,  3.02it/s] 71%|███████▏  | 5/7 [00:01<00:00,  3.22it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.36it/s]100%|██████████| 7/7 [00:02<00:00,  2.95it/s]Validation set distribution: 
Number of samples  100

{0: 13, 1: 19, 2: 68}
Labeled set distribution: 
Number of samples  900
{0: 98, 1: 215, 2: 587}
odict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias', 'heads.head.weight', 'heads.head.bias'])
thief state:  None
pretrained state:  dict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias'])
Thief model initialized successfully
specificity = 80/80
sensitivity = 0/42
Initial model on target dataset: acc = 0.2541, agreement = 0.2377, f1 = 0.1351, spec = 1.0000, sens = 0.0000
specificity = 32/32
sensitivity = 0/68
Initial model on validation dataset: acc = 0.1300, agreement = 0.1300, f1 = 0.0767, spec = 1.0000, sens = 0.0000
la:  None
>> Train a Model.
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:09<16:24,  9.94s/it]  2%|▏         | 2/100 [00:21<17:47, 10.90s/it]  3%|▎         | 3/100 [00:31<16:56, 10.48s/it]  4%|▍         | 4/100 [00:42<17:17, 10.80s/it]  5%|▌         | 5/100 [01:00<20:55, 13.21s/it]Epoch 5: Train acc/f1 = 0.7967 / 0.6871 / 0.5016 / 0.9898 
                Val acc/f1/spec/sens = 0.7000 / 0.4058 / 0.2812 / 0.9706
                Test acc/f1/spec/sens = 0.3607 / 0.2362 / 0.1125 / 0.9524
  6%|▌         | 6/100 [01:12<19:58, 12.75s/it]  7%|▋         | 7/100 [01:22<18:24, 11.87s/it]  8%|▊         | 8/100 [01:33<17:51, 11.65s/it]  9%|▉         | 9/100 [01:43<16:56, 11.16s/it] 10%|█         | 10/100 [02:02<20:20, 13.56s/it]Epoch 10: Train acc/f1 = 0.9556 / 0.9295 / 0.9489 / 0.9830 
                Val acc/f1/spec/sens = 0.7500 / 0.6364 / 0.6875 / 0.8676
                Test acc/f1/spec/sens = 0.3852 / 0.3307 / 0.3750 / 0.7857
 11%|█         | 11/100 [02:12<18:34, 12.52s/it] 12%|█▏        | 12/100 [02:23<17:43, 12.08s/it] 13%|█▎        | 13/100 [02:33<16:36, 11.45s/it] 14%|█▍        | 14/100 [02:44<16:15, 11.35s/it] 15%|█▌        | 15/100 [03:02<18:38, 13.16s/it]Epoch 15: Train acc/f1 = 0.9544 / 0.9461 / 0.9968 / 0.9455 
                Val acc/f1/spec/sens = 0.7500 / 0.5319 / 0.4375 / 0.9559
                Test acc/f1/spec/sens = 0.4344 / 0.3832 / 0.7250 / 0.6190
 16%|█▌        | 16/100 [03:13<17:32, 12.53s/it] 17%|█▋        | 17/100 [03:23<16:19, 11.80s/it] 18%|█▊        | 18/100 [03:34<15:50, 11.59s/it] 19%|█▉        | 19/100 [03:44<15:01, 11.13s/it] 20%|██        | 20/100 [04:03<17:57, 13.47s/it]Epoch 20: Train acc/f1 = 0.9933 / 0.9908 / 1.0000 / 0.9932 
                Val acc/f1/spec/sens = 0.7900 / 0.6492 / 0.6562 / 0.9412
                Test acc/f1/spec/sens = 0.3934 / 0.2982 / 0.3250 / 0.9048
 21%|██        | 21/100 [04:13<16:24, 12.46s/it] 22%|██▏       | 22/100 [04:24<15:40, 12.06s/it] 23%|██▎       | 23/100 [04:34<14:43, 11.47s/it] 24%|██▍       | 24/100 [04:46<14:37, 11.55s/it] 25%|██▌       | 25/100 [05:07<17:52, 14.30s/it]Epoch 25: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.7700 / 0.6158 / 0.5625 / 0.9412
                Test acc/f1/spec/sens = 0.4180 / 0.3307 / 0.3375 / 0.9524
 26%|██▌       | 26/100 [05:18<16:40, 13.52s/it] 27%|██▋       | 27/100 [05:29<15:19, 12.59s/it] 28%|██▊       | 28/100 [05:40<14:48, 12.34s/it] 29%|██▉       | 29/100 [05:51<13:57, 11.79s/it] 30%|███       | 30/100 [06:10<16:13, 13.91s/it]Epoch 30: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.7700 / 0.6158 / 0.5625 / 0.9412
                Test acc/f1/spec/sens = 0.4262 / 0.3462 / 0.3500 / 0.9524
 31%|███       | 31/100 [06:20<14:41, 12.78s/it] 32%|███▏      | 32/100 [06:31<13:56, 12.31s/it] 33%|███▎      | 33/100 [06:41<13:00, 11.65s/it] 34%|███▍      | 34/100 [06:52<12:38, 11.50s/it] 35%|███▌      | 35/100 [07:10<14:21, 13.26s/it]Epoch 35: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.7800 / 0.6323 / 0.5938 / 0.9412
                Test acc/f1/spec/sens = 0.4344 / 0.3611 / 0.3625 / 0.9524
 36%|███▌      | 36/100 [07:21<13:26, 12.61s/it] 37%|███▋      | 37/100 [07:31<12:26, 11.85s/it] 38%|███▊      | 38/100 [07:42<12:01, 11.63s/it] 39%|███▉      | 39/100 [07:52<11:21, 11.18s/it] 40%|████      | 40/100 [08:10<13:10, 13.17s/it]Epoch 40: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.7900 / 0.6481 / 0.6250 / 0.9412
                Test acc/f1/spec/sens = 0.4344 / 0.3611 / 0.3625 / 0.9524
 41%|████      | 41/100 [08:20<12:02, 12.24s/it] 42%|████▏     | 42/100 [08:31<11:29, 11.88s/it] 43%|████▎     | 43/100 [08:41<10:45, 11.33s/it] 44%|████▍     | 44/100 [08:52<10:30, 11.26s/it] 45%|████▌     | 45/100 [09:10<12:00, 13.10s/it]Epoch 45: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.7900 / 0.6481 / 0.6250 / 0.9412
                Test acc/f1/spec/sens = 0.4344 / 0.3611 / 0.3625 / 0.9524
 46%|████▌     | 46/100 [09:21<11:14, 12.49s/it] 47%|████▋     | 47/100 [09:31<10:23, 11.77s/it] 48%|████▊     | 48/100 [09:42<10:01, 11.57s/it] 49%|████▉     | 49/100 [09:52<09:27, 11.12s/it] 50%|█████     | 50/100 [10:11<11:20, 13.62s/it]Epoch 50: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.7900 / 0.6481 / 0.6250 / 0.9412
                Test acc/f1/spec/sens = 0.4344 / 0.3611 / 0.3625 / 0.9524
 51%|█████     | 51/100 [10:22<10:16, 12.59s/it] 52%|█████▏    | 52/100 [10:33<09:44, 12.17s/it] 53%|█████▎    | 53/100 [10:43<09:03, 11.56s/it] 54%|█████▍    | 54/100 [10:54<08:48, 11.50s/it] 55%|█████▌    | 55/100 [11:13<10:16, 13.69s/it]Epoch 55: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.7900 / 0.6481 / 0.6250 / 0.9412
                Test acc/f1/spec/sens = 0.4344 / 0.3611 / 0.3625 / 0.9524
 56%|█████▌    | 56/100 [11:24<09:29, 12.94s/it] 57%|█████▋    | 57/100 [11:34<08:39, 12.07s/it] 58%|█████▊    | 58/100 [11:46<08:14, 11.78s/it] 59%|█████▉    | 59/100 [11:56<07:42, 11.28s/it] 60%|██████    | 60/100 [12:14<08:57, 13.44s/it]Epoch 60: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.7900 / 0.6481 / 0.6250 / 0.9412
                Test acc/f1/spec/sens = 0.4426 / 0.3714 / 0.3750 / 0.9524
 61%|██████    | 61/100 [12:24<08:05, 12.45s/it] 62%|██████▏   | 62/100 [12:35<07:38, 12.07s/it] 63%|██████▎   | 63/100 [12:46<07:06, 11.52s/it] 64%|██████▍   | 64/100 [12:57<06:52, 11.46s/it] 65%|██████▌   | 65/100 [13:15<07:45, 13.29s/it]Epoch 65: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.7900 / 0.6481 / 0.6250 / 0.9412
                Test acc/f1/spec/sens = 0.4426 / 0.3714 / 0.3750 / 0.9524
 66%|██████▌   | 66/100 [13:26<07:12, 12.72s/it] 67%|██████▋   | 67/100 [13:36<06:34, 11.96s/it] 68%|██████▊   | 68/100 [13:47<06:16, 11.77s/it] 69%|██████▉   | 69/100 [13:58<05:50, 11.31s/it] 70%|███████   | 70/100 [14:16<06:43, 13.45s/it]Epoch 70: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.7900 / 0.6481 / 0.6250 / 0.9412
                Test acc/f1/spec/sens = 0.4426 / 0.3714 / 0.3750 / 0.9524
 71%|███████   | 71/100 [14:26<06:01, 12.48s/it] 72%|███████▏  | 72/100 [14:38<05:39, 12.13s/it] 73%|███████▎  | 73/100 [14:48<05:11, 11.54s/it] 74%|███████▍  | 74/100 [14:59<04:58, 11.49s/it] 75%|███████▌  | 75/100 [15:17<05:33, 13.35s/it]Epoch 75: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.7900 / 0.6481 / 0.6250 / 0.9412
                Test acc/f1/spec/sens = 0.4426 / 0.3714 / 0.3750 / 0.9524
 76%|███████▌  | 76/100 [15:28<05:05, 12.74s/it] 77%|███████▋  | 77/100 [15:38<04:35, 11.98s/it] 78%|███████▊  | 78/100 [15:50<04:19, 11.78s/it] 79%|███████▉  | 79/100 [16:00<03:57, 11.31s/it] 80%|████████  | 80/100 [16:19<04:30, 13.50s/it]Epoch 80: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.7900 / 0.6481 / 0.6250 / 0.9412
                Test acc/f1/spec/sens = 0.4426 / 0.3714 / 0.3750 / 0.9524
 81%|████████  | 81/100 [16:29<03:57, 12.51s/it] 82%|████████▏ | 82/100 [16:40<03:39, 12.19s/it] 83%|████████▎ | 83/100 [16:50<03:16, 11.58s/it] 84%|████████▍ | 84/100 [17:02<03:04, 11.53s/it] 85%|████████▌ | 85/100 [17:19<03:20, 13.39s/it]Epoch 85: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.7900 / 0.6481 / 0.6250 / 0.9412
                Test acc/f1/spec/sens = 0.4426 / 0.3714 / 0.3750 / 0.9524
 86%|████████▌ | 86/100 [17:31<02:59, 12.80s/it] 87%|████████▋ | 87/100 [17:41<02:36, 12.04s/it] 88%|████████▊ | 88/100 [17:53<02:22, 11.84s/it] 89%|████████▉ | 89/100 [18:03<02:04, 11.35s/it] 90%|█████████ | 90/100 [18:22<02:16, 13.62s/it]Epoch 90: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.7900 / 0.6481 / 0.6250 / 0.9412
                Test acc/f1/spec/sens = 0.4426 / 0.3714 / 0.3750 / 0.9524
 91%|█████████ | 91/100 [18:32<01:53, 12.61s/it] 92%|█████████▏| 92/100 [18:43<01:38, 12.25s/it] 93%|█████████▎| 93/100 [18:54<01:21, 11.63s/it] 94%|█████████▍| 94/100 [19:05<01:09, 11.57s/it] 95%|█████████▌| 95/100 [19:23<01:07, 13.41s/it]Epoch 95: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.7900 / 0.6481 / 0.6250 / 0.9412
                Test acc/f1/spec/sens = 0.4426 / 0.3714 / 0.3750 / 0.9524
 96%|█████████▌| 96/100 [19:34<00:51, 12.79s/it] 97%|█████████▋| 97/100 [19:44<00:36, 12.00s/it] 98%|█████████▊| 98/100 [19:56<00:23, 11.83s/it] 99%|█████████▉| 99/100 [20:06<00:11, 11.32s/it]100%|██████████| 100/100 [20:25<00:00, 13.56s/it]                                                 Epoch 100: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.7900 / 0.6481 / 0.6250 / 0.9412
                Test acc/f1/spec/sens = 0.4426 / 0.3714 / 0.3750 / 0.9524
specificity = 313/313
sensitivity = 587/587
specificity = 20/32
sensitivity = 64/68
specificity = 30/80
sensitivity = 40/42
Trial 3, Cycle 1
Train acc/f1/spec/sens = 1.0000 / 1.0000 / 1.0000 / 1.0000
Val acc/f1/spec/sens = 0.7900 / 0.6481 / 0.6250 / 0.9412
Test acc/f1/spec/sens = 0.4426 / 0.3714 / 0.3750 / 0.9524
>> Finished.
specificity = 30/80
sensitivity = 40/42
Acc, agreement for latest model:  0.4426229508196721 0.48360655737704916
Load best checkpoint for thief model
specificity = 26/80
sensitivity = 38/42
Acc, agreement for best model:  0.39344262295081966 0.45901639344262296
Trial 2/5 || Cycle 1/1 || Label set size 900 || Test acc 0.3934 || Test agreement 0.4590 || Spec 0.3250 || Sens 0.9048
**************************************************************************************************** 

specificity = 26/80
sensitivity = 38/42
Number of samples  900
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
replacing labeled set labels with victim labels
  0%|          | 0/57 [00:00<?, ?it/s]  2%|▏         | 1/57 [00:00<00:50,  1.10it/s]  4%|▎         | 2/57 [00:01<00:32,  1.72it/s]  5%|▌         | 3/57 [00:01<00:23,  2.30it/s]  7%|▋         | 4/57 [00:01<00:18,  2.90it/s]  9%|▉         | 5/57 [00:01<00:15,  3.37it/s] 11%|█         | 6/57 [00:02<00:13,  3.68it/s] 12%|█▏        | 7/57 [00:02<00:12,  4.00it/s] 14%|█▍        | 8/57 [00:02<00:11,  4.31it/s] 16%|█▌        | 9/57 [00:02<00:11,  4.24it/s] 18%|█▊        | 10/57 [00:02<00:10,  4.50it/s] 19%|█▉        | 11/57 [00:03<00:09,  4.67it/s] 21%|██        | 12/57 [00:03<00:09,  4.82it/s] 23%|██▎       | 13/57 [00:03<00:09,  4.61it/s] 25%|██▍       | 14/57 [00:03<00:09,  4.76it/s] 26%|██▋       | 15/57 [00:04<00:08,  4.87it/s] 28%|██▊       | 16/57 [00:04<00:08,  4.94it/s] 30%|██▉       | 17/57 [00:04<00:08,  4.70it/s] 32%|███▏      | 18/57 [00:04<00:08,  4.78it/s] 33%|███▎      | 19/57 [00:04<00:07,  4.88it/s] 35%|███▌      | 20/57 [00:05<00:07,  4.94it/s] 37%|███▋      | 21/57 [00:05<00:07,  4.76it/s] 39%|███▊      | 22/57 [00:05<00:07,  4.56it/s] 40%|████      | 23/57 [00:05<00:07,  4.32it/s] 42%|████▏     | 24/57 [00:06<00:07,  4.26it/s] 44%|████▍     | 25/57 [00:06<00:07,  4.28it/s] 46%|████▌     | 26/57 [00:06<00:06,  4.49it/s] 47%|████▋     | 27/57 [00:06<00:06,  4.64it/s] 49%|████▉     | 28/57 [00:06<00:06,  4.78it/s] 51%|█████     | 29/57 [00:07<00:05,  4.84it/s] 53%|█████▎    | 30/57 [00:07<00:05,  4.89it/s] 54%|█████▍    | 31/57 [00:07<00:05,  4.96it/s] 56%|█████▌    | 32/57 [00:07<00:05,  4.96it/s] 58%|█████▊    | 33/57 [00:07<00:04,  5.01it/s] 60%|█████▉    | 34/57 [00:08<00:04,  4.98it/s] 61%|██████▏   | 35/57 [00:08<00:04,  5.02it/s] 63%|██████▎   | 36/57 [00:08<00:04,  5.04it/s] 65%|██████▍   | 37/57 [00:08<00:04,  4.98it/s] 67%|██████▋   | 38/57 [00:08<00:03,  4.86it/s] 68%|██████▊   | 39/57 [00:09<00:03,  4.94it/s] 70%|███████   | 40/57 [00:09<00:03,  4.50it/s] 72%|███████▏  | 41/57 [00:09<00:03,  4.31it/s] 74%|███████▎  | 42/57 [00:09<00:03,  4.50it/s] 75%|███████▌  | 43/57 [00:09<00:03,  4.65it/s] 77%|███████▋  | 44/57 [00:10<00:02,  4.78it/s] 79%|███████▉  | 45/57 [00:10<00:02,  4.51it/s] 81%|████████  | 46/57 [00:10<00:02,  4.45it/s] 82%|████████▏ | 47/57 [00:10<00:02,  4.59it/s] 84%|████████▍ | 48/57 [00:11<00:01,  4.75it/s] 86%|████████▌ | 49/57 [00:11<00:01,  4.82it/s] 88%|████████▊ | 50/57 [00:11<00:01,  4.88it/s] 89%|████████▉ | 51/57 [00:11<00:01,  4.84it/s] 91%|█████████ | 52/57 [00:11<00:01,  4.43it/s] 93%|█████████▎| 53/57 [00:12<00:00,  4.60it/s] 95%|█████████▍| 54/57 [00:12<00:00,  4.76it/s] 96%|█████████▋| 55/57 [00:12<00:00,  4.71it/s] 98%|█████████▊| 56/57 [00:12<00:00,  4.65it/s]100%|██████████| 57/57 [00:12<00:00,  4.39it/s]
replacing val labels with victim labels
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:00<00:05,  1.14it/s] 29%|██▊       | 2/7 [00:01<00:02,  1.92it/s] 43%|████▎     | 3/7 [00:01<00:01,  2.43it/s] 57%|█████▋    | 4/7 [00:01<00:01,  3.00it/s] 71%|███████▏  | 5/7 [00:01<00:00,  3.47it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.83it/s]100%|██████████| 7/7 [00:02<00:00,  3.05it/s]Validation set distribution: 
Number of samples  100

{0: 19, 1: 24, 2: 57}
Labeled set distribution: 
Number of samples  900
{0: 114, 1: 210, 2: 576}
odict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias', 'heads.head.weight', 'heads.head.bias'])
thief state:  None
pretrained state:  dict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias'])
Thief model initialized successfully
specificity = 80/80
sensitivity = 0/42
Initial model on target dataset: acc = 0.2541, agreement = 0.2377, f1 = 0.1351, spec = 1.0000, sens = 0.0000
specificity = 43/43
sensitivity = 0/57
Initial model on validation dataset: acc = 0.1900, agreement = 0.1900, f1 = 0.1064, spec = 1.0000, sens = 0.0000
la:  None
>> Train a Model.
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:09<16:28,  9.99s/it]  2%|▏         | 2/100 [00:21<17:57, 11.00s/it]  3%|▎         | 3/100 [00:31<17:08, 10.61s/it]  4%|▍         | 4/100 [00:43<17:51, 11.16s/it]  5%|▌         | 5/100 [01:01<21:18, 13.46s/it]Epoch 5: Train acc/f1 = 0.8756 / 0.8308 / 0.8519 / 0.9323 
                Val acc/f1/spec/sens = 0.6700 / 0.5500 / 0.4419 / 0.9298
                Test acc/f1/spec/sens = 0.4098 / 0.3116 / 0.3375 / 0.8810
  6%|▌         | 6/100 [01:13<20:19, 12.97s/it]  7%|▋         | 7/100 [01:23<18:42, 12.07s/it]  8%|▊         | 8/100 [01:34<18:08, 11.83s/it]  9%|▉         | 9/100 [01:45<17:10, 11.32s/it] 10%|█         | 10/100 [02:03<20:22, 13.58s/it]Epoch 10: Train acc/f1 = 0.9344 / 0.9244 / 0.9136 / 0.9601 
                Val acc/f1/spec/sens = 0.6200 / 0.5390 / 0.5116 / 0.7895
                Test acc/f1/spec/sens = 0.3770 / 0.3161 / 0.3500 / 0.7857
 11%|█         | 11/100 [02:13<18:33, 12.52s/it] 12%|█▏        | 12/100 [02:25<17:47, 12.13s/it] 13%|█▎        | 13/100 [02:35<16:43, 11.53s/it] 14%|█▍        | 14/100 [02:46<16:26, 11.47s/it] 15%|█▌        | 15/100 [03:03<18:46, 13.25s/it]Epoch 15: Train acc/f1 = 0.9311 / 0.9183 / 0.9506 / 0.9392 
                Val acc/f1/spec/sens = 0.6300 / 0.5443 / 0.5116 / 0.8246
                Test acc/f1/spec/sens = 0.4262 / 0.3829 / 0.5125 / 0.7143
 16%|█▌        | 16/100 [03:15<17:43, 12.66s/it] 17%|█▋        | 17/100 [03:25<16:28, 11.91s/it] 18%|█▊        | 18/100 [03:36<16:03, 11.75s/it] 19%|█▉        | 19/100 [03:47<15:14, 11.29s/it] 20%|██        | 20/100 [04:05<17:49, 13.36s/it]Epoch 20: Train acc/f1 = 0.9878 / 0.9843 / 0.9784 / 0.9965 
                Val acc/f1/spec/sens = 0.6400 / 0.5419 / 0.5349 / 0.8421
                Test acc/f1/spec/sens = 0.4016 / 0.3675 / 0.3750 / 0.7381
 21%|██        | 21/100 [04:15<16:20, 12.41s/it] 22%|██▏       | 22/100 [04:26<15:42, 12.08s/it] 23%|██▎       | 23/100 [04:36<14:47, 11.53s/it] 24%|██▍       | 24/100 [04:48<14:33, 11.49s/it] 25%|██▌       | 25/100 [05:08<17:34, 14.06s/it]Epoch 25: Train acc/f1 = 0.9978 / 0.9978 / 0.9938 / 1.0000 
                Val acc/f1/spec/sens = 0.6300 / 0.5334 / 0.5116 / 0.8421
                Test acc/f1/spec/sens = 0.4180 / 0.3555 / 0.3125 / 0.8571
 26%|██▌       | 26/100 [05:20<16:29, 13.37s/it] 27%|██▋       | 27/100 [05:30<15:07, 12.44s/it] 28%|██▊       | 28/100 [05:41<14:35, 12.16s/it] 29%|██▉       | 29/100 [05:52<13:40, 11.56s/it] 30%|███       | 30/100 [06:10<15:50, 13.58s/it]Epoch 30: Train acc/f1 = 0.9989 / 0.9989 / 0.9969 / 1.0000 
                Val acc/f1/spec/sens = 0.6400 / 0.5388 / 0.5116 / 0.8596
                Test acc/f1/spec/sens = 0.4098 / 0.3500 / 0.3250 / 0.8333
 31%|███       | 31/100 [06:20<14:24, 12.53s/it] 32%|███▏      | 32/100 [06:31<13:46, 12.16s/it] 33%|███▎      | 33/100 [06:41<12:53, 11.55s/it] 34%|███▍      | 34/100 [06:53<12:34, 11.44s/it] 35%|███▌      | 35/100 [07:10<14:21, 13.26s/it]Epoch 35: Train acc/f1 = 0.9989 / 0.9989 / 0.9969 / 1.0000 
                Val acc/f1/spec/sens = 0.6400 / 0.5388 / 0.5116 / 0.8596
                Test acc/f1/spec/sens = 0.4016 / 0.3360 / 0.3000 / 0.8333
 36%|███▌      | 36/100 [07:21<13:32, 12.69s/it] 37%|███▋      | 37/100 [07:32<12:31, 11.93s/it] 38%|███▊      | 38/100 [07:43<12:07, 11.74s/it] 39%|███▉      | 39/100 [07:53<11:26, 11.26s/it] 40%|████      | 40/100 [08:11<13:23, 13.39s/it]Epoch 40: Train acc/f1 = 0.9989 / 0.9989 / 0.9969 / 1.0000 
                Val acc/f1/spec/sens = 0.6500 / 0.5553 / 0.5349 / 0.8596
                Test acc/f1/spec/sens = 0.3934 / 0.3211 / 0.2875 / 0.8333
 41%|████      | 41/100 [08:22<12:12, 12.42s/it] 42%|████▏     | 42/100 [08:33<11:40, 12.08s/it] 43%|████▎     | 43/100 [08:43<10:55, 11.50s/it] 44%|████▍     | 44/100 [08:54<10:41, 11.45s/it] 45%|████▌     | 45/100 [09:12<12:04, 13.18s/it]Epoch 45: Train acc/f1 = 0.9989 / 0.9989 / 0.9969 / 1.0000 
                Val acc/f1/spec/sens = 0.6500 / 0.5553 / 0.5349 / 0.8596
                Test acc/f1/spec/sens = 0.3934 / 0.3211 / 0.2875 / 0.8333
 46%|████▌     | 46/100 [09:23<11:20, 12.60s/it] 47%|████▋     | 47/100 [09:33<10:28, 11.86s/it] 48%|████▊     | 48/100 [09:44<10:08, 11.70s/it] 49%|████▉     | 49/100 [09:54<09:32, 11.23s/it] 50%|█████     | 50/100 [10:13<11:14, 13.48s/it]Epoch 50: Train acc/f1 = 0.9989 / 0.9989 / 0.9969 / 1.0000 
                Val acc/f1/spec/sens = 0.6500 / 0.5553 / 0.5349 / 0.8596
                Test acc/f1/spec/sens = 0.3852 / 0.3159 / 0.2875 / 0.8095
 51%|█████     | 51/100 [10:23<10:12, 12.50s/it] 52%|█████▏    | 52/100 [10:35<09:44, 12.18s/it] 53%|█████▎    | 53/100 [10:45<09:03, 11.56s/it] 54%|█████▍    | 54/100 [10:56<08:47, 11.48s/it] 55%|█████▌    | 55/100 [11:14<09:59, 13.31s/it]Epoch 55: Train acc/f1 = 0.9989 / 0.9989 / 0.9969 / 1.0000 
                Val acc/f1/spec/sens = 0.6500 / 0.5553 / 0.5349 / 0.8596
                Test acc/f1/spec/sens = 0.3852 / 0.3159 / 0.2875 / 0.8095
 56%|█████▌    | 56/100 [11:25<09:19, 12.71s/it] 57%|█████▋    | 57/100 [11:35<08:33, 11.94s/it] 58%|█████▊    | 58/100 [11:46<08:12, 11.74s/it] 59%|█████▉    | 59/100 [11:57<07:41, 11.26s/it] 60%|██████    | 60/100 [12:16<09:02, 13.57s/it]Epoch 60: Train acc/f1 = 0.9989 / 0.9989 / 0.9969 / 1.0000 
                Val acc/f1/spec/sens = 0.6500 / 0.5553 / 0.5349 / 0.8596
                Test acc/f1/spec/sens = 0.3852 / 0.3159 / 0.2875 / 0.8095
 61%|██████    | 61/100 [12:26<08:09, 12.54s/it] 62%|██████▏   | 62/100 [12:37<07:41, 12.14s/it] 63%|██████▎   | 63/100 [12:47<07:06, 11.51s/it] 64%|██████▍   | 64/100 [12:58<06:52, 11.45s/it] 65%|██████▌   | 65/100 [13:16<07:46, 13.32s/it]Epoch 65: Train acc/f1 = 0.9989 / 0.9989 / 0.9969 / 1.0000 
                Val acc/f1/spec/sens = 0.6500 / 0.5553 / 0.5349 / 0.8596
                Test acc/f1/spec/sens = 0.3852 / 0.3159 / 0.2875 / 0.8095
 66%|██████▌   | 66/100 [13:27<07:11, 12.70s/it] 67%|██████▋   | 67/100 [13:37<06:33, 11.93s/it] 68%|██████▊   | 68/100 [13:49<06:15, 11.72s/it] 69%|██████▉   | 69/100 [13:59<05:48, 11.23s/it] 70%|███████   | 70/100 [14:17<06:39, 13.30s/it]Epoch 70: Train acc/f1 = 0.9989 / 0.9989 / 0.9969 / 1.0000 
                Val acc/f1/spec/sens = 0.6500 / 0.5553 / 0.5349 / 0.8596
                Test acc/f1/spec/sens = 0.3852 / 0.3159 / 0.2875 / 0.8095
 71%|███████   | 71/100 [14:27<05:58, 12.35s/it] 72%|███████▏  | 72/100 [14:38<05:37, 12.04s/it] 73%|███████▎  | 73/100 [14:48<05:09, 11.48s/it] 74%|███████▍  | 74/100 [15:00<04:57, 11.43s/it] 75%|███████▌  | 75/100 [15:18<05:33, 13.34s/it]Epoch 75: Train acc/f1 = 0.9989 / 0.9989 / 0.9969 / 1.0000 
                Val acc/f1/spec/sens = 0.6500 / 0.5553 / 0.5349 / 0.8596
                Test acc/f1/spec/sens = 0.3852 / 0.3159 / 0.2875 / 0.8095
 76%|███████▌  | 76/100 [15:29<05:05, 12.72s/it] 77%|███████▋  | 77/100 [15:39<04:34, 11.95s/it] 78%|███████▊  | 78/100 [15:50<04:17, 11.73s/it] 79%|███████▉  | 79/100 [16:00<03:56, 11.25s/it] 80%|████████  | 80/100 [16:19<04:32, 13.63s/it]Epoch 80: Train acc/f1 = 0.9989 / 0.9989 / 0.9969 / 1.0000 
                Val acc/f1/spec/sens = 0.6500 / 0.5553 / 0.5349 / 0.8596
                Test acc/f1/spec/sens = 0.3852 / 0.3159 / 0.2875 / 0.8095
 81%|████████  | 81/100 [16:30<03:59, 12.61s/it] 82%|████████▏ | 82/100 [16:41<03:39, 12.20s/it] 83%|████████▎ | 83/100 [16:51<03:16, 11.58s/it] 84%|████████▍ | 84/100 [17:02<03:03, 11.49s/it] 85%|████████▌ | 85/100 [17:20<03:19, 13.31s/it]Epoch 85: Train acc/f1 = 0.9989 / 0.9989 / 0.9969 / 1.0000 
                Val acc/f1/spec/sens = 0.6500 / 0.5553 / 0.5349 / 0.8596
                Test acc/f1/spec/sens = 0.3852 / 0.3159 / 0.2875 / 0.8095
 86%|████████▌ | 86/100 [17:31<02:57, 12.70s/it] 87%|████████▋ | 87/100 [17:41<02:34, 11.92s/it] 88%|████████▊ | 88/100 [17:53<02:21, 11.77s/it] 89%|████████▉ | 89/100 [18:03<02:03, 11.27s/it] 90%|█████████ | 90/100 [18:21<02:13, 13.37s/it]Epoch 90: Train acc/f1 = 0.9989 / 0.9989 / 0.9969 / 1.0000 
                Val acc/f1/spec/sens = 0.6500 / 0.5553 / 0.5349 / 0.8596
                Test acc/f1/spec/sens = 0.3852 / 0.3159 / 0.2875 / 0.8095
 91%|█████████ | 91/100 [18:31<01:51, 12.41s/it] 92%|█████████▏| 92/100 [18:43<01:36, 12.08s/it] 93%|█████████▎| 93/100 [18:53<01:20, 11.51s/it] 94%|█████████▍| 94/100 [19:04<01:08, 11.45s/it] 95%|█████████▌| 95/100 [19:22<01:06, 13.26s/it]Epoch 95: Train acc/f1 = 0.9989 / 0.9989 / 0.9969 / 1.0000 
                Val acc/f1/spec/sens = 0.6500 / 0.5553 / 0.5349 / 0.8596
                Test acc/f1/spec/sens = 0.3852 / 0.3159 / 0.2875 / 0.8095
 96%|█████████▌| 96/100 [19:33<00:50, 12.66s/it] 97%|█████████▋| 97/100 [19:43<00:35, 11.91s/it] 98%|█████████▊| 98/100 [19:54<00:23, 11.76s/it] 99%|█████████▉| 99/100 [20:05<00:11, 11.28s/it]100%|██████████| 100/100 [20:23<00:00, 13.51s/it]                                                 Epoch 100: Train acc/f1 = 0.9989 / 0.9989 / 0.9969 / 1.0000 
                Val acc/f1/spec/sens = 0.6500 / 0.5553 / 0.5349 / 0.8596
                Test acc/f1/spec/sens = 0.3852 / 0.3159 / 0.2875 / 0.8095
specificity = 323/324
sensitivity = 576/576
specificity = 23/43
sensitivity = 49/57
specificity = 23/80
sensitivity = 34/42
Trial 4, Cycle 1
Train acc/f1/spec/sens = 0.9989 / 0.9989 / 0.9969 / 1.0000
Val acc/f1/spec/sens = 0.6500 / 0.5553 / 0.5349 / 0.8596
Test acc/f1/spec/sens = 0.3852 / 0.3159 / 0.2875 / 0.8095
>> Finished.
specificity = 23/80
sensitivity = 34/42
Acc, agreement for latest model:  0.38524590163934425 0.3770491803278688
Load best checkpoint for thief model
specificity = 52/80
sensitivity = 15/42
Acc, agreement for best model:  0.319672131147541 0.36885245901639346
Trial 3/5 || Cycle 1/1 || Label set size 900 || Test acc 0.3197 || Test agreement 0.3689 || Spec 0.6500 || Sens 0.3571
**************************************************************************************************** 

specificity = 52/80
sensitivity = 15/42
Number of samples  900
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
replacing labeled set labels with victim labels
  0%|          | 0/57 [00:00<?, ?it/s]  2%|▏         | 1/57 [00:00<00:48,  1.17it/s]  4%|▎         | 2/57 [00:01<00:26,  2.04it/s]  5%|▌         | 3/57 [00:01<00:20,  2.58it/s]  7%|▋         | 4/57 [00:01<00:18,  2.83it/s]  9%|▉         | 5/57 [00:01<00:17,  3.05it/s] 11%|█         | 6/57 [00:02<00:14,  3.50it/s] 12%|█▏        | 7/57 [00:02<00:13,  3.85it/s] 14%|█▍        | 8/57 [00:02<00:11,  4.17it/s] 16%|█▌        | 9/57 [00:02<00:11,  4.35it/s] 18%|█▊        | 10/57 [00:02<00:10,  4.47it/s] 19%|█▉        | 11/57 [00:03<00:10,  4.59it/s] 21%|██        | 12/57 [00:03<00:09,  4.69it/s] 23%|██▎       | 13/57 [00:03<00:09,  4.70it/s] 25%|██▍       | 14/57 [00:03<00:08,  4.79it/s] 26%|██▋       | 15/57 [00:03<00:08,  4.81it/s] 28%|██▊       | 16/57 [00:04<00:08,  4.85it/s] 30%|██▉       | 17/57 [00:04<00:09,  4.41it/s] 32%|███▏      | 18/57 [00:04<00:09,  4.15it/s] 33%|███▎      | 19/57 [00:04<00:08,  4.33it/s] 35%|███▌      | 20/57 [00:05<00:08,  4.48it/s] 37%|███▋      | 21/57 [00:05<00:08,  4.24it/s] 39%|███▊      | 22/57 [00:05<00:08,  4.07it/s] 40%|████      | 23/57 [00:05<00:08,  3.84it/s] 42%|████▏     | 24/57 [00:06<00:08,  4.08it/s] 44%|████▍     | 25/57 [00:06<00:07,  4.32it/s] 46%|████▌     | 26/57 [00:06<00:06,  4.53it/s] 47%|████▋     | 27/57 [00:06<00:06,  4.65it/s] 49%|████▉     | 28/57 [00:06<00:06,  4.74it/s] 51%|█████     | 29/57 [00:07<00:05,  4.80it/s] 53%|█████▎    | 30/57 [00:07<00:05,  4.84it/s] 54%|█████▍    | 31/57 [00:07<00:05,  4.85it/s] 56%|█████▌    | 32/57 [00:07<00:05,  4.90it/s] 58%|█████▊    | 33/57 [00:08<00:04,  4.91it/s] 60%|█████▉    | 34/57 [00:08<00:04,  4.90it/s] 61%|██████▏   | 35/57 [00:08<00:04,  4.47it/s] 63%|██████▎   | 36/57 [00:08<00:04,  4.63it/s] 65%|██████▍   | 37/57 [00:08<00:04,  4.73it/s] 67%|██████▋   | 38/57 [00:09<00:03,  4.79it/s] 68%|██████▊   | 39/57 [00:09<00:03,  4.86it/s] 70%|███████   | 40/57 [00:09<00:03,  4.45it/s] 72%|███████▏  | 41/57 [00:09<00:03,  4.60it/s] 74%|███████▎  | 42/57 [00:09<00:03,  4.69it/s] 75%|███████▌  | 43/57 [00:10<00:02,  4.79it/s] 77%|███████▋  | 44/57 [00:10<00:02,  4.84it/s] 79%|███████▉  | 45/57 [00:10<00:02,  4.85it/s] 81%|████████  | 46/57 [00:10<00:02,  4.91it/s] 82%|████████▏ | 47/57 [00:10<00:02,  4.90it/s] 84%|████████▍ | 48/57 [00:11<00:01,  4.90it/s] 86%|████████▌ | 49/57 [00:11<00:01,  4.89it/s] 88%|████████▊ | 50/57 [00:11<00:01,  4.91it/s] 89%|████████▉ | 51/57 [00:11<00:01,  4.88it/s] 91%|█████████ | 52/57 [00:12<00:01,  4.34it/s] 93%|█████████▎| 53/57 [00:12<00:00,  4.12it/s] 95%|█████████▍| 54/57 [00:12<00:00,  3.92it/s] 96%|█████████▋| 55/57 [00:12<00:00,  3.86it/s] 98%|█████████▊| 56/57 [00:13<00:00,  3.78it/s]100%|██████████| 57/57 [00:13<00:00,  4.24it/s]
replacing val labels with victim labels
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:00<00:04,  1.33it/s] 29%|██▊       | 2/7 [00:00<00:02,  2.32it/s] 43%|████▎     | 3/7 [00:01<00:01,  3.02it/s] 57%|█████▋    | 4/7 [00:01<00:00,  3.07it/s] 71%|███████▏  | 5/7 [00:01<00:00,  3.29it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.49it/s]100%|██████████| 7/7 [00:02<00:00,  3.09it/s]Validation set distribution: 
Number of samples  100

{0: 11, 1: 20, 2: 69}
Labeled set distribution: 
Number of samples  900
{0: 101, 1: 218, 2: 581}
odict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias', 'heads.head.weight', 'heads.head.bias'])
thief state:  None
pretrained state:  dict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias'])
Thief model initialized successfully
specificity = 80/80
sensitivity = 0/42
Initial model on target dataset: acc = 0.2541, agreement = 0.2377, f1 = 0.1351, spec = 1.0000, sens = 0.0000
specificity = 31/31
sensitivity = 0/69
Initial model on validation dataset: acc = 0.1100, agreement = 0.1100, f1 = 0.0661, spec = 1.0000, sens = 0.0000
la:  None
>> Train a Model.
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:09<16:29, 10.00s/it]  2%|▏         | 2/100 [00:21<17:56, 10.98s/it]  3%|▎         | 3/100 [00:31<17:03, 10.55s/it]  4%|▍         | 4/100 [00:43<17:50, 11.15s/it]  5%|▌         | 5/100 [01:00<21:06, 13.33s/it]Epoch 5: Train acc/f1 = 0.9144 / 0.8658 / 0.8997 / 0.9604 
                Val acc/f1/spec/sens = 0.7400 / 0.5783 / 0.8387 / 0.7971
                Test acc/f1/spec/sens = 0.3852 / 0.2641 / 0.2125 / 0.9048
  6%|▌         | 6/100 [01:12<20:11, 12.89s/it]  7%|▋         | 7/100 [01:23<18:35, 11.99s/it]  8%|▊         | 8/100 [01:34<18:04, 11.79s/it]  9%|▉         | 9/100 [01:44<17:07, 11.29s/it] 10%|█         | 10/100 [02:03<20:20, 13.56s/it]Epoch 10: Train acc/f1 = 0.9189 / 0.8931 / 0.8182 / 0.9914 
                Val acc/f1/spec/sens = 0.7700 / 0.6308 / 0.4516 / 0.9420
                Test acc/f1/spec/sens = 0.3525 / 0.1872 / 0.0375 / 1.0000
 11%|█         | 11/100 [02:13<18:34, 12.52s/it] 12%|█▏        | 12/100 [02:24<17:47, 12.13s/it] 13%|█▎        | 13/100 [02:34<16:42, 11.52s/it] 14%|█▍        | 14/100 [02:46<16:23, 11.44s/it] 15%|█▌        | 15/100 [03:03<18:52, 13.33s/it]Epoch 15: Train acc/f1 = 0.9344 / 0.9397 / 1.0000 / 0.9019 
                Val acc/f1/spec/sens = 0.7600 / 0.6713 / 0.8387 / 0.7681
                Test acc/f1/spec/sens = 0.3770 / 0.2858 / 0.3500 / 0.7381
 16%|█▌        | 16/100 [03:15<17:46, 12.70s/it] 17%|█▋        | 17/100 [03:25<16:30, 11.93s/it] 18%|█▊        | 18/100 [03:36<16:02, 11.74s/it] 19%|█▉        | 19/100 [03:46<15:10, 11.25s/it] 20%|██        | 20/100 [04:05<17:57, 13.47s/it]Epoch 20: Train acc/f1 = 0.9367 / 0.9084 / 0.9122 / 0.9776 
                Val acc/f1/spec/sens = 0.7100 / 0.5476 / 0.6129 / 0.8551
                Test acc/f1/spec/sens = 0.3279 / 0.2475 / 0.1750 / 0.7857
 21%|██        | 21/100 [04:15<16:26, 12.49s/it] 22%|██▏       | 22/100 [04:27<16:04, 12.36s/it] 23%|██▎       | 23/100 [04:37<15:04, 11.75s/it] 24%|██▍       | 24/100 [04:49<14:40, 11.58s/it] 25%|██▌       | 25/100 [05:06<16:32, 13.23s/it]Epoch 25: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8300 / 0.7194 / 0.6774 / 0.9275
                Test acc/f1/spec/sens = 0.3607 / 0.2442 / 0.1625 / 0.8810
 26%|██▌       | 26/100 [05:17<15:34, 12.63s/it] 27%|██▋       | 27/100 [05:27<14:25, 11.86s/it] 28%|██▊       | 28/100 [05:38<14:02, 11.70s/it] 29%|██▉       | 29/100 [05:48<13:16, 11.22s/it] 30%|███       | 30/100 [06:07<15:40, 13.44s/it]Epoch 30: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8300 / 0.7194 / 0.6774 / 0.9275
                Test acc/f1/spec/sens = 0.3607 / 0.2442 / 0.1625 / 0.8810
 31%|███       | 31/100 [06:17<14:18, 12.45s/it] 32%|███▏      | 32/100 [06:28<13:42, 12.10s/it] 33%|███▎      | 33/100 [06:38<12:51, 11.51s/it] 34%|███▍      | 34/100 [06:50<12:35, 11.45s/it] 35%|███▌      | 35/100 [07:07<14:23, 13.28s/it]Epoch 35: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8200 / 0.6993 / 0.6774 / 0.9275
                Test acc/f1/spec/sens = 0.3689 / 0.2476 / 0.1625 / 0.9048
 36%|███▌      | 36/100 [07:19<13:30, 12.66s/it] 37%|███▋      | 37/100 [07:29<12:29, 11.90s/it] 38%|███▊      | 38/100 [07:40<12:06, 11.71s/it] 39%|███▉      | 39/100 [07:50<11:25, 11.24s/it] 40%|████      | 40/100 [08:09<13:30, 13.52s/it]Epoch 40: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8200 / 0.6993 / 0.6774 / 0.9275
                Test acc/f1/spec/sens = 0.3689 / 0.2476 / 0.1625 / 0.9048
 41%|████      | 41/100 [08:19<12:17, 12.50s/it] 42%|████▏     | 42/100 [08:30<11:44, 12.15s/it] 43%|████▎     | 43/100 [08:41<10:57, 11.54s/it] 44%|████▍     | 44/100 [08:52<10:42, 11.48s/it] 45%|████▌     | 45/100 [09:09<12:13, 13.33s/it]Epoch 45: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8200 / 0.6993 / 0.6774 / 0.9275
                Test acc/f1/spec/sens = 0.3689 / 0.2476 / 0.1625 / 0.9048
 46%|████▌     | 46/100 [09:21<11:26, 12.70s/it] 47%|████▋     | 47/100 [09:31<10:31, 11.92s/it] 48%|████▊     | 48/100 [09:42<10:09, 11.72s/it] 49%|████▉     | 49/100 [09:52<09:34, 11.27s/it] 50%|█████     | 50/100 [10:12<11:31, 13.82s/it]Epoch 50: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8200 / 0.6993 / 0.6774 / 0.9275
                Test acc/f1/spec/sens = 0.3689 / 0.2476 / 0.1625 / 0.9048
 51%|█████     | 51/100 [10:22<10:25, 12.76s/it] 52%|█████▏    | 52/100 [10:34<09:53, 12.37s/it] 53%|█████▎    | 53/100 [10:44<09:11, 11.72s/it] 54%|█████▍    | 54/100 [10:55<08:53, 11.61s/it] 55%|█████▌    | 55/100 [11:13<09:59, 13.32s/it]Epoch 55: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8200 / 0.6993 / 0.6774 / 0.9275
                Test acc/f1/spec/sens = 0.3689 / 0.2476 / 0.1625 / 0.9048
 56%|█████▌    | 56/100 [11:24<09:17, 12.66s/it] 57%|█████▋    | 57/100 [11:34<08:32, 11.92s/it] 58%|█████▊    | 58/100 [11:45<08:11, 11.71s/it] 59%|█████▉    | 59/100 [11:55<07:41, 11.26s/it] 60%|██████    | 60/100 [12:14<08:58, 13.47s/it]Epoch 60: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8200 / 0.6993 / 0.6774 / 0.9275
                Test acc/f1/spec/sens = 0.3689 / 0.2476 / 0.1625 / 0.9048
 61%|██████    | 61/100 [12:24<08:06, 12.47s/it] 62%|██████▏   | 62/100 [12:35<07:39, 12.08s/it] 63%|██████▎   | 63/100 [12:45<07:05, 11.49s/it] 64%|██████▍   | 64/100 [12:57<06:51, 11.42s/it] 65%|██████▌   | 65/100 [13:14<07:41, 13.17s/it]Epoch 65: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8200 / 0.6993 / 0.6774 / 0.9275
                Test acc/f1/spec/sens = 0.3689 / 0.2476 / 0.1625 / 0.9048
 66%|██████▌   | 66/100 [13:25<07:07, 12.58s/it] 67%|██████▋   | 67/100 [13:35<06:30, 11.82s/it] 68%|██████▊   | 68/100 [13:46<06:12, 11.63s/it] 69%|██████▉   | 69/100 [13:57<05:46, 11.19s/it] 70%|███████   | 70/100 [14:15<06:40, 13.35s/it]Epoch 70: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8200 / 0.6993 / 0.6774 / 0.9275
                Test acc/f1/spec/sens = 0.3689 / 0.2476 / 0.1625 / 0.9048
 71%|███████   | 71/100 [14:25<05:58, 12.36s/it] 72%|███████▏  | 72/100 [14:36<05:36, 12.02s/it] 73%|███████▎  | 73/100 [14:46<05:09, 11.45s/it] 74%|███████▍  | 74/100 [14:58<04:55, 11.38s/it] 75%|███████▌  | 75/100 [15:15<05:31, 13.25s/it]Epoch 75: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8200 / 0.6993 / 0.6774 / 0.9275
                Test acc/f1/spec/sens = 0.3689 / 0.2476 / 0.1625 / 0.9048
 76%|███████▌  | 76/100 [15:26<05:02, 12.62s/it] 77%|███████▋  | 77/100 [15:36<04:32, 11.86s/it] 78%|███████▊  | 78/100 [15:48<04:16, 11.67s/it] 79%|███████▉  | 79/100 [15:58<03:55, 11.21s/it] 80%|████████  | 80/100 [16:17<04:30, 13.53s/it]Epoch 80: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8200 / 0.6993 / 0.6774 / 0.9275
                Test acc/f1/spec/sens = 0.3689 / 0.2476 / 0.1625 / 0.9048
 81%|████████  | 81/100 [16:27<03:57, 12.49s/it] 82%|████████▏ | 82/100 [16:38<03:38, 12.13s/it] 83%|████████▎ | 83/100 [16:48<03:15, 11.52s/it] 84%|████████▍ | 84/100 [16:59<03:02, 11.44s/it] 85%|████████▌ | 85/100 [17:17<03:18, 13.26s/it]Epoch 85: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8200 / 0.6993 / 0.6774 / 0.9275
                Test acc/f1/spec/sens = 0.3689 / 0.2476 / 0.1625 / 0.9048
 86%|████████▌ | 86/100 [17:28<02:56, 12.62s/it] 87%|████████▋ | 87/100 [17:38<02:34, 11.86s/it] 88%|████████▊ | 88/100 [17:49<02:20, 11.69s/it] 89%|████████▉ | 89/100 [18:00<02:03, 11.21s/it] 90%|█████████ | 90/100 [18:18<02:14, 13.44s/it]Epoch 90: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8200 / 0.6993 / 0.6774 / 0.9275
                Test acc/f1/spec/sens = 0.3689 / 0.2476 / 0.1625 / 0.9048
 91%|█████████ | 91/100 [18:28<01:51, 12.43s/it] 92%|█████████▏| 92/100 [18:40<01:36, 12.09s/it] 93%|█████████▎| 93/100 [18:50<01:20, 11.51s/it] 94%|█████████▍| 94/100 [19:01<01:08, 11.46s/it] 95%|█████████▌| 95/100 [19:19<01:06, 13.28s/it]Epoch 95: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8200 / 0.6993 / 0.6774 / 0.9275
                Test acc/f1/spec/sens = 0.3689 / 0.2476 / 0.1625 / 0.9048
 96%|█████████▌| 96/100 [19:30<00:50, 12.73s/it] 97%|█████████▋| 97/100 [19:40<00:35, 11.94s/it] 98%|█████████▊| 98/100 [19:51<00:23, 11.76s/it] 99%|█████████▉| 99/100 [20:02<00:11, 11.26s/it]100%|██████████| 100/100 [20:20<00:00, 13.46s/it]                                                 Epoch 100: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8200 / 0.6993 / 0.6774 / 0.9275
                Test acc/f1/spec/sens = 0.3689 / 0.2476 / 0.1625 / 0.9048
specificity = 319/319
sensitivity = 581/581
specificity = 21/31
sensitivity = 64/69
specificity = 13/80
sensitivity = 38/42
Trial 5, Cycle 1
Train acc/f1/spec/sens = 1.0000 / 1.0000 / 1.0000 / 1.0000
Val acc/f1/spec/sens = 0.8200 / 0.6993 / 0.6774 / 0.9275
Test acc/f1/spec/sens = 0.3689 / 0.2476 / 0.1625 / 0.9048
>> Finished.
specificity = 13/80
sensitivity = 38/42
Acc, agreement for latest model:  0.36885245901639346 0.4262295081967213
Load best checkpoint for thief model
specificity = 14/80
sensitivity = 37/42
Acc, agreement for best model:  0.36065573770491804 0.4180327868852459
Trial 4/5 || Cycle 1/1 || Label set size 900 || Test acc 0.3607 || Test agreement 0.4180 || Spec 0.1750 || Sens 0.8810
**************************************************************************************************** 

specificity = 14/80
sensitivity = 37/42
Number of samples  900
0.4065573770491803 0.032208004433423774
        acc       agr    spec      sens                label dist
0  0.401639  0.377049  0.5250  0.666667  {0: 111, 1: 200, 2: 589}
1  0.368852  0.409836  0.3625  0.619048  {0: 102, 1: 220, 2: 578}
2  0.393443  0.459016  0.3250  0.904762   {0: 98, 1: 215, 2: 587}
3  0.319672  0.368852  0.6500  0.357143  {0: 114, 1: 210, 2: 576}
4  0.360656  0.418033  0.1750  0.880952  {0: 101, 1: 218, 2: 581}
Results saved to  /home/deepankar/scratch/MSA_Medical/results_1k/gbusg_radformer/GBUSV_vit/SGD/1000_val100/random_v1
