nohup: ignoring input
[24/02/14 17:38:13] [conf.py:  281]: PyTorch Version: torch=1.11.0, cuda=11.3, cudnn=8200
[24/02/14 17:38:13] [conf.py:  283]: ACTIVE:
  ADDENDUM: 0
  ALPHA: 0.0
  AUGMENT: None
  BETA: 1.0
  BUDGET: 2000
  CUTMIX_PROB: 0.0
  CYCLES: 1
  INITIAL: 1800
  LA: False
  METHOD: random
  PRETRAINED_PATH: /home/ankita/scratch/MSA_results/ckpts/resnet50-imagenet1k.pth
  TEMP: 1.0
  TRO: 1.0
  USE_PRETRAINED: True
  VAL: 200
AM:
  SGR: 1000
  THRESHOLD: 0.5
CUDNN_BENCHMARK: True
DS_SEED: 123
EDM:
  HASH: /home/harsh_s/scratch/msacopy/exp/hash/alpha.pt
  NUM_MODELS: 5
  PATH1: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T0.pt
  PATH2: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T1.pt
  PATH3: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T2.pt
  PATH4: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T3.pt
  PATH5: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T4.pt
GR:
  EPSILON: 0.1
  SUR_PATH: /home/harsh_s/scratch/msacopy/GRAD2/batch_training/outputs/trained_models/imagenet_cifar10_to_cifar10_surrogate_10epochs.pt
LOG_DEST: radformer_gbusv_240214_173813.txt
LOG_TIME: 240214_173813
METHOD_NAME: 
OUT_DIR: results
RNG_SEED: 1
SAVE_DIR: results/gbusg_radformer/GBUSV_benign_resnet50/SGD/2000_val200/random_
THIEF:
  ARCH: resnet50
  DATASET: GBUSV_benign
  DATA_ROOT: /home/ankita/scratch/Datasets/GBUSV-Shared
  HARD_LABELS: True
  NUM_TRAIN: 1281167
  SUBSET: 128116
TRAIN:
  BATCH: 128
  EPOCH: 50
  GAMMA: 0.1
  LR: 0.02
  MILESTONES: [60, 120, 180]
  MOMENTUM: 0.9
  OPTIMIZER: SGD
  WDECAY: 0.0005
VICTIM:
  ARCH: radformer
  DATASET: gbusg
  DATA_ROOT: /home/ankita/scratch/Datasets/GBCU-Shared
  HEIGHT: 224
  PATH: victim_models/radformer/radformer.pkl
  PATHIN: /home/harsh_s/scratch/msacopy/ckpts/cifar10-resnet32-inaccurate/checkpoint.pth.tar
  WIDTH: 224
Loaded target dataset of size 122 with 3 classes
target model keys:  695
checkpoint keys:  695
specificity = 72/80
sensitivity = 39/42

Target model acc = 0.9016393442622951
Val-Acc: 0.9016 Val-Spec: 0.9000 Val-Sens: 0.9286
Num of videos 32 frames 3549
Num of videos 32 frames 3549
replacing labeled set labels with victim labels
  0%|          | 0/15 [00:00<?, ?it/s]  7%|▋         | 1/15 [00:03<00:42,  3.04s/it] 13%|█▎        | 2/15 [00:05<00:32,  2.50s/it] 20%|██        | 3/15 [00:07<00:26,  2.20s/it] 27%|██▋       | 4/15 [00:09<00:23,  2.17s/it] 33%|███▎      | 5/15 [00:11<00:21,  2.19s/it] 40%|████      | 6/15 [00:13<00:20,  2.31s/it] 47%|████▋     | 7/15 [00:16<00:18,  2.35s/it] 53%|█████▎    | 8/15 [00:19<00:17,  2.54s/it] 60%|██████    | 9/15 [00:21<00:14,  2.46s/it] 67%|██████▋   | 10/15 [00:24<00:13,  2.64s/it] 73%|███████▎  | 11/15 [00:27<00:10,  2.73s/it] 80%|████████  | 12/15 [00:31<00:09,  3.03s/it] 87%|████████▋ | 13/15 [00:34<00:06,  3.07s/it] 93%|█████████▎| 14/15 [00:37<00:03,  3.06s/it]100%|██████████| 15/15 [00:37<00:00,  2.22s/it]100%|██████████| 15/15 [00:37<00:00,  2.53s/it]
replacing val labels with victim labels
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:04<00:04,  4.89s/it]100%|██████████| 2/2 [00:07<00:00,  3.43s/it]100%|██████████| 2/2 [00:07<00:00,  3.78s/it]Validation set distribution: 
Number of samples  200

{0: 101, 1: 61, 2: 38}
Labeled set distribution: 
Number of samples  1800
{0: 934, 1: 536, 2: 330}
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.weight', 'fc.bias'])
thief state:  None
Load pretrained model for initializing the thief
pretrained state:  dict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked'])
Thief model initialized successfully
specificity = 79/80
sensitivity = 0/42
Initial model on target dataset: acc = 0.3934, agreement = 0.3689, f1 = 0.1882, spec = 0.9875, sens = 0.0000
specificity = 157/162
sensitivity = 0/38
Initial model on validation dataset: acc = 0.2950, agreement = 0.2950, f1 = 0.1536, spec = 0.9691, sens = 0.0000
la:  None
>> Train a Model.
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:03<03:06,  3.80s/it]epoch 0, loss = 116.8456039428711
epoch 1, loss = 77.94763946533203
  4%|▍         | 2/50 [00:09<03:46,  4.73s/it]  6%|▌         | 3/50 [00:12<03:20,  4.27s/it]epoch 2, loss = 48.111915588378906
epoch 3, loss = 35.37261199951172
  8%|▊         | 4/50 [00:18<03:37,  4.73s/it]epoch 4, loss = 34.15297317504883
 10%|█         | 5/50 [00:28<05:03,  6.74s/it]Epoch 5: Train acc/f1 = 0.8372 / 0.8195 / 0.9959 / 0.6424 
                Val acc/f1/spec/sens = 0.7400 / 0.7237 / 0.9383 / 0.6579
                Test acc/f1/spec/sens = 0.4836 / 0.3744 / 0.9875 / 0.0000
epoch 5, loss = 23.503782272338867
 12%|█▏        | 6/50 [00:34<04:40,  6.38s/it] 14%|█▍        | 7/50 [00:38<03:59,  5.56s/it]epoch 6, loss = 16.45527458190918
epoch 7, loss = 12.791706085205078
 16%|█▌        | 8/50 [00:43<03:53,  5.56s/it] 18%|█▊        | 9/50 [00:47<03:26,  5.05s/it]epoch 8, loss = 12.334731101989746
epoch 9, loss = 8.39673137664795
 20%|██        | 10/50 [00:59<04:50,  7.25s/it]Epoch 10: Train acc/f1 = 0.8356 / 0.8481 / 0.9633 / 0.9788 
                Val acc/f1/spec/sens = 0.7000 / 0.6903 / 0.9136 / 0.6579
                Test acc/f1/spec/sens = 0.4590 / 0.3578 / 0.9625 / 0.0000
 22%|██▏       | 11/50 [01:03<04:05,  6.29s/it]epoch 10, loss = 11.066169738769531
epoch 11, loss = 35.53267288208008
 24%|██▍       | 12/50 [01:09<03:48,  6.02s/it] 26%|██▌       | 13/50 [01:13<03:18,  5.36s/it]epoch 12, loss = 28.558218002319336
epoch 13, loss = 14.726225852966309
 28%|██▊       | 14/50 [01:18<03:15,  5.44s/it]epoch 14, loss = 14.697325706481934
 30%|███       | 15/50 [01:29<04:06,  7.03s/it]Epoch 15: Train acc/f1 = 0.9406 / 0.9311 / 0.9796 / 0.9061 
                Val acc/f1/spec/sens = 0.8050 / 0.7753 / 0.9630 / 0.6053
                Test acc/f1/spec/sens = 0.5000 / 0.4659 / 0.9250 / 0.1905
epoch 15, loss = 6.634214401245117
 32%|███▏      | 16/50 [01:34<03:41,  6.51s/it] 34%|███▍      | 17/50 [01:38<03:07,  5.69s/it]epoch 16, loss = 10.766315460205078
epoch 17, loss = 21.47278594970703
 36%|███▌      | 18/50 [01:44<03:00,  5.63s/it] 38%|███▊      | 19/50 [01:47<02:37,  5.09s/it]epoch 18, loss = 8.639427185058594
epoch 19, loss = 4.069918632507324
 40%|████      | 20/50 [02:00<03:39,  7.33s/it]Epoch 20: Train acc/f1 = 0.9950 / 0.9950 / 1.0000 / 0.9939 
                Val acc/f1/spec/sens = 0.8600 / 0.8403 / 0.9753 / 0.7368
                Test acc/f1/spec/sens = 0.5328 / 0.4720 / 1.0000 / 0.0952
 42%|████▏     | 21/50 [02:04<03:03,  6.33s/it]epoch 20, loss = 2.2399516105651855
epoch 21, loss = 42.15608596801758
 44%|████▍     | 22/50 [02:09<02:49,  6.06s/it] 46%|████▌     | 23/50 [02:13<02:26,  5.43s/it]epoch 22, loss = 25.793317794799805
epoch 23, loss = 9.684558868408203
 48%|████▊     | 24/50 [02:19<02:19,  5.37s/it]epoch 24, loss = 3.465343475341797
 50%|█████     | 25/50 [02:29<02:50,  6.82s/it]Epoch 25: Train acc/f1 = 0.9972 / 0.9972 / 0.9986 / 1.0000 
                Val acc/f1/spec/sens = 0.8150 / 0.7811 / 0.9136 / 0.7368
                Test acc/f1/spec/sens = 0.5820 / 0.5657 / 0.9125 / 0.2381
epoch 25, loss = 1.0935391187667847
 52%|█████▏    | 26/50 [02:34<02:32,  6.36s/it] 54%|█████▍    | 27/50 [02:38<02:08,  5.59s/it]epoch 26, loss = 4.187719345092773
epoch 27, loss = 4.63272762298584
 56%|█████▌    | 28/50 [02:43<02:01,  5.52s/it] 58%|█████▊    | 29/50 [02:47<01:46,  5.05s/it]epoch 28, loss = 3.0058882236480713
epoch 29, loss = 1.7165329456329346
 60%|██████    | 30/50 [02:59<02:18,  6.95s/it]Epoch 30: Train acc/f1 = 0.9900 / 0.9881 / 0.9993 / 0.9606 
                Val acc/f1/spec/sens = 0.8300 / 0.7862 / 0.9568 / 0.5789
                Test acc/f1/spec/sens = 0.5164 / 0.4519 / 0.9875 / 0.0952
 62%|██████▏   | 31/50 [03:03<01:55,  6.08s/it]epoch 30, loss = 14.08423137664795
epoch 31, loss = 10.07154655456543
 64%|██████▍   | 32/50 [03:08<01:44,  5.81s/it] 66%|██████▌   | 33/50 [03:12<01:28,  5.20s/it]epoch 32, loss = 5.376667499542236
epoch 33, loss = 1.953896403312683
 68%|██████▊   | 34/50 [03:17<01:22,  5.18s/it]epoch 34, loss = 3.518970012664795
 70%|███████   | 35/50 [03:27<01:38,  6.56s/it]Epoch 35: Train acc/f1 = 0.9961 / 0.9945 / 1.0000 / 0.9788 
                Val acc/f1/spec/sens = 0.8550 / 0.8282 / 0.9630 / 0.7105
                Test acc/f1/spec/sens = 0.5082 / 0.4797 / 0.9875 / 0.1905
epoch 35, loss = 18.259803771972656
 72%|███████▏  | 36/50 [03:32<01:25,  6.13s/it] 74%|███████▍  | 37/50 [03:35<01:10,  5.44s/it]epoch 36, loss = 10.924817085266113
epoch 37, loss = 4.07147741317749
 76%|███████▌  | 38/50 [03:41<01:05,  5.43s/it] 78%|███████▊  | 39/50 [03:45<00:54,  4.97s/it]epoch 38, loss = 17.888269424438477
epoch 39, loss = 12.090709686279297
 80%|████████  | 40/50 [03:56<01:08,  6.84s/it]Epoch 40: Train acc/f1 = 0.9811 / 0.9785 / 0.9980 / 0.9455 
                Val acc/f1/spec/sens = 0.8400 / 0.8097 / 0.9753 / 0.6316
                Test acc/f1/spec/sens = 0.4672 / 0.4175 / 0.9500 / 0.0714
 82%|████████▏ | 41/50 [04:00<00:53,  5.94s/it]epoch 40, loss = 4.481625080108643
epoch 41, loss = 3.299344778060913
 84%|████████▍ | 42/50 [04:05<00:45,  5.72s/it] 86%|████████▌ | 43/50 [04:09<00:36,  5.16s/it]epoch 42, loss = 1.7753281593322754
epoch 43, loss = 6.998290061950684
 88%|████████▊ | 44/50 [04:14<00:31,  5.23s/it]epoch 44, loss = 4.272289276123047
 90%|█████████ | 45/50 [04:25<00:34,  6.81s/it]Epoch 45: Train acc/f1 = 0.9972 / 0.9962 / 0.9986 / 0.9909 
                Val acc/f1/spec/sens = 0.8200 / 0.7794 / 0.9321 / 0.6579
                Test acc/f1/spec/sens = 0.5656 / 0.4730 / 1.0000 / 0.0000
epoch 45, loss = 2.265031576156616
 92%|█████████▏| 46/50 [04:30<00:25,  6.36s/it] 94%|█████████▍| 47/50 [04:34<00:16,  5.63s/it]epoch 46, loss = 8.219364166259766
epoch 47, loss = 7.21226167678833
 96%|█████████▌| 48/50 [04:39<00:11,  5.54s/it] 98%|█████████▊| 49/50 [04:43<00:05,  5.04s/it]epoch 48, loss = 11.521280288696289
epoch 49, loss = 10.450933456420898
100%|██████████| 50/50 [04:55<00:00,  6.95s/it]                                               Epoch 50: Train acc/f1 = 0.9572 / 0.9460 / 0.9980 / 0.8515 
                Val acc/f1/spec/sens = 0.8100 / 0.7626 / 0.9753 / 0.5000
                Test acc/f1/spec/sens = 0.5656 / 0.5095 / 0.9750 / 0.0952
specificity = 1467/1470
sensitivity = 281/330
specificity = 158/162
sensitivity = 19/38
specificity = 78/80
sensitivity = 4/42
Trial 1, Cycle 1
Train acc/f1/spec/sens = 0.9572 / 0.9460 / 0.9980 / 0.8515
Val acc/f1/spec/sens = 0.8100 / 0.7626 / 0.9753 / 0.5000
Test acc/f1/spec/sens = 0.5656 / 0.5095 / 0.9750 / 0.0952
>> Finished.
specificity = 78/80
sensitivity = 4/42
Acc, agreement for latest model:  0.5655737704918032 0.5409836065573771
Load best checkpoint for thief model
specificity = 80/80
sensitivity = 4/42
Acc, agreement for best model:  0.5327868852459017 0.48360655737704916
Trial 0/1 || Cycle 1/1 || Label set size 1800 || Test acc 0.5328 || Test agreement 0.4836 || Spec 1.0000 || Sens 0.0952
**************************************************************************************************** 

specificity = 80/80
sensitivity = 4/42
Number of samples  1800
0.48360655737704916 0.0
        acc       agr  spec      sens                label dist
0  0.532787  0.483607   1.0  0.095238  {0: 934, 1: 536, 2: 330}
Results saved to  results/gbusg_radformer/GBUSV_benign_resnet50/SGD/2000_val200/random_
