nohup: ignoring input
[24/02/15 17:10:01] [conf.py:  281]: PyTorch Version: torch=1.10.0, cuda=11.3, cudnn=8200
[24/02/15 17:10:01] [conf.py:  283]: ACTIVE:
  ADDENDUM: 0
  ALPHA: 0.1
  AUGMENT: None
  BETA: 1.0
  BUDGET: 5000
  CUTMIX_PROB: 0.0
  CYCLES: 1
  INITIAL: 4500
  LA: False
  METHOD: random
  PRETRAINED_PATH: /home/ankita/scratch/MSA_results/ckpts/resnet50-imagenet1k.pth
  TEMP: 10.0
  TRO: 1.0
  USE_PRETRAINED: True
  VAL: 500
AM:
  SGR: 1000
  THRESHOLD: 0.5
CUDNN_BENCHMARK: True
DS_SEED: 123
EDM:
  HASH: /home/harsh_s/scratch/msacopy/exp/hash/alpha.pt
  NUM_MODELS: 5
  PATH1: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T0.pt
  PATH2: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T1.pt
  PATH3: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T2.pt
  PATH4: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T3.pt
  PATH5: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T4.pt
GR:
  EPSILON: 0.1
  SUR_PATH: /home/harsh_s/scratch/msacopy/GRAD2/batch_training/outputs/trained_models/imagenet_cifar10_to_cifar10_surrogate_10epochs.pt
LOG_DEST: radformer_gbusv_240215_171001.txt
LOG_TIME: 240215_171001
METHOD_NAME: soft_alpha_p1_temp_10_lr2
OUT_DIR: results
RNG_SEED: 1
SAVE_DIR: results/gbusg_radformer/GBUSV_resnet50/SGD/5000_val500/random_soft_alpha_p1_temp_10_lr2
THIEF:
  ARCH: resnet50
  DATASET: GBUSV
  DATA_ROOT: /home/ankita/scratch/Datasets/GBUSV-Shared
  HARD_LABELS: False
  NUM_TRAIN: 1281167
  SUBSET: 128116
TRAIN:
  BATCH: 128
  EPOCH: 50
  GAMMA: 0.1
  LR: 0.2
  MILESTONES: [60, 120, 180]
  MOMENTUM: 0.9
  OPTIMIZER: SGD
  WDECAY: 0.0005
VICTIM:
  ARCH: radformer
  DATASET: gbusg
  DATA_ROOT: /home/ankita/scratch/Datasets/GBCU-Shared
  HEIGHT: 224
  PATH: victim_models/radformer/radformer.pkl
  PATHIN: /home/harsh_s/scratch/msacopy/ckpts/cifar10-resnet32-inaccurate/checkpoint.pth.tar
  WIDTH: 224
Loaded target dataset of size 122 with 3 classes
target model keys:  695
checkpoint keys:  695
specificity = 72/80
sensitivity = 39/42

Target model acc = 0.9016393442622951
Val-Acc: 0.9016 Val-Spec: 0.9000 Val-Sens: 0.9286
/home/ankita/scratch/Datasets/GBUSV-Shared/all_names.pkl
Num of videos 64 frames 15800
/home/ankita/scratch/Datasets/GBUSV-Shared/all_names.pkl
Num of videos 64 frames 15800
replacing labeled set labels with victim labels
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:02<01:18,  2.24s/it]  6%|▌         | 2/36 [00:03<00:54,  1.60s/it]  8%|▊         | 3/36 [00:04<00:45,  1.39s/it] 11%|█         | 4/36 [00:05<00:41,  1.30s/it] 14%|█▍        | 5/36 [00:06<00:38,  1.25s/it] 17%|█▋        | 6/36 [00:07<00:36,  1.21s/it] 19%|█▉        | 7/36 [00:09<00:34,  1.18s/it] 22%|██▏       | 8/36 [00:10<00:32,  1.17s/it] 25%|██▌       | 9/36 [00:11<00:31,  1.16s/it] 28%|██▊       | 10/36 [00:12<00:29,  1.14s/it] 31%|███       | 11/36 [00:13<00:27,  1.10s/it] 33%|███▎      | 12/36 [00:14<00:26,  1.10s/it] 36%|███▌      | 13/36 [00:15<00:25,  1.12s/it] 39%|███▉      | 14/36 [00:16<00:24,  1.13s/it] 42%|████▏     | 15/36 [00:18<00:23,  1.13s/it] 44%|████▍     | 16/36 [00:19<00:22,  1.12s/it] 47%|████▋     | 17/36 [00:20<00:21,  1.11s/it] 50%|█████     | 18/36 [00:21<00:19,  1.07s/it] 53%|█████▎    | 19/36 [00:22<00:18,  1.07s/it] 56%|█████▌    | 20/36 [00:23<00:16,  1.05s/it] 58%|█████▊    | 21/36 [00:24<00:15,  1.02s/it] 61%|██████    | 22/36 [00:25<00:14,  1.00s/it] 64%|██████▍   | 23/36 [00:26<00:12,  1.01it/s] 67%|██████▋   | 24/36 [00:27<00:12,  1.03s/it] 69%|██████▉   | 25/36 [00:28<00:11,  1.02s/it] 72%|███████▏  | 26/36 [00:29<00:10,  1.02s/it] 75%|███████▌  | 27/36 [00:30<00:09,  1.02s/it] 78%|███████▊  | 28/36 [00:31<00:08,  1.04s/it] 81%|████████  | 29/36 [00:32<00:07,  1.03s/it] 83%|████████▎ | 30/36 [00:33<00:06,  1.02s/it] 86%|████████▌ | 31/36 [00:34<00:05,  1.01s/it] 89%|████████▉ | 32/36 [00:35<00:03,  1.00it/s] 92%|█████████▏| 33/36 [00:36<00:03,  1.02s/it] 94%|█████████▍| 34/36 [00:37<00:01,  1.00it/s] 97%|█████████▋| 35/36 [00:38<00:01,  1.01s/it]100%|██████████| 36/36 [00:38<00:00,  1.31it/s]100%|██████████| 36/36 [00:38<00:00,  1.08s/it]
replacing val labels with victim labels
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:05,  1.93s/it] 50%|█████     | 2/4 [00:02<00:02,  1.39s/it] 75%|███████▌  | 3/4 [00:03<00:01,  1.19s/it]100%|██████████| 4/4 [00:04<00:00,  1.10s/it]100%|██████████| 4/4 [00:05<00:00,  1.25s/it]
Validation set distribution: 
Number of samples  500
{0: 74, 1: 125, 2: 301}
Labeled set distribution: 
Number of samples  4500
{0: 581, 1: 1070, 2: 2849}
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.weight', 'fc.bias'])
thief state:  None
Load pretrained model for initializing the thief
pretrained state:  dict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked'])
Thief model initialized successfully
specificity = 79/80
sensitivity = 0/42
Initial model on target dataset: acc = 0.3934, agreement = 0.3689, f1 = 0.1882, spec = 0.9875, sens = 0.0000
specificity = 179/199
sensitivity = 26/301
Initial model on validation dataset: acc = 0.2740, agreement = 0.2740, f1 = 0.1778, spec = 0.8995, sens = 0.0864
la:  None
>> Train a Model.
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:07<06:20,  7.76s/it]  4%|▍         | 2/50 [00:16<06:51,  8.58s/it]  6%|▌         | 3/50 [00:24<06:17,  8.03s/it]  8%|▊         | 4/50 [00:33<06:29,  8.47s/it] 10%|█         | 5/50 [00:49<08:26, 11.25s/it]specificity = 1596/1651
sensitivity = 2567/2849
specificity = 55/80
sensitivity = 27/42
Epoch 5: Train acc/f1 = 0.9062 / 0.8893 
                Val acc/f1 = 0.8760 / 0.8458 
                Test acc/f1 = 0.5656 / 0.5804
 12%|█▏        | 6/50 [00:58<07:43, 10.53s/it] 14%|█▍        | 7/50 [01:06<06:51,  9.57s/it] 16%|█▌        | 8/50 [01:15<06:37,  9.46s/it] 18%|█▊        | 9/50 [01:23<06:04,  8.90s/it] 20%|██        | 10/50 [01:41<07:53, 11.83s/it]specificity = 1581/1651
sensitivity = 2781/2849
specificity = 54/80
sensitivity = 27/42
Epoch 10: Train acc/f1 = 0.9598 / 0.9490 
                Val acc/f1 = 0.8860 / 0.8572 
                Test acc/f1 = 0.5574 / 0.5651
 22%|██▏       | 11/50 [01:49<06:52, 10.57s/it] 24%|██▍       | 12/50 [01:58<06:25, 10.16s/it] 26%|██▌       | 13/50 [02:06<05:48,  9.41s/it] 28%|██▊       | 14/50 [02:15<05:36,  9.35s/it] 30%|███       | 15/50 [02:31<06:41, 11.48s/it]specificity = 1599/1651
sensitivity = 2833/2849
specificity = 50/80
sensitivity = 29/42
Epoch 15: Train acc/f1 = 0.9760 / 0.9659 
                Val acc/f1 = 0.8680 / 0.8430 
                Test acc/f1 = 0.4836 / 0.4621
 32%|███▏      | 16/50 [02:41<06:07, 10.81s/it] 34%|███▍      | 17/50 [02:48<05:24,  9.85s/it] 36%|███▌      | 18/50 [02:58<05:10,  9.72s/it] 38%|███▊      | 19/50 [03:05<04:41,  9.10s/it] 40%|████      | 20/50 [03:23<05:49, 11.64s/it]specificity = 1569/1651
sensitivity = 2704/2849
specificity = 61/80
sensitivity = 25/42
Epoch 20: Train acc/f1 = 0.9400 / 0.9219 
                Val acc/f1 = 0.8580 / 0.8362 
                Test acc/f1 = 0.5410 / 0.5371
 42%|████▏     | 21/50 [03:30<05:02, 10.44s/it] 44%|████▍     | 22/50 [03:40<04:40, 10.02s/it] 46%|████▌     | 23/50 [03:47<04:09,  9.25s/it] 48%|████▊     | 24/50 [03:56<03:58,  9.18s/it] 50%|█████     | 25/50 [04:12<04:41, 11.26s/it]specificity = 1642/1651
sensitivity = 2652/2849
specificity = 66/80
sensitivity = 17/42
Epoch 25: Train acc/f1 = 0.9484 / 0.9435 
                Val acc/f1 = 0.8720 / 0.8360 
                Test acc/f1 = 0.5164 / 0.5104
 52%|█████▏    | 26/50 [04:21<04:14, 10.62s/it] 54%|█████▍    | 27/50 [04:29<03:43,  9.71s/it] 56%|█████▌    | 28/50 [04:38<03:29,  9.54s/it] 58%|█████▊    | 29/50 [04:45<03:07,  8.93s/it] 60%|██████    | 30/50 [05:03<03:51, 11.56s/it]specificity = 1579/1651
sensitivity = 2708/2849
specificity = 50/80
sensitivity = 34/42
Epoch 30: Train acc/f1 = 0.9369 / 0.9212 
                Val acc/f1 = 0.8240 / 0.7893 
                Test acc/f1 = 0.5574 / 0.5068
 62%|██████▏   | 31/50 [05:11<03:17, 10.38s/it] 64%|██████▍   | 32/50 [05:20<03:00, 10.04s/it] 66%|██████▌   | 33/50 [05:28<02:37,  9.29s/it] 68%|██████▊   | 34/50 [05:37<02:27,  9.23s/it] 70%|███████   | 35/50 [05:52<02:48, 11.21s/it]specificity = 1495/1651
sensitivity = 2844/2849
specificity = 33/80
sensitivity = 37/42
Epoch 35: Train acc/f1 = 0.9573 / 0.9426 
                Val acc/f1 = 0.8120 / 0.7939 
                Test acc/f1 = 0.4754 / 0.4384
 72%|███████▏  | 36/50 [06:02<02:28, 10.60s/it] 74%|███████▍  | 37/50 [06:09<02:05,  9.67s/it] 76%|███████▌  | 38/50 [06:18<01:53,  9.45s/it] 78%|███████▊  | 39/50 [06:26<01:38,  8.93s/it] 80%|████████  | 40/50 [06:43<01:54, 11.46s/it]specificity = 1625/1651
sensitivity = 2501/2849
specificity = 65/80
sensitivity = 21/42
Epoch 40: Train acc/f1 = 0.9082 / 0.9066 
                Val acc/f1 = 0.8060 / 0.8000 
                Test acc/f1 = 0.5328 / 0.4974
 82%|████████▏ | 41/50 [06:51<01:32, 10.30s/it] 84%|████████▍ | 42/50 [07:00<01:20, 10.01s/it] 86%|████████▌ | 43/50 [07:08<01:05,  9.29s/it] 88%|████████▊ | 44/50 [07:17<00:55,  9.19s/it] 90%|█████████ | 45/50 [07:33<00:56, 11.25s/it]specificity = 1640/1651
sensitivity = 2753/2849
specificity = 63/80
sensitivity = 16/42
Epoch 45: Train acc/f1 = 0.9718 / 0.9662 
                Val acc/f1 = 0.5920 / 0.6380 
                Test acc/f1 = 0.4918 / 0.4805
 92%|█████████▏| 46/50 [07:42<00:42, 10.55s/it] 94%|█████████▍| 47/50 [07:49<00:28,  9.67s/it] 96%|█████████▌| 48/50 [07:59<00:19,  9.56s/it] 98%|█████████▊| 49/50 [08:06<00:08,  8.94s/it]100%|██████████| 50/50 [08:25<00:00, 11.91s/it]                                               specificity = 1624/1651
sensitivity = 2775/2849
specificity = 61/80
sensitivity = 23/42
Epoch 50: Train acc/f1 = 0.9684 / 0.9584 
                Val acc/f1 = 0.8640 / 0.8304 
                Test acc/f1 = 0.4918 / 0.4451
specificity = 1624/1651
sensitivity = 2775/2849
specificity = 172/199
sensitivity = 277/301
specificity = 61/80
sensitivity = 23/42
Trial 1, Cycle 1
Train acc/f1/spec/sens = 0.9684 / 0.9584 / 0.9836 / 0.9740
Val acc/f1/spec/sens = 0.8640 / 0.8304 / 0.8643 / 0.9203
Test acc/f1/spec/sens = 0.4918 / 0.4451 / 0.7625 / 0.5476
>> Finished.
specificity = 61/80
sensitivity = 23/42
Acc, agreement for latest model:  0.4918032786885246 0.5
Load best checkpoint for thief model
specificity = 54/80
sensitivity = 27/42
Acc, agreement for best model:  0.5573770491803278 0.5573770491803278
Trial 0/1 || Cycle 1/1 || Label set size 4500 || Test acc 0.5574 || Test agreement 0.5574 || Spec 0.6750 || Sens 0.6429
**************************************************************************************************** 

specificity = 54/80
sensitivity = 27/42
Number of samples  4500
0.5573770491803278 0.0
        acc       agr   spec      sens                  label dist
0  0.557377  0.557377  0.675  0.642857  {0: 581, 1: 1070, 2: 2849}
Results saved to  results/gbusg_radformer/GBUSV_resnet50/SGD/5000_val500/random_soft_alpha_p1_temp_10_lr2
