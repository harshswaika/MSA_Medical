nohup: ignoring input
[24/02/14 18:09:31] [conf.py:  281]: PyTorch Version: torch=1.11.0, cuda=11.3, cudnn=8200
[24/02/14 18:09:31] [conf.py:  283]: ACTIVE:
  ADDENDUM: 0
  ALPHA: 0.0
  AUGMENT: None
  BETA: 1.0
  BUDGET: 2000
  CUTMIX_PROB: 0.0
  CYCLES: 1
  INITIAL: 1800
  LA: False
  METHOD: random
  PRETRAINED_PATH: /home/ankita/scratch/MSA_results/ckpts/resnet50-imagenet1k.pth
  TEMP: 1.0
  TRO: 1.0
  USE_PRETRAINED: True
  VAL: 200
AM:
  SGR: 1000
  THRESHOLD: 0.5
CUDNN_BENCHMARK: True
DS_SEED: 123
EDM:
  HASH: /home/harsh_s/scratch/msacopy/exp/hash/alpha.pt
  NUM_MODELS: 5
  PATH1: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T0.pt
  PATH2: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T1.pt
  PATH3: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T2.pt
  PATH4: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T3.pt
  PATH5: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T4.pt
GR:
  EPSILON: 0.1
  SUR_PATH: /home/harsh_s/scratch/msacopy/GRAD2/batch_training/outputs/trained_models/imagenet_cifar10_to_cifar10_surrogate_10epochs.pt
LOG_DEST: radformer_gbusv_240214_180931.txt
LOG_TIME: 240214_180931
METHOD_NAME: 
OUT_DIR: results
RNG_SEED: 1
SAVE_DIR: results/gbusg_radformer/GBUSV_resnet50/SGD/2000_val200/random_
THIEF:
  ARCH: resnet50
  DATASET: GBUSV
  DATA_ROOT: /home/ankita/scratch/Datasets/GBUSV-Shared
  HARD_LABELS: True
  NUM_TRAIN: 1281167
  SUBSET: 128116
TRAIN:
  BATCH: 128
  EPOCH: 50
  GAMMA: 0.1
  LR: 0.02
  MILESTONES: [60, 120, 180]
  MOMENTUM: 0.9
  OPTIMIZER: SGD
  WDECAY: 0.0005
VICTIM:
  ARCH: radformer
  DATASET: gbusg
  DATA_ROOT: /home/ankita/scratch/Datasets/GBCU-Shared
  HEIGHT: 224
  PATH: victim_models/radformer/radformer.pkl
  PATHIN: /home/harsh_s/scratch/msacopy/ckpts/cifar10-resnet32-inaccurate/checkpoint.pth.tar
  WIDTH: 224
Loaded target dataset of size 122 with 3 classes
target model keys:  695
checkpoint keys:  695
specificity = 72/80
sensitivity = 39/42

Target model acc = 0.9016393442622951
Val-Acc: 0.9016 Val-Spec: 0.9000 Val-Sens: 0.9286
/home/ankita/scratch/Datasets/GBUSV-Shared/all_names.pkl
create new cache
path ############ /home/ankita/scratch/Datasets/GBUSV-Shared
0it [00:00, ?it/s]15800it [00:00, 234974.18it/s]
Num of videos 64 frames 15800
/home/ankita/scratch/Datasets/GBUSV-Shared/all_names.pkl
Num of videos 64 frames 15800
replacing labeled set labels with victim labels
  0%|          | 0/15 [00:00<?, ?it/s]  7%|▋         | 1/15 [00:03<00:43,  3.14s/it] 13%|█▎        | 2/15 [00:05<00:34,  2.69s/it] 20%|██        | 3/15 [00:08<00:32,  2.68s/it] 27%|██▋       | 4/15 [00:11<00:30,  2.75s/it] 33%|███▎      | 5/15 [00:14<00:29,  2.90s/it] 40%|████      | 6/15 [00:17<00:26,  2.96s/it] 47%|████▋     | 7/15 [00:20<00:24,  3.10s/it] 53%|█████▎    | 8/15 [00:24<00:23,  3.32s/it] 60%|██████    | 9/15 [00:28<00:21,  3.55s/it] 67%|██████▋   | 10/15 [00:32<00:18,  3.60s/it] 73%|███████▎  | 11/15 [00:35<00:13,  3.48s/it] 80%|████████  | 12/15 [00:40<00:11,  3.92s/it] 87%|████████▋ | 13/15 [00:45<00:08,  4.31s/it] 93%|█████████▎| 14/15 [00:50<00:04,  4.40s/it]100%|██████████| 15/15 [00:50<00:00,  3.16s/it]100%|██████████| 15/15 [00:50<00:00,  3.39s/it]
replacing val labels with victim labels
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:04<00:04,  4.88s/it]100%|██████████| 2/2 [00:06<00:00,  3.17s/it]100%|██████████| 2/2 [00:07<00:00,  3.56s/it]Validation set distribution: 
Number of samples  200

{0: 33, 1: 50, 2: 117}
Labeled set distribution: 
Number of samples  1800
{0: 292, 1: 430, 2: 1078}
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.weight', 'fc.bias'])
thief state:  None
Load pretrained model for initializing the thief
pretrained state:  dict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked'])
Thief model initialized successfully
specificity = 79/80
sensitivity = 0/42
Initial model on target dataset: acc = 0.3934, agreement = 0.3689, f1 = 0.1882, spec = 0.9875, sens = 0.0000
specificity = 75/83
sensitivity = 6/117
Initial model on validation dataset: acc = 0.2450, agreement = 0.2450, f1 = 0.1525, spec = 0.9036, sens = 0.0513
la:  None
>> Train a Model.
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:03<03:01,  3.70s/it]epoch 0, loss = 95.75213623046875
epoch 1, loss = 62.19059753417969
  4%|▍         | 2/50 [00:08<03:39,  4.56s/it]  6%|▌         | 3/50 [00:12<03:15,  4.16s/it]epoch 2, loss = 40.421531677246094
epoch 3, loss = 23.641775131225586
  8%|▊         | 4/50 [00:18<03:36,  4.70s/it]epoch 4, loss = 26.007638931274414
 10%|█         | 5/50 [00:28<05:02,  6.73s/it]Epoch 5: Train acc/f1 = 0.7078 / 0.7000 / 0.9792 / 0.6308 
                Val acc/f1/spec/sens = 0.8150 / 0.7496 / 0.9036 / 0.8889
                Test acc/f1/spec/sens = 0.4098 / 0.3346 / 0.9625 / 0.0000
epoch 5, loss = 23.404926300048828
 12%|█▏        | 6/50 [00:34<04:42,  6.41s/it] 14%|█▍        | 7/50 [00:38<04:03,  5.65s/it]epoch 6, loss = 40.8230094909668
epoch 7, loss = 42.86913299560547
 16%|█▌        | 8/50 [00:44<04:01,  5.75s/it] 18%|█▊        | 9/50 [00:48<03:34,  5.23s/it]epoch 8, loss = 31.776260375976562
epoch 9, loss = 30.457923889160156
 20%|██        | 10/50 [01:00<04:52,  7.30s/it]Epoch 10: Train acc/f1 = 0.8967 / 0.8517 / 0.9155 / 0.9518 
                Val acc/f1/spec/sens = 0.7700 / 0.6999 / 0.7470 / 0.8974
                Test acc/f1/spec/sens = 0.5000 / 0.4782 / 0.8250 / 0.4524
 22%|██▏       | 11/50 [01:04<04:08,  6.36s/it]epoch 10, loss = 13.482660293579102
epoch 11, loss = 7.481287002563477
 24%|██▍       | 12/50 [01:10<03:56,  6.22s/it] 26%|██▌       | 13/50 [01:14<03:25,  5.55s/it]epoch 12, loss = 29.883331298828125
epoch 13, loss = 14.481437683105469
 28%|██▊       | 14/50 [01:19<03:17,  5.49s/it]epoch 14, loss = 15.257129669189453
 30%|███       | 15/50 [01:30<04:03,  6.94s/it]Epoch 15: Train acc/f1 = 0.9583 / 0.9484 / 0.9404 / 0.9861 
                Val acc/f1/spec/sens = 0.8650 / 0.8216 / 0.8916 / 0.9402
                Test acc/f1/spec/sens = 0.5410 / 0.5236 / 0.9000 / 0.3095
epoch 15, loss = 15.993914604187012
 32%|███▏      | 16/50 [01:35<03:42,  6.55s/it] 34%|███▍      | 17/50 [01:39<03:10,  5.79s/it]epoch 16, loss = 8.231432914733887
epoch 17, loss = 13.26545238494873
 36%|███▌      | 18/50 [01:45<03:04,  5.76s/it] 38%|███▊      | 19/50 [01:49<02:42,  5.23s/it]epoch 18, loss = 9.451180458068848
epoch 19, loss = 11.959866523742676
 40%|████      | 20/50 [02:01<03:39,  7.32s/it]Epoch 20: Train acc/f1 = 0.9589 / 0.9453 / 0.9765 / 0.9712 
                Val acc/f1/spec/sens = 0.8150 / 0.7604 / 0.8193 / 0.9060
                Test acc/f1/spec/sens = 0.5000 / 0.4852 / 0.8500 / 0.3571
 42%|████▏     | 21/50 [02:05<03:04,  6.35s/it]epoch 20, loss = 6.84118127822876
epoch 21, loss = 2.533612012863159
 44%|████▍     | 22/50 [02:11<02:54,  6.23s/it] 46%|████▌     | 23/50 [02:15<02:30,  5.57s/it]epoch 22, loss = 1.4047791957855225
epoch 23, loss = 2.7543251514434814
 48%|████▊     | 24/50 [02:21<02:25,  5.59s/it]epoch 24, loss = 48.47819519042969
 50%|█████     | 25/50 [02:31<02:57,  7.10s/it]Epoch 25: Train acc/f1 = 0.5383 / 0.5542 / 0.9945 / 0.3748 
                Val acc/f1/spec/sens = 0.7800 / 0.7407 / 0.9639 / 0.7949
                Test acc/f1/spec/sens = 0.4590 / 0.3750 / 1.0000 / 0.1429
epoch 25, loss = 26.961368560791016
 52%|█████▏    | 26/50 [02:37<02:39,  6.67s/it] 54%|█████▍    | 27/50 [02:41<02:14,  5.86s/it]epoch 26, loss = 10.832548141479492
epoch 27, loss = 3.8052635192871094
 56%|█████▌    | 28/50 [02:47<02:06,  5.77s/it] 58%|█████▊    | 29/50 [02:51<01:50,  5.27s/it]epoch 28, loss = 14.775650978088379
epoch 29, loss = 22.617557525634766
 60%|██████    | 30/50 [03:03<02:29,  7.46s/it]Epoch 30: Train acc/f1 = 0.9111 / 0.8824 / 0.9501 / 0.9462 
                Val acc/f1/spec/sens = 0.8350 / 0.7902 / 0.8795 / 0.9060
                Test acc/f1/spec/sens = 0.5410 / 0.5312 / 0.7625 / 0.6429
 62%|██████▏   | 31/50 [03:07<02:02,  6.44s/it]epoch 30, loss = 15.302443504333496
epoch 31, loss = 8.987664222717285
 64%|██████▍   | 32/50 [03:13<01:51,  6.19s/it] 66%|██████▌   | 33/50 [03:17<01:34,  5.55s/it]epoch 32, loss = 8.867500305175781
epoch 33, loss = 4.6157026290893555
 68%|██████▊   | 34/50 [03:23<01:29,  5.56s/it]epoch 34, loss = 15.977299690246582
 70%|███████   | 35/50 [03:33<01:46,  7.08s/it]Epoch 35: Train acc/f1 = 0.9117 / 0.9009 / 0.9986 / 0.8664 
                Val acc/f1/spec/sens = 0.8600 / 0.7998 / 0.8795 / 0.9573
                Test acc/f1/spec/sens = 0.5082 / 0.4184 / 1.0000 / 0.0238
epoch 35, loss = 9.316469192504883
 72%|███████▏  | 36/50 [03:39<01:33,  6.68s/it] 74%|███████▍  | 37/50 [03:43<01:16,  5.91s/it]epoch 36, loss = 4.8034563064575195
epoch 37, loss = 7.430554389953613
 76%|███████▌  | 38/50 [03:49<01:09,  5.80s/it] 78%|███████▊  | 39/50 [03:53<00:57,  5.27s/it]epoch 38, loss = 4.261117935180664
epoch 39, loss = 1.150160312652588
 80%|████████  | 40/50 [04:05<01:12,  7.25s/it]Epoch 40: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8550 / 0.8080 / 0.8554 / 0.9487
                Test acc/f1/spec/sens = 0.5902 / 0.5828 / 0.8875 / 0.3810
 82%|████████▏ | 41/50 [04:09<00:56,  6.32s/it]epoch 40, loss = 0.38624534010887146
epoch 41, loss = 0.6407197713851929
 84%|████████▍ | 42/50 [04:14<00:48,  6.11s/it] 86%|████████▌ | 43/50 [04:18<00:38,  5.47s/it]epoch 42, loss = 15.637125015258789
epoch 43, loss = 11.39523983001709
 88%|████████▊ | 44/50 [04:24<00:33,  5.53s/it]epoch 44, loss = 11.695243835449219
 90%|█████████ | 45/50 [04:35<00:35,  7.13s/it]Epoch 45: Train acc/f1 = 0.8828 / 0.8544 / 1.0000 / 0.8850 
                Val acc/f1/spec/sens = 0.8350 / 0.7802 / 0.7590 / 0.9744
                Test acc/f1/spec/sens = 0.4754 / 0.4364 / 0.9125 / 0.2143
epoch 45, loss = 9.044584274291992
 92%|█████████▏| 46/50 [04:41<00:26,  6.70s/it] 94%|█████████▍| 47/50 [04:45<00:17,  5.92s/it]epoch 46, loss = 2.2096383571624756
epoch 47, loss = 0.8685543537139893
 96%|█████████▌| 48/50 [04:50<00:11,  5.83s/it] 98%|█████████▊| 49/50 [04:54<00:05,  5.24s/it]epoch 48, loss = 6.6658430099487305
epoch 49, loss = 4.493868827819824
100%|██████████| 50/50 [05:06<00:00,  7.28s/it]                                               Epoch 50: Train acc/f1 = 0.9900 / 0.9857 / 0.9972 / 0.9954 
                Val acc/f1/spec/sens = 0.8400 / 0.7939 / 0.8795 / 0.9145
                Test acc/f1/spec/sens = 0.5738 / 0.5569 / 0.7875 / 0.6667
specificity = 720/722
sensitivity = 1073/1078
specificity = 73/83
sensitivity = 107/117
specificity = 63/80
sensitivity = 28/42
Trial 1, Cycle 1
Train acc/f1/spec/sens = 0.9900 / 0.9857 / 0.9972 / 0.9954
Val acc/f1/spec/sens = 0.8400 / 0.7939 / 0.8795 / 0.9145
Test acc/f1/spec/sens = 0.5738 / 0.5569 / 0.7875 / 0.6667
>> Finished.
specificity = 63/80
sensitivity = 28/42
Acc, agreement for latest model:  0.5737704918032787 0.5819672131147541
Load best checkpoint for thief model
specificity = 74/80
sensitivity = 14/42
Acc, agreement for best model:  0.5409836065573771 0.5491803278688525
Trial 0/1 || Cycle 1/1 || Label set size 1800 || Test acc 0.5410 || Test agreement 0.5492 || Spec 0.9250 || Sens 0.3333
**************************************************************************************************** 

specificity = 74/80
sensitivity = 14/42
Number of samples  1800
0.5491803278688525 0.0
        acc      agr   spec      sens                 label dist
0  0.540984  0.54918  0.925  0.333333  {0: 292, 1: 430, 2: 1078}
Results saved to  results/gbusg_radformer/GBUSV_resnet50/SGD/2000_val200/random_
