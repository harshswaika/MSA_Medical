[24/02/23 17:13:05] [conf.py:  298]: PyTorch Version: torch=2.2.1+cu121, cuda=12.1, cudnn=8902
[24/02/23 17:13:05] [conf.py:  300]: ACTIVE:
  ADDENDUM: 0
  ALPHA: 0.2
  AUGMENT: None
  BETA: 1.0
  BUDGET: 5000
  CUTMIX_PROB: 0.0
  CYCLES: 1
  INITIAL: 4500
  LA: False
  METHOD: random
  PRETRAINED_PATH: /home/deepankar/scratch/medclip_vit.bin
  TEMP: 1.0
  TRO: 1.0
  USE_PRETRAINED: True
  VAL: 500
AM:
  SGR: 1000
  THRESHOLD: 0.5
CUDNN_BENCHMARK: True
DS_SEED: 123
EDM:
  HASH: /home/harsh_s/scratch/msacopy/exp/hash/alpha.pt
  NUM_MODELS: 5
  PATH1: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T0.pt
  PATH2: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T1.pt
  PATH3: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T2.pt
  PATH4: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T3.pt
  PATH5: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T4.pt
GR:
  EPSILON: 0.1
  SUR_PATH: /home/harsh_s/scratch/msacopy/GRAD2/batch_training/outputs/trained_models/imagenet_cifar10_to_cifar10_surrogate_10epochs.pt
LOG_DEST: radformer_medclip_vit_gbusv_240223_171305.txt
LOG_TIME: 240223_171305
METHOD_NAME: v1_medclip_vit
OUT_DIR: /home/deepankar/scratch/MSA_Medical/results_deepankar
PL:
  CLASS_BLNC: 10
  ITERATIONS: 20
  KAPPA_N: 0.005
  KAPPA_P: 0.05
  NO_PROGRESS: False
  NO_UNCERTAINTY: False
  TAU_N: 0.05
  TAU_P: 0.7
  TEMP_NL: 2.0
RNG_SEED: 1
SAVE_DIR: /home/deepankar/scratch/MSA_Medical/results_deepankar/gbusg_radformer/GBUSV_medclip_vit/SGD/5000_val500/random_v1_medclip_vit
THIEF:
  ARCH: medclip_vit
  DATASET: GBUSV
  DATA_ROOT: /home/deepankar/mnt/vision3_data_ckpts_msa_medical/GBUSV-Shared
  HARD_LABELS: True
  NUM_TRAIN: 1281167
  SUBSET: 128116
TRAIN:
  BATCH: 16
  EPOCH: 40
  GAMMA: 0.1
  LR: 0.005
  MILESTONES: [20, 40, 60, 80]
  MOMENTUM: 0.9
  OPTIMIZER: SGD
  WDECAY: 0.0005
VICTIM:
  ARCH: radformer
  DATASET: gbusg
  DATA_ROOT: /home/deepankar/mnt/vision3_data_ckpts_msa_medical/GBCU-Shared
  HEIGHT: 224
  PATH: /home/deepankar/mnt/vision3_data_ckpts_msa_medical/victim_models/radformer/radformer.pkl
  PATHIN: /home/harsh_s/scratch/msacopy/ckpts/cifar10-resnet32-inaccurate/checkpoint.pth.tar
  WIDTH: 224
Loaded target dataset of size 122 with 3 classes
target model keys:  695
checkpoint keys:  695
specificity = 72/80
sensitivity = 39/42

Target model acc = 0.9016393442622951
Val-Acc: 0.9016 Val-Spec: 0.9000 Val-Sens: 0.9286
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
replacing labeled set labels with victim labels
  0%|          | 0/282 [00:00<?, ?it/s]  0%|          | 1/282 [00:00<02:39,  1.76it/s]  1%|          | 2/282 [00:00<01:45,  2.65it/s]  1%|          | 3/282 [00:01<01:24,  3.32it/s]  1%|▏         | 4/282 [00:01<01:15,  3.69it/s]  2%|▏         | 5/282 [00:01<01:09,  3.98it/s]  2%|▏         | 6/282 [00:01<01:09,  3.99it/s]  2%|▏         | 7/282 [00:01<01:07,  4.08it/s]  3%|▎         | 8/282 [00:02<01:05,  4.21it/s]  3%|▎         | 9/282 [00:02<01:04,  4.21it/s]  4%|▎         | 10/282 [00:02<01:01,  4.45it/s]  4%|▍         | 11/282 [00:02<00:58,  4.63it/s]  4%|▍         | 12/282 [00:03<01:03,  4.25it/s]  5%|▍         | 13/282 [00:03<01:00,  4.41it/s]  5%|▍         | 14/282 [00:03<01:04,  4.13it/s]  5%|▌         | 15/282 [00:03<01:07,  3.97it/s]  6%|▌         | 16/282 [00:04<01:08,  3.87it/s]  6%|▌         | 17/282 [00:04<01:09,  3.84it/s]  6%|▋         | 18/282 [00:04<01:10,  3.77it/s]  7%|▋         | 19/282 [00:04<01:09,  3.76it/s]  7%|▋         | 20/282 [00:05<01:09,  3.75it/s]  7%|▋         | 21/282 [00:05<01:09,  3.73it/s]  8%|▊         | 22/282 [00:05<01:09,  3.76it/s]  8%|▊         | 23/282 [00:05<01:09,  3.74it/s]  9%|▊         | 24/282 [00:06<01:10,  3.68it/s]  9%|▉         | 25/282 [00:06<01:09,  3.69it/s]  9%|▉         | 26/282 [00:06<01:08,  3.72it/s] 10%|▉         | 27/282 [00:07<01:08,  3.70it/s] 10%|▉         | 28/282 [00:07<01:08,  3.71it/s] 10%|█         | 29/282 [00:07<01:07,  3.74it/s] 11%|█         | 30/282 [00:07<01:07,  3.72it/s] 11%|█         | 31/282 [00:08<01:08,  3.69it/s] 11%|█▏        | 32/282 [00:08<01:02,  3.98it/s] 12%|█▏        | 33/282 [00:08<01:01,  4.05it/s] 12%|█▏        | 34/282 [00:08<01:03,  3.90it/s] 12%|█▏        | 35/282 [00:09<01:04,  3.81it/s] 13%|█▎        | 36/282 [00:09<01:05,  3.73it/s] 13%|█▎        | 37/282 [00:09<01:07,  3.64it/s] 13%|█▎        | 38/282 [00:09<01:06,  3.69it/s] 14%|█▍        | 39/282 [00:10<01:06,  3.65it/s] 14%|█▍        | 40/282 [00:10<01:05,  3.69it/s] 15%|█▍        | 41/282 [00:10<01:05,  3.66it/s] 15%|█▍        | 42/282 [00:11<01:05,  3.68it/s] 15%|█▌        | 43/282 [00:11<01:04,  3.72it/s] 16%|█▌        | 44/282 [00:11<01:05,  3.65it/s] 16%|█▌        | 45/282 [00:11<01:04,  3.67it/s] 16%|█▋        | 46/282 [00:12<01:04,  3.67it/s] 17%|█▋        | 47/282 [00:12<01:03,  3.72it/s] 17%|█▋        | 48/282 [00:12<01:03,  3.71it/s] 17%|█▋        | 49/282 [00:12<01:04,  3.63it/s] 18%|█▊        | 50/282 [00:13<01:05,  3.55it/s] 18%|█▊        | 51/282 [00:13<01:04,  3.57it/s] 18%|█▊        | 52/282 [00:13<01:03,  3.64it/s] 19%|█▉        | 53/282 [00:14<01:03,  3.63it/s] 19%|█▉        | 54/282 [00:14<01:02,  3.67it/s] 20%|█▉        | 55/282 [00:14<01:01,  3.69it/s] 20%|█▉        | 56/282 [00:14<01:00,  3.75it/s] 20%|██        | 57/282 [00:15<01:00,  3.72it/s] 21%|██        | 58/282 [00:15<01:00,  3.70it/s] 21%|██        | 59/282 [00:15<00:59,  3.73it/s] 21%|██▏       | 60/282 [00:15<00:59,  3.72it/s] 22%|██▏       | 61/282 [00:16<00:59,  3.73it/s] 22%|██▏       | 62/282 [00:16<00:58,  3.78it/s] 22%|██▏       | 63/282 [00:16<00:58,  3.73it/s] 23%|██▎       | 64/282 [00:17<00:58,  3.73it/s] 23%|██▎       | 65/282 [00:17<00:58,  3.74it/s] 23%|██▎       | 66/282 [00:17<00:58,  3.68it/s] 24%|██▍       | 67/282 [00:17<00:58,  3.69it/s] 24%|██▍       | 68/282 [00:18<00:58,  3.64it/s] 24%|██▍       | 69/282 [00:18<01:00,  3.51it/s] 25%|██▍       | 70/282 [00:18<01:00,  3.52it/s] 25%|██▌       | 71/282 [00:19<00:59,  3.54it/s] 26%|██▌       | 72/282 [00:19<00:58,  3.59it/s] 26%|██▌       | 73/282 [00:19<00:57,  3.61it/s] 26%|██▌       | 74/282 [00:19<01:01,  3.41it/s] 27%|██▋       | 75/282 [00:20<00:58,  3.51it/s] 27%|██▋       | 76/282 [00:20<00:56,  3.66it/s] 27%|██▋       | 77/282 [00:20<00:54,  3.74it/s] 28%|██▊       | 78/282 [00:20<00:53,  3.82it/s] 28%|██▊       | 79/282 [00:21<00:53,  3.80it/s] 28%|██▊       | 80/282 [00:21<00:53,  3.81it/s] 29%|██▊       | 81/282 [00:21<00:54,  3.70it/s] 29%|██▉       | 82/282 [00:21<00:50,  3.96it/s] 29%|██▉       | 83/282 [00:22<00:54,  3.67it/s] 30%|██▉       | 84/282 [00:22<00:53,  3.67it/s] 30%|███       | 85/282 [00:22<00:53,  3.71it/s] 30%|███       | 86/282 [00:23<00:53,  3.69it/s] 31%|███       | 87/282 [00:23<00:52,  3.68it/s] 31%|███       | 88/282 [00:23<00:55,  3.48it/s] 32%|███▏      | 89/282 [00:23<00:55,  3.49it/s] 32%|███▏      | 90/282 [00:24<00:54,  3.53it/s] 32%|███▏      | 91/282 [00:24<00:54,  3.51it/s] 33%|███▎      | 92/282 [00:24<00:54,  3.47it/s] 33%|███▎      | 93/282 [00:25<00:57,  3.31it/s] 33%|███▎      | 94/282 [00:25<00:58,  3.21it/s] 34%|███▎      | 95/282 [00:25<01:03,  2.93it/s] 34%|███▍      | 96/282 [00:26<01:06,  2.82it/s] 34%|███▍      | 97/282 [00:26<01:03,  2.91it/s] 35%|███▍      | 98/282 [00:26<01:01,  2.99it/s] 35%|███▌      | 99/282 [00:27<01:03,  2.88it/s] 35%|███▌      | 100/282 [00:27<01:00,  3.02it/s] 36%|███▌      | 101/282 [00:27<00:57,  3.14it/s] 36%|███▌      | 102/282 [00:28<00:51,  3.52it/s] 37%|███▋      | 103/282 [00:28<00:50,  3.56it/s] 37%|███▋      | 104/282 [00:28<00:50,  3.54it/s] 37%|███▋      | 105/282 [00:28<00:49,  3.60it/s] 38%|███▊      | 106/282 [00:29<00:48,  3.61it/s] 38%|███▊      | 107/282 [00:29<00:46,  3.74it/s] 38%|███▊      | 108/282 [00:29<00:48,  3.62it/s] 39%|███▊      | 109/282 [00:29<00:48,  3.59it/s] 39%|███▉      | 110/282 [00:30<00:48,  3.52it/s] 39%|███▉      | 111/282 [00:30<00:46,  3.70it/s] 40%|███▉      | 112/282 [00:30<00:44,  3.86it/s] 40%|████      | 113/282 [00:30<00:41,  4.03it/s] 40%|████      | 114/282 [00:31<00:41,  4.01it/s] 41%|████      | 115/282 [00:31<00:43,  3.86it/s] 41%|████      | 116/282 [00:31<00:44,  3.76it/s] 41%|████▏     | 117/282 [00:32<00:43,  3.80it/s] 42%|████▏     | 118/282 [00:32<00:43,  3.76it/s] 42%|████▏     | 119/282 [00:32<00:43,  3.74it/s] 43%|████▎     | 120/282 [00:32<00:44,  3.68it/s] 43%|████▎     | 121/282 [00:33<00:43,  3.68it/s] 43%|████▎     | 122/282 [00:33<00:44,  3.60it/s] 44%|████▎     | 123/282 [00:33<00:45,  3.53it/s] 44%|████▍     | 124/282 [00:34<00:48,  3.26it/s] 44%|████▍     | 125/282 [00:34<00:49,  3.18it/s] 45%|████▍     | 126/282 [00:34<00:51,  3.00it/s] 45%|████▌     | 127/282 [00:35<00:52,  2.98it/s] 45%|████▌     | 128/282 [00:35<00:54,  2.80it/s] 46%|████▌     | 129/282 [00:35<00:52,  2.90it/s] 46%|████▌     | 130/282 [00:36<00:50,  3.00it/s] 46%|████▋     | 131/282 [00:36<00:56,  2.67it/s] 47%|████▋     | 132/282 [00:36<00:55,  2.72it/s] 47%|████▋     | 133/282 [00:37<00:59,  2.52it/s] 48%|████▊     | 134/282 [00:37<00:55,  2.67it/s] 48%|████▊     | 135/282 [00:38<00:52,  2.77it/s] 48%|████▊     | 136/282 [00:38<00:51,  2.85it/s] 49%|████▊     | 137/282 [00:38<00:49,  2.95it/s] 49%|████▉     | 138/282 [00:39<00:49,  2.91it/s] 49%|████▉     | 139/282 [00:39<00:55,  2.60it/s] 50%|████▉     | 140/282 [00:39<00:53,  2.65it/s] 50%|█████     | 141/282 [00:40<00:49,  2.83it/s] 50%|█████     | 142/282 [00:40<00:44,  3.13it/s] 51%|█████     | 143/282 [00:40<00:41,  3.32it/s] 51%|█████     | 144/282 [00:41<00:39,  3.46it/s] 51%|█████▏    | 145/282 [00:41<00:38,  3.52it/s] 52%|█████▏    | 146/282 [00:41<00:37,  3.64it/s] 52%|█████▏    | 147/282 [00:41<00:34,  3.86it/s] 52%|█████▏    | 148/282 [00:42<00:34,  3.88it/s] 53%|█████▎    | 149/282 [00:42<00:36,  3.63it/s] 53%|█████▎    | 150/282 [00:42<00:36,  3.60it/s] 54%|█████▎    | 151/282 [00:42<00:36,  3.63it/s] 54%|█████▍    | 152/282 [00:43<00:35,  3.63it/s] 54%|█████▍    | 153/282 [00:43<00:35,  3.63it/s] 55%|█████▍    | 154/282 [00:43<00:35,  3.62it/s] 55%|█████▍    | 155/282 [00:43<00:35,  3.62it/s] 55%|█████▌    | 156/282 [00:44<00:35,  3.59it/s] 56%|█████▌    | 157/282 [00:44<00:35,  3.56it/s] 56%|█████▌    | 158/282 [00:44<00:34,  3.57it/s] 56%|█████▋    | 159/282 [00:45<00:34,  3.56it/s] 57%|█████▋    | 160/282 [00:45<00:34,  3.57it/s] 57%|█████▋    | 161/282 [00:45<00:33,  3.57it/s] 57%|█████▋    | 162/282 [00:45<00:33,  3.57it/s] 58%|█████▊    | 163/282 [00:46<00:33,  3.58it/s] 58%|█████▊    | 164/282 [00:46<00:32,  3.63it/s] 59%|█████▊    | 165/282 [00:46<00:31,  3.66it/s] 59%|█████▉    | 166/282 [00:47<00:31,  3.68it/s] 59%|█████▉    | 167/282 [00:47<00:31,  3.67it/s] 60%|█████▉    | 168/282 [00:47<00:31,  3.66it/s] 60%|█████▉    | 169/282 [00:47<00:31,  3.59it/s] 60%|██████    | 170/282 [00:48<00:30,  3.61it/s] 61%|██████    | 171/282 [00:48<00:30,  3.70it/s] 61%|██████    | 172/282 [00:48<00:29,  3.71it/s] 61%|██████▏   | 173/282 [00:48<00:29,  3.66it/s] 62%|██████▏   | 174/282 [00:49<00:29,  3.64it/s] 62%|██████▏   | 175/282 [00:49<00:28,  3.70it/s] 62%|██████▏   | 176/282 [00:49<00:28,  3.73it/s] 63%|██████▎   | 177/282 [00:50<00:28,  3.68it/s] 63%|██████▎   | 178/282 [00:50<00:28,  3.68it/s] 63%|██████▎   | 179/282 [00:50<00:28,  3.64it/s] 64%|██████▍   | 180/282 [00:50<00:27,  3.66it/s] 64%|██████▍   | 181/282 [00:51<00:27,  3.65it/s] 65%|██████▍   | 182/282 [00:51<00:27,  3.69it/s] 65%|██████▍   | 183/282 [00:51<00:26,  3.75it/s] 65%|██████▌   | 184/282 [00:51<00:26,  3.71it/s] 66%|██████▌   | 185/282 [00:52<00:26,  3.71it/s] 66%|██████▌   | 186/282 [00:52<00:25,  3.74it/s] 66%|██████▋   | 187/282 [00:52<00:25,  3.77it/s] 67%|██████▋   | 188/282 [00:52<00:25,  3.73it/s] 67%|██████▋   | 189/282 [00:53<00:24,  3.79it/s] 67%|██████▋   | 190/282 [00:53<00:22,  4.09it/s] 68%|██████▊   | 191/282 [00:53<00:22,  3.98it/s] 68%|██████▊   | 192/282 [00:53<00:22,  3.94it/s] 68%|██████▊   | 193/282 [00:54<00:23,  3.87it/s] 69%|██████▉   | 194/282 [00:54<00:23,  3.78it/s] 69%|██████▉   | 195/282 [00:54<00:23,  3.77it/s] 70%|██████▉   | 196/282 [00:55<00:22,  3.77it/s] 70%|██████▉   | 197/282 [00:55<00:22,  3.80it/s] 70%|███████   | 198/282 [00:55<00:21,  3.85it/s] 71%|███████   | 199/282 [00:55<00:21,  3.82it/s] 71%|███████   | 200/282 [00:56<00:21,  3.80it/s] 71%|███████▏  | 201/282 [00:56<00:21,  3.77it/s] 72%|███████▏  | 202/282 [00:56<00:21,  3.75it/s] 72%|███████▏  | 203/282 [00:56<00:20,  3.81it/s] 72%|███████▏  | 204/282 [00:57<00:20,  3.80it/s] 73%|███████▎  | 205/282 [00:57<00:20,  3.75it/s] 73%|███████▎  | 206/282 [00:57<00:20,  3.79it/s] 73%|███████▎  | 207/282 [00:57<00:19,  3.82it/s] 74%|███████▍  | 208/282 [00:58<00:19,  3.78it/s] 74%|███████▍  | 209/282 [00:58<00:19,  3.78it/s] 74%|███████▍  | 210/282 [00:58<00:18,  3.80it/s] 75%|███████▍  | 211/282 [00:58<00:18,  3.80it/s] 75%|███████▌  | 212/282 [00:59<00:18,  3.77it/s] 76%|███████▌  | 213/282 [00:59<00:18,  3.78it/s] 76%|███████▌  | 214/282 [00:59<00:17,  3.81it/s] 76%|███████▌  | 215/282 [01:00<00:17,  3.78it/s] 77%|███████▋  | 216/282 [01:00<00:17,  3.80it/s] 77%|███████▋  | 217/282 [01:00<00:17,  3.79it/s] 77%|███████▋  | 218/282 [01:00<00:17,  3.73it/s] 78%|███████▊  | 219/282 [01:01<00:16,  3.73it/s] 78%|███████▊  | 220/282 [01:01<00:16,  3.74it/s] 78%|███████▊  | 221/282 [01:01<00:16,  3.70it/s] 79%|███████▊  | 222/282 [01:01<00:16,  3.67it/s] 79%|███████▉  | 223/282 [01:02<00:16,  3.61it/s] 79%|███████▉  | 224/282 [01:02<00:16,  3.59it/s] 80%|███████▉  | 225/282 [01:02<00:15,  3.62it/s] 80%|████████  | 226/282 [01:03<00:15,  3.63it/s] 80%|████████  | 227/282 [01:03<00:13,  3.99it/s] 81%|████████  | 228/282 [01:03<00:12,  4.28it/s] 81%|████████  | 229/282 [01:03<00:11,  4.45it/s] 82%|████████▏ | 230/282 [01:03<00:11,  4.56it/s] 82%|████████▏ | 231/282 [01:04<00:11,  4.56it/s] 82%|████████▏ | 232/282 [01:04<00:11,  4.49it/s] 83%|████████▎ | 233/282 [01:04<00:10,  4.48it/s] 83%|████████▎ | 234/282 [01:04<00:10,  4.57it/s] 83%|████████▎ | 235/282 [01:04<00:10,  4.56it/s] 84%|████████▎ | 236/282 [01:05<00:09,  4.68it/s] 84%|████████▍ | 237/282 [01:05<00:10,  4.39it/s] 84%|████████▍ | 238/282 [01:05<00:10,  4.06it/s] 85%|████████▍ | 239/282 [01:05<00:10,  3.92it/s] 85%|████████▌ | 240/282 [01:06<00:11,  3.76it/s] 85%|████████▌ | 241/282 [01:06<00:10,  4.06it/s] 86%|████████▌ | 242/282 [01:06<00:09,  4.33it/s] 86%|████████▌ | 243/282 [01:06<00:08,  4.54it/s] 87%|████████▋ | 244/282 [01:07<00:08,  4.31it/s] 87%|████████▋ | 245/282 [01:07<00:09,  3.89it/s] 87%|████████▋ | 246/282 [01:07<00:09,  3.85it/s] 88%|████████▊ | 247/282 [01:07<00:09,  3.78it/s] 88%|████████▊ | 248/282 [01:08<00:08,  3.79it/s] 88%|████████▊ | 249/282 [01:08<00:08,  3.79it/s] 89%|████████▊ | 250/282 [01:08<00:08,  3.76it/s] 89%|████████▉ | 251/282 [01:09<00:08,  3.59it/s] 89%|████████▉ | 252/282 [01:09<00:08,  3.65it/s] 90%|████████▉ | 253/282 [01:09<00:07,  3.68it/s] 90%|█████████ | 254/282 [01:09<00:07,  3.68it/s] 90%|█████████ | 255/282 [01:10<00:07,  3.69it/s] 91%|█████████ | 256/282 [01:10<00:07,  3.70it/s] 91%|█████████ | 257/282 [01:10<00:06,  3.75it/s] 91%|█████████▏| 258/282 [01:10<00:06,  3.75it/s] 92%|█████████▏| 259/282 [01:11<00:06,  3.74it/s] 92%|█████████▏| 260/282 [01:11<00:05,  3.70it/s] 93%|█████████▎| 261/282 [01:11<00:05,  3.61it/s] 93%|█████████▎| 262/282 [01:12<00:05,  3.65it/s] 93%|█████████▎| 263/282 [01:12<00:05,  3.61it/s] 94%|█████████▎| 264/282 [01:12<00:05,  3.58it/s] 94%|█████████▍| 265/282 [01:12<00:04,  3.43it/s] 94%|█████████▍| 266/282 [01:13<00:04,  3.48it/s] 95%|█████████▍| 267/282 [01:13<00:04,  3.43it/s] 95%|█████████▌| 268/282 [01:13<00:04,  3.37it/s] 95%|█████████▌| 269/282 [01:14<00:03,  3.44it/s] 96%|█████████▌| 270/282 [01:14<00:03,  3.49it/s] 96%|█████████▌| 271/282 [01:14<00:03,  3.54it/s] 96%|█████████▋| 272/282 [01:14<00:02,  3.61it/s] 97%|█████████▋| 273/282 [01:15<00:02,  3.63it/s] 97%|█████████▋| 274/282 [01:15<00:02,  3.65it/s] 98%|█████████▊| 275/282 [01:15<00:01,  3.64it/s] 98%|█████████▊| 276/282 [01:16<00:01,  3.44it/s] 98%|█████████▊| 277/282 [01:16<00:01,  3.47it/s] 99%|█████████▊| 278/282 [01:16<00:01,  3.83it/s] 99%|█████████▉| 279/282 [01:16<00:00,  3.79it/s] 99%|█████████▉| 280/282 [01:17<00:00,  3.74it/s]100%|█████████▉| 281/282 [01:17<00:00,  3.74it/s]100%|██████████| 282/282 [01:17<00:00,  3.59it/s]100%|██████████| 282/282 [01:17<00:00,  3.63it/s]
replacing val labels with victim labels
  0%|          | 0/32 [00:00<?, ?it/s]  3%|▎         | 1/32 [00:00<00:16,  1.89it/s]  6%|▋         | 2/32 [00:00<00:11,  2.64it/s]  9%|▉         | 3/32 [00:01<00:09,  3.04it/s] 12%|█▎        | 4/32 [00:01<00:08,  3.20it/s] 16%|█▌        | 5/32 [00:01<00:07,  3.39it/s] 19%|█▉        | 6/32 [00:01<00:07,  3.50it/s] 22%|██▏       | 7/32 [00:02<00:07,  3.51it/s] 25%|██▌       | 8/32 [00:02<00:06,  3.57it/s] 28%|██▊       | 9/32 [00:02<00:06,  3.63it/s] 31%|███▏      | 10/32 [00:02<00:05,  3.68it/s] 34%|███▍      | 11/32 [00:03<00:05,  3.68it/s] 38%|███▊      | 12/32 [00:03<00:05,  3.73it/s] 41%|████      | 13/32 [00:03<00:05,  3.70it/s] 44%|████▍     | 14/32 [00:04<00:04,  3.70it/s] 47%|████▋     | 15/32 [00:04<00:04,  4.01it/s] 50%|█████     | 16/32 [00:04<00:03,  4.07it/s] 53%|█████▎    | 17/32 [00:04<00:03,  3.85it/s] 56%|█████▋    | 18/32 [00:05<00:03,  3.98it/s] 59%|█████▉    | 19/32 [00:05<00:03,  4.19it/s] 62%|██████▎   | 20/32 [00:05<00:02,  4.20it/s] 66%|██████▌   | 21/32 [00:05<00:02,  4.05it/s] 69%|██████▉   | 22/32 [00:05<00:02,  3.97it/s] 72%|███████▏  | 23/32 [00:06<00:02,  3.88it/s] 75%|███████▌  | 24/32 [00:06<00:02,  3.84it/s] 78%|███████▊  | 25/32 [00:06<00:01,  3.78it/s] 81%|████████▏ | 26/32 [00:07<00:01,  3.76it/s] 84%|████████▍ | 27/32 [00:07<00:01,  3.73it/s] 88%|████████▊ | 28/32 [00:07<00:01,  3.68it/s] 91%|█████████ | 29/32 [00:07<00:00,  3.68it/s] 94%|█████████▍| 30/32 [00:08<00:00,  3.63it/s] 97%|█████████▋| 31/32 [00:08<00:00,  3.62it/s]100%|██████████| 32/32 [00:08<00:00,  3.73it/s]Validation set distribution: 
Number of samples  500

{0: 74, 1: 123, 2: 303}
Labeled set distribution: 
Number of samples  4500
Some weights of the model checkpoint at microsoft/swin-tiny-patch4-window7-224 were not used when initializing SwinModel: ['classifier.bias', 'classifier.weight']
- This IS expected if you are initializing SwinModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing SwinModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
{0: 581, 1: 1040, 2: 2879}
load model weight from: /home/deepankar/scratch/MSA_Medical/
MedCLIPModel(
  (vision_model): MedCLIPVisionModelViT(
    (model): SwinModel(
      (embeddings): SwinEmbeddings(
        (patch_embeddings): SwinPatchEmbeddings(
          (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        )
        (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (encoder): SwinEncoder(
        (layers): ModuleList(
          (0): SwinStage(
            (blocks): ModuleList(
              (0-1): 2 x SwinLayer(
                (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attention): SwinAttention(
                  (self): SwinSelfAttention(
                    (query): Linear(in_features=96, out_features=96, bias=True)
                    (key): Linear(in_features=96, out_features=96, bias=True)
                    (value): Linear(in_features=96, out_features=96, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): SwinSelfOutput(
                    (dense): Linear(in_features=96, out_features=96, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (drop_path): SwinDropPath(p=0.1)
                (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (intermediate): SwinIntermediate(
                  (dense): Linear(in_features=96, out_features=384, bias=True)
                  (intermediate_act_fn): GELUActivation()
                )
                (output): SwinOutput(
                  (dense): Linear(in_features=384, out_features=96, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): SwinPatchMerging(
              (reduction): Linear(in_features=384, out_features=192, bias=False)
              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): SwinStage(
            (blocks): ModuleList(
              (0-1): 2 x SwinLayer(
                (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attention): SwinAttention(
                  (self): SwinSelfAttention(
                    (query): Linear(in_features=192, out_features=192, bias=True)
                    (key): Linear(in_features=192, out_features=192, bias=True)
                    (value): Linear(in_features=192, out_features=192, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): SwinSelfOutput(
                    (dense): Linear(in_features=192, out_features=192, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (drop_path): SwinDropPath(p=0.1)
                (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (intermediate): SwinIntermediate(
                  (dense): Linear(in_features=192, out_features=768, bias=True)
                  (intermediate_act_fn): GELUActivation()
                )
                (output): SwinOutput(
                  (dense): Linear(in_features=768, out_features=192, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): SwinPatchMerging(
              (reduction): Linear(in_features=768, out_features=384, bias=False)
              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): SwinStage(
            (blocks): ModuleList(
              (0-5): 6 x SwinLayer(
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attention): SwinAttention(
                  (self): SwinSelfAttention(
                    (query): Linear(in_features=384, out_features=384, bias=True)
                    (key): Linear(in_features=384, out_features=384, bias=True)
                    (value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): SwinSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (drop_path): SwinDropPath(p=0.1)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (intermediate): SwinIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (intermediate_act_fn): GELUActivation()
                )
                (output): SwinOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): SwinPatchMerging(
              (reduction): Linear(in_features=1536, out_features=768, bias=False)
              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): SwinStage(
            (blocks): ModuleList(
              (0-1): 2 x SwinLayer(
                (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attention): SwinAttention(
                  (self): SwinSelfAttention(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): SwinSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (drop_path): SwinDropPath(p=0.1)
                (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (intermediate): SwinIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                  (intermediate_act_fn): GELUActivation()
                )
                (output): SwinOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
        )
      )
      (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (pooler): AdaptiveAvgPool1d(output_size=1)
    )
    (projection_head): Linear(in_features=768, out_features=512, bias=False)
  )
  (text_model): MedCLIPTextModel(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(28996, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-11): 12 x BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (projection_head): Linear(in_features=768, out_features=512, bias=False)
  )
)
Thief model initialized successfully
Traceback (most recent call last):
  File "activethief_gbc.py", line 103, in <module>
    acc, f1, spec, sens = testz(thief_model, test_loader, no_roi=False)
  File "/nvme/scratch/deepankar/MSA_Medical/activethief/train_utils_gbc.py", line 33, in testz
    outputs = model(input_var)
  File "/home/deepankar/scratch/miniconda3/envs/msa/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/deepankar/scratch/miniconda3/envs/msa/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/deepankar/scratch/miniconda3/envs/msa/lib/python3.8/site-packages/medclip/modeling_medclip.py", line 212, in forward
    pixel_values = pixel_values.cuda()
AttributeError: 'NoneType' object has no attribute 'cuda'
