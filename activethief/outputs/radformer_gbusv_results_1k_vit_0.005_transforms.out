[24/02/29 21:48:31] [conf.py:  298]: PyTorch Version: torch=1.11.0, cuda=11.3, cudnn=8200
[24/02/29 21:48:31] [conf.py:  300]: ACTIVE:
  ADDENDUM: 0
  ALPHA: 0.2
  AUGMENT: None
  BETA: 1.0
  BUDGET: 1000
  CUTMIX_PROB: 0.0
  CYCLES: 1
  INITIAL: 900
  LA: False
  METHOD: random
  PRETRAINED_PATH: /home/deepankar/mnt/vision3_ckpts/vit_b_16-imagenet1k.pth
  TEMP: 1.0
  TRO: 1.0
  USE_PRETRAINED: True
  VAL: 100
AM:
  SGR: 1000
  THRESHOLD: 0.5
CUDNN_BENCHMARK: True
DS_SEED: 123
EDM:
  HASH: /home/harsh_s/scratch/msacopy/exp/hash/alpha.pt
  NUM_MODELS: 5
  PATH1: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T0.pt
  PATH2: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T1.pt
  PATH3: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T2.pt
  PATH4: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T3.pt
  PATH5: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T4.pt
GR:
  EPSILON: 0.1
  SUR_PATH: /home/harsh_s/scratch/msacopy/GRAD2/batch_training/outputs/trained_models/imagenet_cifar10_to_cifar10_surrogate_10epochs.pt
LOG_DEST: radformer_vit_gbusv_240229_214831.txt
LOG_TIME: 240229_214831
METHOD_NAME: v1_transforms
OUT_DIR: /home/deepankar/scratch/MSA_Medical/results_1k
PL:
  CLASS_BLNC: 10
  ITERATIONS: 20
  KAPPA_N: 0.005
  KAPPA_P: 0.05
  NO_PROGRESS: False
  NO_UNCERTAINTY: False
  TAU_N: 0.05
  TAU_P: 0.7
  TEMP_NL: 2.0
RNG_SEED: 5
SAVE_DIR: /home/deepankar/scratch/MSA_Medical/results_1k/gbusg_radformer/GBUSV_vit/SGD/1000_val100/random_v1_transforms
THIEF:
  ARCH: vit
  DATASET: GBUSV
  DATA_ROOT: /home/deepankar/mnt/vision3_data_ckpts_msa_medical/GBUSV-Shared
  HARD_LABELS: True
  NUM_TRAIN: 1281167
  SUBSET: 128116
TRAIN:
  BATCH: 16
  EPOCH: 100
  GAMMA: 0.1
  LR: 0.005
  MILESTONES: [20, 40, 60, 80]
  MOMENTUM: 0.9
  OPTIMIZER: SGD
  WDECAY: 0.0005
VICTIM:
  ARCH: radformer
  DATASET: gbusg
  DATA_ROOT: /home/deepankar/mnt/vision3_data_ckpts_msa_medical/GBCU-Shared
  HEIGHT: 224
  PATH: /home/deepankar/mnt/vision3_data_ckpts_msa_medical/victim_models/radformer/radformer.pkl
  PATHIN: /home/harsh_s/scratch/msacopy/ckpts/cifar10-resnet32-inaccurate/checkpoint.pth.tar
  WIDTH: 224
Loaded target dataset of size 122 with 3 classes
target model keys:  695
checkpoint keys:  695
specificity = 72/80
sensitivity = 39/42

Target model acc = 0.9016393442622951
Val-Acc: 0.9016 Val-Spec: 0.9000 Val-Sens: 0.9286
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
replacing labeled set labels with victim labels
  0%|          | 0/57 [00:00<?, ?it/s]  2%|▏         | 1/57 [00:00<00:35,  1.59it/s]  4%|▎         | 2/57 [00:00<00:20,  2.64it/s]  5%|▌         | 3/57 [00:01<00:17,  3.03it/s]  7%|▋         | 4/57 [00:01<00:16,  3.27it/s]  9%|▉         | 5/57 [00:01<00:15,  3.44it/s] 11%|█         | 6/57 [00:01<00:13,  3.76it/s] 12%|█▏        | 7/57 [00:02<00:13,  3.79it/s] 14%|█▍        | 8/57 [00:02<00:11,  4.14it/s] 16%|█▌        | 9/57 [00:02<00:12,  4.00it/s] 18%|█▊        | 10/57 [00:02<00:12,  3.89it/s] 19%|█▉        | 11/57 [00:03<00:11,  3.85it/s] 21%|██        | 12/57 [00:03<00:11,  3.78it/s] 23%|██▎       | 13/57 [00:03<00:12,  3.65it/s] 25%|██▍       | 14/57 [00:03<00:10,  3.92it/s] 26%|██▋       | 15/57 [00:04<00:10,  4.03it/s] 28%|██▊       | 16/57 [00:04<00:09,  4.30it/s] 30%|██▉       | 17/57 [00:04<00:08,  4.49it/s] 32%|███▏      | 18/57 [00:04<00:08,  4.69it/s] 33%|███▎      | 19/57 [00:04<00:08,  4.59it/s] 35%|███▌      | 20/57 [00:05<00:07,  4.70it/s] 37%|███▋      | 21/57 [00:05<00:07,  4.81it/s] 39%|███▊      | 22/57 [00:05<00:07,  4.91it/s] 40%|████      | 23/57 [00:05<00:07,  4.69it/s] 42%|████▏     | 24/57 [00:05<00:06,  4.80it/s] 44%|████▍     | 25/57 [00:06<00:06,  4.89it/s] 46%|████▌     | 26/57 [00:06<00:06,  4.90it/s] 47%|████▋     | 27/57 [00:06<00:06,  4.72it/s] 49%|████▉     | 28/57 [00:06<00:05,  4.84it/s] 51%|█████     | 29/57 [00:07<00:05,  4.77it/s] 53%|█████▎    | 30/57 [00:07<00:05,  4.85it/s] 54%|█████▍    | 31/57 [00:07<00:05,  4.69it/s] 56%|█████▌    | 32/57 [00:07<00:05,  4.78it/s] 58%|█████▊    | 33/57 [00:07<00:04,  4.88it/s] 60%|█████▉    | 34/57 [00:08<00:04,  4.94it/s] 61%|██████▏   | 35/57 [00:08<00:04,  4.71it/s] 63%|██████▎   | 36/57 [00:08<00:04,  4.83it/s] 65%|██████▍   | 37/57 [00:08<00:04,  4.91it/s] 67%|██████▋   | 38/57 [00:08<00:03,  4.96it/s] 68%|██████▊   | 39/57 [00:09<00:03,  4.70it/s] 70%|███████   | 40/57 [00:09<00:03,  4.84it/s] 72%|███████▏  | 41/57 [00:09<00:03,  4.88it/s] 74%|███████▎  | 42/57 [00:09<00:03,  4.78it/s] 75%|███████▌  | 43/57 [00:09<00:03,  4.49it/s] 77%|███████▋  | 44/57 [00:10<00:02,  4.65it/s] 79%|███████▉  | 45/57 [00:10<00:02,  4.79it/s] 81%|████████  | 46/57 [00:10<00:02,  4.88it/s] 82%|████████▏ | 47/57 [00:10<00:02,  4.75it/s] 84%|████████▍ | 48/57 [00:10<00:01,  4.79it/s] 86%|████████▌ | 49/57 [00:11<00:01,  4.86it/s] 88%|████████▊ | 50/57 [00:11<00:01,  4.93it/s] 89%|████████▉ | 51/57 [00:11<00:01,  4.91it/s] 91%|█████████ | 52/57 [00:11<00:01,  4.49it/s] 93%|█████████▎| 53/57 [00:12<00:00,  4.43it/s] 95%|█████████▍| 54/57 [00:12<00:00,  4.34it/s] 96%|█████████▋| 55/57 [00:12<00:00,  4.52it/s] 98%|█████████▊| 56/57 [00:12<00:00,  4.69it/s]100%|██████████| 57/57 [00:12<00:00,  4.43it/s]
replacing val labels with victim labels
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:00<00:03,  1.75it/s] 29%|██▊       | 2/7 [00:00<00:01,  2.84it/s] 43%|████▎     | 3/7 [00:00<00:01,  3.44it/s] 57%|█████▋    | 4/7 [00:01<00:00,  3.92it/s] 71%|███████▏  | 5/7 [00:01<00:00,  3.76it/s] 86%|████████▌ | 6/7 [00:01<00:00,  4.16it/s]100%|██████████| 7/7 [00:01<00:00,  3.77it/s]Validation set distribution: 
Number of samples  100

{0: 9, 1: 18, 2: 73}
Labeled set distribution: 
Number of samples  900
{0: 111, 1: 200, 2: 589}
odict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias', 'heads.head.weight', 'heads.head.bias'])
thief state:  None
pretrained state:  dict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias'])
Thief model initialized successfully
specificity = 80/80
sensitivity = 0/42
Initial model on target dataset: acc = 0.2541, agreement = 0.2377, f1 = 0.1351, spec = 1.0000, sens = 0.0000
specificity = 27/27
sensitivity = 0/73
Initial model on validation dataset: acc = 0.0900, agreement = 0.0900, f1 = 0.0550, spec = 1.0000, sens = 0.0000
la:  None
>> Train a Model.
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:09<16:22,  9.92s/it]  2%|▏         | 2/100 [00:21<17:49, 10.91s/it]  3%|▎         | 3/100 [00:31<16:58, 10.50s/it]  4%|▍         | 4/100 [00:43<17:37, 11.01s/it]  5%|▌         | 5/100 [01:00<20:47, 13.13s/it]Epoch 5: Train acc/f1 = 0.7100 / 0.4154 / 0.2926 / 0.9779 
                Val acc/f1/spec/sens = 0.7700 / 0.4606 / 0.2222 / 1.0000
                Test acc/f1/spec/sens = 0.4344 / 0.3108 / 0.2250 / 0.9524
  6%|▌         | 6/100 [01:11<19:50, 12.66s/it]  7%|▋         | 7/100 [01:22<18:17, 11.80s/it]  8%|▊         | 8/100 [01:33<17:42, 11.55s/it]  9%|▉         | 9/100 [01:43<16:48, 11.08s/it] 10%|█         | 10/100 [02:00<19:41, 13.13s/it]Epoch 10: Train acc/f1 = 0.7100 / 0.4513 / 0.2186 / 0.9898 
                Val acc/f1/spec/sens = 0.7800 / 0.4373 / 0.3333 / 0.9863
                Test acc/f1/spec/sens = 0.3525 / 0.2161 / 0.0875 / 0.9524
 11%|█         | 11/100 [02:10<18:03, 12.17s/it] 12%|█▏        | 12/100 [02:21<17:23, 11.86s/it] 13%|█▎        | 13/100 [02:32<16:26, 11.34s/it] 14%|█▍        | 14/100 [02:43<16:12, 11.31s/it] 15%|█▌        | 15/100 [03:00<18:25, 13.00s/it]Epoch 15: Train acc/f1 = 0.7867 / 0.6532 / 0.5563 / 0.9694 
                Val acc/f1/spec/sens = 0.8300 / 0.5893 / 0.8148 / 0.9315
                Test acc/f1/spec/sens = 0.3934 / 0.2855 / 0.2750 / 0.9048
 16%|█▌        | 16/100 [03:11<17:22, 12.41s/it] 17%|█▋        | 17/100 [03:21<16:10, 11.70s/it] 18%|█▊        | 18/100 [03:33<16:02, 11.74s/it] 19%|█▉        | 19/100 [03:43<15:08, 11.22s/it] 20%|██        | 20/100 [04:01<17:58, 13.48s/it]Epoch 20: Train acc/f1 = 0.8256 / 0.7422 / 0.8071 / 0.9134 
                Val acc/f1/spec/sens = 0.8600 / 0.7186 / 0.8889 / 0.9452
                Test acc/f1/spec/sens = 0.4590 / 0.3976 / 0.7375 / 0.5476
 21%|██        | 21/100 [04:11<16:21, 12.43s/it] 22%|██▏       | 22/100 [04:23<15:54, 12.24s/it] 23%|██▎       | 23/100 [04:33<14:51, 11.58s/it] 24%|██▍       | 24/100 [04:45<14:45, 11.65s/it] 25%|██▌       | 25/100 [05:02<16:38, 13.31s/it]Epoch 25: Train acc/f1 = 0.8689 / 0.8187 / 0.8810 / 0.9168 
                Val acc/f1/spec/sens = 0.8600 / 0.7800 / 0.8889 / 0.9041
                Test acc/f1/spec/sens = 0.5164 / 0.5064 / 0.8000 / 0.5952
 26%|██▌       | 26/100 [05:14<15:49, 12.83s/it] 27%|██▋       | 27/100 [05:24<14:38, 12.04s/it] 28%|██▊       | 28/100 [05:36<14:23, 12.00s/it] 29%|██▉       | 29/100 [05:46<13:30, 11.42s/it] 30%|███       | 30/100 [06:04<15:40, 13.44s/it]Epoch 30: Train acc/f1 = 0.8922 / 0.8457 / 0.8842 / 0.9508 
                Val acc/f1/spec/sens = 0.8900 / 0.8222 / 0.8889 / 0.9315
                Test acc/f1/spec/sens = 0.5574 / 0.5309 / 0.8000 / 0.5952
 31%|███       | 31/100 [06:14<14:18, 12.44s/it] 32%|███▏      | 32/100 [06:25<13:38, 12.04s/it] 33%|███▎      | 33/100 [06:36<12:47, 11.45s/it] 34%|███▍      | 34/100 [06:47<12:28, 11.35s/it] 35%|███▌      | 35/100 [07:03<14:04, 12.99s/it]Epoch 35: Train acc/f1 = 0.9233 / 0.8958 / 0.9068 / 0.9593 
                Val acc/f1/spec/sens = 0.8800 / 0.8101 / 0.9259 / 0.9041
                Test acc/f1/spec/sens = 0.5246 / 0.4462 / 0.7625 / 0.5952
 36%|███▌      | 36/100 [07:15<13:27, 12.62s/it] 37%|███▋      | 37/100 [07:25<12:26, 11.85s/it] 38%|███▊      | 38/100 [07:36<12:00, 11.63s/it] 39%|███▉      | 39/100 [07:47<11:23, 11.20s/it] 40%|████      | 40/100 [08:06<13:39, 13.65s/it]Epoch 40: Train acc/f1 = 0.9244 / 0.8958 / 0.9357 / 0.9474 
                Val acc/f1/spec/sens = 0.9100 / 0.8642 / 0.9630 / 0.9178
                Test acc/f1/spec/sens = 0.5246 / 0.4841 / 0.8125 / 0.5000
 41%|████      | 41/100 [08:16<12:23, 12.61s/it] 42%|████▏     | 42/100 [08:27<11:44, 12.14s/it] 43%|████▎     | 43/100 [08:37<10:56, 11.53s/it] 44%|████▍     | 44/100 [08:49<10:50, 11.62s/it] 45%|████▌     | 45/100 [09:07<12:14, 13.36s/it]Epoch 45: Train acc/f1 = 0.9333 / 0.9092 / 0.9325 / 0.9593 
                Val acc/f1/spec/sens = 0.9200 / 0.8735 / 0.9630 / 0.9315
                Test acc/f1/spec/sens = 0.5574 / 0.5338 / 0.8375 / 0.5238
 46%|████▌     | 46/100 [09:18<11:23, 12.66s/it] 47%|████▋     | 47/100 [09:28<10:30, 11.90s/it] 48%|████▊     | 48/100 [09:39<10:05, 11.65s/it] 49%|████▉     | 49/100 [09:49<09:29, 11.16s/it] 50%|█████     | 50/100 [10:07<11:06, 13.33s/it]Epoch 50: Train acc/f1 = 0.9267 / 0.8948 / 0.9100 / 0.9660 
                Val acc/f1/spec/sens = 0.9200 / 0.8735 / 0.9630 / 0.9315
                Test acc/f1/spec/sens = 0.5328 / 0.5009 / 0.8125 / 0.5238
 51%|█████     | 51/100 [10:17<10:04, 12.35s/it] 52%|█████▏    | 52/100 [10:28<09:36, 12.00s/it] 53%|█████▎    | 53/100 [10:39<08:58, 11.45s/it] 54%|█████▍    | 54/100 [10:50<08:47, 11.46s/it] 55%|█████▌    | 55/100 [11:08<10:07, 13.49s/it]Epoch 55: Train acc/f1 = 0.9311 / 0.8960 / 0.9421 / 0.9643 
                Val acc/f1/spec/sens = 0.8900 / 0.8197 / 0.8889 / 0.9315
                Test acc/f1/spec/sens = 0.5410 / 0.5212 / 0.8250 / 0.5000
 56%|█████▌    | 56/100 [11:19<09:22, 12.79s/it] 57%|█████▋    | 57/100 [11:29<08:34, 11.97s/it] 58%|█████▊    | 58/100 [11:41<08:11, 11.70s/it] 59%|█████▉    | 59/100 [11:51<07:38, 11.19s/it] 60%|██████    | 60/100 [12:09<08:54, 13.37s/it]Epoch 60: Train acc/f1 = 0.9411 / 0.9173 / 0.9518 / 0.9626 
                Val acc/f1/spec/sens = 0.8800 / 0.8109 / 0.8889 / 0.9178
                Test acc/f1/spec/sens = 0.5410 / 0.5141 / 0.8375 / 0.5000
 61%|██████    | 61/100 [12:19<08:02, 12.38s/it] 62%|██████▏   | 62/100 [12:30<07:36, 12.02s/it] 63%|██████▎   | 63/100 [12:40<07:03, 11.44s/it] 64%|██████▍   | 64/100 [12:51<06:48, 11.34s/it] 65%|██████▌   | 65/100 [13:09<07:40, 13.16s/it]Epoch 65: Train acc/f1 = 0.9467 / 0.9267 / 0.9421 / 0.9677 
                Val acc/f1/spec/sens = 0.8800 / 0.8109 / 0.8889 / 0.9178
                Test acc/f1/spec/sens = 0.5410 / 0.5141 / 0.8375 / 0.5000
 66%|██████▌   | 66/100 [13:20<07:07, 12.58s/it] 67%|██████▋   | 67/100 [13:30<06:30, 11.82s/it] 68%|██████▊   | 68/100 [13:41<06:11, 11.61s/it] 69%|██████▉   | 69/100 [13:51<05:45, 11.16s/it] 70%|███████   | 70/100 [14:09<06:35, 13.19s/it]Epoch 70: Train acc/f1 = 0.9244 / 0.8910 / 0.9100 / 0.9660 
                Val acc/f1/spec/sens = 0.8800 / 0.8109 / 0.8889 / 0.9178
                Test acc/f1/spec/sens = 0.5410 / 0.5204 / 0.8375 / 0.5000
 71%|███████   | 71/100 [14:19<05:55, 12.25s/it] 72%|███████▏  | 72/100 [14:30<05:32, 11.89s/it] 73%|███████▎  | 73/100 [14:40<05:06, 11.33s/it] 74%|███████▍  | 74/100 [14:51<04:52, 11.25s/it] 75%|███████▌  | 75/100 [15:10<05:32, 13.32s/it]Epoch 75: Train acc/f1 = 0.9333 / 0.9061 / 0.9293 / 0.9643 
                Val acc/f1/spec/sens = 0.8800 / 0.8109 / 0.8889 / 0.9178
                Test acc/f1/spec/sens = 0.5410 / 0.5204 / 0.8375 / 0.5000
 76%|███████▌  | 76/100 [15:21<05:06, 12.76s/it] 77%|███████▋  | 77/100 [15:31<04:35, 11.99s/it] 78%|███████▊  | 78/100 [15:42<04:18, 11.75s/it] 79%|███████▉  | 79/100 [15:53<03:57, 11.30s/it] 80%|████████  | 80/100 [16:14<04:44, 14.21s/it]Epoch 80: Train acc/f1 = 0.9389 / 0.9128 / 0.9486 / 0.9610 
                Val acc/f1/spec/sens = 0.8900 / 0.8238 / 0.9259 / 0.9178
                Test acc/f1/spec/sens = 0.5410 / 0.5204 / 0.8375 / 0.5000
 81%|████████  | 81/100 [16:24<04:09, 13.11s/it] 82%|████████▏ | 82/100 [16:36<03:46, 12.61s/it] 83%|████████▎ | 83/100 [16:46<03:21, 11.86s/it] 84%|████████▍ | 84/100 [16:57<03:07, 11.69s/it] 85%|████████▌ | 85/100 [17:16<03:29, 13.95s/it]Epoch 85: Train acc/f1 = 0.9389 / 0.9144 / 0.9100 / 0.9779 
                Val acc/f1/spec/sens = 0.8900 / 0.8238 / 0.9259 / 0.9178
                Test acc/f1/spec/sens = 0.5410 / 0.5204 / 0.8375 / 0.5000
 86%|████████▌ | 86/100 [17:28<03:04, 13.20s/it] 87%|████████▋ | 87/100 [17:38<02:39, 12.28s/it] 88%|████████▊ | 88/100 [17:49<02:23, 11.92s/it] 89%|████████▉ | 89/100 [17:59<02:05, 11.38s/it] 90%|█████████ | 90/100 [18:18<02:15, 13.54s/it]Epoch 90: Train acc/f1 = 0.9311 / 0.9010 / 0.9389 / 0.9626 
                Val acc/f1/spec/sens = 0.8900 / 0.8238 / 0.9259 / 0.9178
                Test acc/f1/spec/sens = 0.5410 / 0.5204 / 0.8375 / 0.5000
 91%|█████████ | 91/100 [18:28<01:52, 12.49s/it] 92%|█████████▏| 92/100 [18:39<01:37, 12.13s/it] 93%|█████████▎| 93/100 [18:49<01:20, 11.54s/it] 94%|█████████▍| 94/100 [19:00<01:08, 11.43s/it] 95%|█████████▌| 95/100 [19:17<01:05, 13.09s/it]Epoch 95: Train acc/f1 = 0.9344 / 0.9067 / 0.9196 / 0.9728 
                Val acc/f1/spec/sens = 0.8900 / 0.8238 / 0.9259 / 0.9178
                Test acc/f1/spec/sens = 0.5410 / 0.5204 / 0.8375 / 0.5000
 96%|█████████▌| 96/100 [19:28<00:49, 12.48s/it] 97%|█████████▋| 97/100 [19:38<00:35, 11.76s/it] 98%|█████████▊| 98/100 [19:50<00:23, 11.57s/it] 99%|█████████▉| 99/100 [20:00<00:11, 11.13s/it]100%|██████████| 100/100 [20:18<00:00, 13.32s/it]                                                 Epoch 100: Train acc/f1 = 0.9411 / 0.9226 / 0.9196 / 0.9711 
                Val acc/f1/spec/sens = 0.8900 / 0.8238 / 0.9259 / 0.9178
                Test acc/f1/spec/sens = 0.5410 / 0.5204 / 0.8375 / 0.5000
specificity = 292/311
sensitivity = 574/589
specificity = 25/27
sensitivity = 67/73
specificity = 67/80
sensitivity = 21/42
Trial 1, Cycle 1
Train acc/f1/spec/sens = 0.9456 / 0.9253 / 0.9389 / 0.9745
Val acc/f1/spec/sens = 0.8900 / 0.8238 / 0.9259 / 0.9178
Test acc/f1/spec/sens = 0.5410 / 0.5204 / 0.8375 / 0.5000
>> Finished.
specificity = 67/80
sensitivity = 21/42
Acc, agreement for latest model:  0.5409836065573771 0.5491803278688525
Load best checkpoint for thief model
specificity = 64/80
sensitivity = 22/42
Acc, agreement for best model:  0.5327868852459017 0.5573770491803278
Trial 0/5 || Cycle 1/1 || Label set size 900 || Test acc 0.5328 || Test agreement 0.5574 || Spec 0.8000 || Sens 0.5238
**************************************************************************************************** 

specificity = 64/80
sensitivity = 22/42
Number of samples  900
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
replacing labeled set labels with victim labels
  0%|          | 0/57 [00:00<?, ?it/s]  2%|▏         | 1/57 [00:00<00:41,  1.35it/s]  4%|▎         | 2/57 [00:01<00:25,  2.17it/s]  5%|▌         | 3/57 [00:01<00:19,  2.75it/s]  7%|▋         | 4/57 [00:01<00:16,  3.14it/s]  9%|▉         | 5/57 [00:01<00:15,  3.44it/s] 11%|█         | 6/57 [00:01<00:14,  3.60it/s] 12%|█▏        | 7/57 [00:02<00:12,  3.95it/s] 14%|█▍        | 8/57 [00:02<00:12,  3.92it/s] 16%|█▌        | 9/57 [00:02<00:12,  3.86it/s] 18%|█▊        | 10/57 [00:02<00:11,  4.02it/s] 19%|█▉        | 11/57 [00:03<00:12,  3.76it/s] 21%|██        | 12/57 [00:03<00:11,  3.77it/s] 23%|██▎       | 13/57 [00:03<00:11,  3.71it/s] 25%|██▍       | 14/57 [00:04<00:12,  3.55it/s] 26%|██▋       | 15/57 [00:04<00:12,  3.50it/s] 28%|██▊       | 16/57 [00:04<00:11,  3.43it/s] 30%|██▉       | 17/57 [00:05<00:11,  3.40it/s] 32%|███▏      | 18/57 [00:05<00:11,  3.43it/s] 33%|███▎      | 19/57 [00:05<00:11,  3.41it/s] 35%|███▌      | 20/57 [00:05<00:11,  3.35it/s] 37%|███▋      | 21/57 [00:06<00:10,  3.39it/s] 39%|███▊      | 22/57 [00:06<00:10,  3.36it/s] 40%|████      | 23/57 [00:06<00:10,  3.38it/s] 42%|████▏     | 24/57 [00:07<00:11,  2.78it/s] 44%|████▍     | 25/57 [00:07<00:11,  2.75it/s] 46%|████▌     | 26/57 [00:07<00:10,  2.92it/s] 47%|████▋     | 27/57 [00:08<00:09,  3.11it/s] 49%|████▉     | 28/57 [00:08<00:08,  3.26it/s] 51%|█████     | 29/57 [00:08<00:08,  3.39it/s] 53%|█████▎    | 30/57 [00:09<00:07,  3.49it/s] 54%|█████▍    | 31/57 [00:09<00:07,  3.60it/s] 56%|█████▌    | 32/57 [00:09<00:06,  3.66it/s] 58%|█████▊    | 33/57 [00:09<00:06,  3.71it/s] 60%|█████▉    | 34/57 [00:10<00:06,  3.68it/s] 61%|██████▏   | 35/57 [00:10<00:05,  3.72it/s] 63%|██████▎   | 36/57 [00:10<00:05,  3.82it/s] 65%|██████▍   | 37/57 [00:10<00:04,  4.14it/s] 67%|██████▋   | 38/57 [00:10<00:04,  4.40it/s] 68%|██████▊   | 39/57 [00:11<00:03,  4.59it/s] 70%|███████   | 40/57 [00:11<00:03,  4.71it/s] 72%|███████▏  | 41/57 [00:11<00:03,  4.81it/s] 74%|███████▎  | 42/57 [00:11<00:03,  4.87it/s] 75%|███████▌  | 43/57 [00:11<00:02,  4.93it/s] 77%|███████▋  | 44/57 [00:12<00:02,  4.99it/s] 79%|███████▉  | 45/57 [00:12<00:02,  5.02it/s] 81%|████████  | 46/57 [00:12<00:02,  5.04it/s] 82%|████████▏ | 47/57 [00:12<00:01,  5.07it/s] 84%|████████▍ | 48/57 [00:12<00:01,  5.09it/s] 86%|████████▌ | 49/57 [00:13<00:01,  4.42it/s] 88%|████████▊ | 50/57 [00:13<00:01,  4.06it/s] 89%|████████▉ | 51/57 [00:13<00:01,  4.32it/s] 91%|█████████ | 52/57 [00:13<00:01,  4.52it/s] 93%|█████████▎| 53/57 [00:14<00:00,  4.42it/s] 95%|█████████▍| 54/57 [00:14<00:00,  4.11it/s] 96%|█████████▋| 55/57 [00:14<00:00,  4.02it/s] 98%|█████████▊| 56/57 [00:14<00:00,  3.99it/s]100%|██████████| 57/57 [00:15<00:00,  3.75it/s]
replacing val labels with victim labels
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:00<00:04,  1.37it/s] 29%|██▊       | 2/7 [00:01<00:02,  2.16it/s] 43%|████▎     | 3/7 [00:01<00:01,  2.94it/s] 57%|█████▋    | 4/7 [00:01<00:00,  3.51it/s] 71%|███████▏  | 5/7 [00:01<00:00,  3.96it/s] 86%|████████▌ | 6/7 [00:01<00:00,  4.26it/s]100%|██████████| 7/7 [00:01<00:00,  3.54it/s]Validation set distribution: 
Number of samples  100

{0: 16, 1: 21, 2: 63}
Labeled set distribution: 
Number of samples  900
{0: 102, 1: 220, 2: 578}
odict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias', 'heads.head.weight', 'heads.head.bias'])
thief state:  None
pretrained state:  dict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias'])
Thief model initialized successfully
specificity = 80/80
sensitivity = 0/42
Initial model on target dataset: acc = 0.2541, agreement = 0.2377, f1 = 0.1351, spec = 1.0000, sens = 0.0000
specificity = 37/37
sensitivity = 0/63
Initial model on validation dataset: acc = 0.1600, agreement = 0.1600, f1 = 0.0920, spec = 1.0000, sens = 0.0000
la:  None
>> Train a Model.
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:09<16:25,  9.96s/it]  2%|▏         | 2/100 [00:21<17:52, 10.94s/it]  3%|▎         | 3/100 [00:31<17:04, 10.56s/it]  4%|▍         | 4/100 [00:43<17:42, 11.06s/it]  5%|▌         | 5/100 [01:01<21:18, 13.45s/it]Epoch 5: Train acc/f1 = 0.6989 / 0.4409 / 0.4441 / 0.9256 
                Val acc/f1/spec/sens = 0.6400 / 0.4253 / 0.6486 / 0.8095
                Test acc/f1/spec/sens = 0.3443 / 0.2112 / 0.1250 / 0.9048
  6%|▌         | 6/100 [01:13<20:19, 12.97s/it]  7%|▋         | 7/100 [01:23<18:39, 12.04s/it]  8%|▊         | 8/100 [01:35<18:25, 12.01s/it]  9%|▉         | 9/100 [01:45<17:19, 11.43s/it] 10%|█         | 10/100 [02:04<20:46, 13.85s/it]Epoch 10: Train acc/f1 = 0.7300 / 0.5860 / 0.5807 / 0.8997 
                Val acc/f1/spec/sens = 0.7000 / 0.5658 / 0.5946 / 0.8889
                Test acc/f1/spec/sens = 0.3852 / 0.2531 / 0.2375 / 0.9524
 11%|█         | 11/100 [02:14<18:52, 12.72s/it] 12%|█▏        | 12/100 [02:27<18:23, 12.54s/it] 13%|█▎        | 13/100 [02:37<17:09, 11.83s/it] 14%|█▍        | 14/100 [02:49<17:03, 11.90s/it] 15%|█▌        | 15/100 [03:06<19:06, 13.49s/it]Epoch 15: Train acc/f1 = 0.7389 / 0.5974 / 0.5776 / 0.9343 
                Val acc/f1/spec/sens = 0.7000 / 0.6077 / 0.8649 / 0.7937
                Test acc/f1/spec/sens = 0.4016 / 0.3456 / 0.2750 / 0.8333
 16%|█▌        | 16/100 [03:18<18:17, 13.06s/it] 17%|█▋        | 17/100 [03:28<16:49, 12.17s/it] 18%|█▊        | 18/100 [03:39<16:12, 11.86s/it] 19%|█▉        | 19/100 [03:49<15:19, 11.35s/it] 20%|██        | 20/100 [04:08<18:01, 13.52s/it]Epoch 20: Train acc/f1 = 0.7156 / 0.5196 / 0.3043 / 0.9810 
                Val acc/f1/spec/sens = 0.7300 / 0.5647 / 0.3784 / 0.9841
                Test acc/f1/spec/sens = 0.3443 / 0.1707 / 0.0000 / 1.0000
 21%|██        | 21/100 [04:18<16:27, 12.51s/it] 22%|██▏       | 22/100 [04:30<16:02, 12.34s/it] 23%|██▎       | 23/100 [04:40<14:59, 11.68s/it] 24%|██▍       | 24/100 [04:52<14:38, 11.55s/it] 25%|██▌       | 25/100 [05:09<16:42, 13.37s/it]Epoch 25: Train acc/f1 = 0.8100 / 0.7150 / 0.7826 / 0.9204 
                Val acc/f1/spec/sens = 0.8000 / 0.7263 / 0.8919 / 0.8730
                Test acc/f1/spec/sens = 0.3770 / 0.3489 / 0.4125 / 0.5952
 26%|██▌       | 26/100 [05:20<15:41, 12.73s/it] 27%|██▋       | 27/100 [05:31<14:32, 11.95s/it] 28%|██▊       | 28/100 [05:42<14:02, 11.71s/it] 29%|██▉       | 29/100 [05:52<13:17, 11.23s/it] 30%|███       | 30/100 [06:11<15:56, 13.66s/it]Epoch 30: Train acc/f1 = 0.8000 / 0.7065 / 0.7609 / 0.9152 
                Val acc/f1/spec/sens = 0.8300 / 0.7464 / 0.9189 / 0.9206
                Test acc/f1/spec/sens = 0.4262 / 0.3911 / 0.5875 / 0.5000
 31%|███       | 31/100 [06:21<14:29, 12.60s/it] 32%|███▏      | 32/100 [06:32<13:46, 12.15s/it] 33%|███▎      | 33/100 [06:42<12:53, 11.54s/it] 34%|███▍      | 34/100 [06:54<12:32, 11.40s/it] 35%|███▌      | 35/100 [07:11<14:16, 13.18s/it]Epoch 35: Train acc/f1 = 0.8144 / 0.7347 / 0.8012 / 0.9187 
                Val acc/f1/spec/sens = 0.8300 / 0.7177 / 0.8649 / 0.9841
                Test acc/f1/spec/sens = 0.4426 / 0.4394 / 0.6375 / 0.4762
 36%|███▌      | 36/100 [07:22<13:24, 12.57s/it] 37%|███▋      | 37/100 [07:32<12:27, 11.86s/it] 38%|███▊      | 38/100 [07:43<12:00, 11.62s/it] 39%|███▉      | 39/100 [07:54<11:25, 11.24s/it] 40%|████      | 40/100 [08:13<13:33, 13.56s/it]Epoch 40: Train acc/f1 = 0.8433 / 0.7790 / 0.8758 / 0.9083 
                Val acc/f1/spec/sens = 0.8500 / 0.7522 / 0.8919 / 0.9841
                Test acc/f1/spec/sens = 0.4344 / 0.4160 / 0.6625 / 0.4286
 41%|████      | 41/100 [08:23<12:21, 12.57s/it] 42%|████▏     | 42/100 [08:35<12:00, 12.41s/it] 43%|████▎     | 43/100 [08:45<11:10, 11.76s/it] 44%|████▍     | 44/100 [08:57<10:52, 11.65s/it] 45%|████▌     | 45/100 [09:14<12:18, 13.43s/it]Epoch 45: Train acc/f1 = 0.8556 / 0.7989 / 0.8447 / 0.9221 
                Val acc/f1/spec/sens = 0.8600 / 0.7792 / 0.8919 / 0.9683
                Test acc/f1/spec/sens = 0.4344 / 0.3710 / 0.7125 / 0.4286
 46%|████▌     | 46/100 [09:25<11:28, 12.75s/it] 47%|████▋     | 47/100 [09:35<10:34, 11.96s/it] 48%|████▊     | 48/100 [09:47<10:18, 11.89s/it] 49%|████▉     | 49/100 [09:58<09:45, 11.48s/it] 50%|█████     | 50/100 [10:17<11:28, 13.78s/it]Epoch 50: Train acc/f1 = 0.8644 / 0.7936 / 0.8913 / 0.9256 
                Val acc/f1/spec/sens = 0.8700 / 0.7882 / 0.8919 / 0.9841
                Test acc/f1/spec/sens = 0.4508 / 0.4064 / 0.7000 / 0.4286
 51%|█████     | 51/100 [10:27<10:23, 12.73s/it] 52%|█████▏    | 52/100 [10:39<09:54, 12.39s/it] 53%|█████▎    | 53/100 [10:49<09:13, 11.78s/it] 54%|█████▍    | 54/100 [11:01<08:59, 11.73s/it] 55%|█████▌    | 55/100 [11:18<10:02, 13.38s/it]Epoch 55: Train acc/f1 = 0.8656 / 0.8056 / 0.8665 / 0.9291 
                Val acc/f1/spec/sens = 0.8700 / 0.7882 / 0.8919 / 0.9841
                Test acc/f1/spec/sens = 0.4098 / 0.3475 / 0.7125 / 0.3571
 56%|█████▌    | 56/100 [11:29<09:21, 12.76s/it] 57%|█████▋    | 57/100 [11:39<08:35, 11.99s/it] 58%|█████▊    | 58/100 [11:51<08:17, 11.84s/it] 59%|█████▉    | 59/100 [12:01<07:44, 11.33s/it] 60%|██████    | 60/100 [12:19<08:52, 13.32s/it]Epoch 60: Train acc/f1 = 0.8878 / 0.8406 / 0.9006 / 0.9325 
                Val acc/f1/spec/sens = 0.8600 / 0.7792 / 0.8919 / 0.9683
                Test acc/f1/spec/sens = 0.4426 / 0.3932 / 0.7750 / 0.3571
 61%|██████    | 61/100 [12:29<08:03, 12.39s/it] 62%|██████▏   | 62/100 [12:40<07:37, 12.03s/it] 63%|██████▎   | 63/100 [12:51<07:06, 11.53s/it] 64%|██████▍   | 64/100 [13:02<06:54, 11.51s/it] 65%|██████▌   | 65/100 [13:20<07:49, 13.41s/it]Epoch 65: Train acc/f1 = 0.8689 / 0.8098 / 0.8820 / 0.9256 
                Val acc/f1/spec/sens = 0.8600 / 0.7792 / 0.8919 / 0.9683
                Test acc/f1/spec/sens = 0.4508 / 0.4015 / 0.7750 / 0.3810
 66%|██████▌   | 66/100 [13:31<07:13, 12.74s/it] 67%|██████▋   | 67/100 [13:41<06:34, 11.95s/it] 68%|██████▊   | 68/100 [13:53<06:16, 11.76s/it] 69%|██████▉   | 69/100 [14:03<05:51, 11.34s/it] 70%|███████   | 70/100 [14:21<06:39, 13.32s/it]Epoch 70: Train acc/f1 = 0.8733 / 0.8180 / 0.8696 / 0.9325 
                Val acc/f1/spec/sens = 0.8600 / 0.7792 / 0.8919 / 0.9683
                Test acc/f1/spec/sens = 0.4344 / 0.3902 / 0.7500 / 0.3810
 71%|███████   | 71/100 [14:31<05:58, 12.37s/it] 72%|███████▏  | 72/100 [14:42<05:36, 12.00s/it] 73%|███████▎  | 73/100 [14:53<05:10, 11.48s/it] 74%|███████▍  | 74/100 [15:04<04:58, 11.49s/it] 75%|███████▌  | 75/100 [15:23<05:41, 13.64s/it]Epoch 75: Train acc/f1 = 0.8678 / 0.7971 / 0.8665 / 0.9446 
                Val acc/f1/spec/sens = 0.8600 / 0.7792 / 0.8919 / 0.9683
                Test acc/f1/spec/sens = 0.4426 / 0.3959 / 0.7625 / 0.3810
 76%|███████▌  | 76/100 [15:34<05:12, 13.00s/it] 77%|███████▋  | 77/100 [15:44<04:39, 12.15s/it] 78%|███████▊  | 78/100 [15:56<04:25, 12.08s/it] 79%|███████▉  | 79/100 [16:07<04:03, 11.59s/it] 80%|████████  | 80/100 [16:31<05:05, 15.29s/it]Epoch 80: Train acc/f1 = 0.8733 / 0.8201 / 0.8727 / 0.9308 
                Val acc/f1/spec/sens = 0.8600 / 0.7792 / 0.8919 / 0.9683
                Test acc/f1/spec/sens = 0.4344 / 0.3902 / 0.7500 / 0.3810
 81%|████████  | 81/100 [16:41<04:22, 13.81s/it] 82%|████████▏ | 82/100 [16:52<03:55, 13.06s/it] 83%|████████▎ | 83/100 [17:03<03:28, 12.24s/it] 84%|████████▍ | 84/100 [17:14<03:11, 11.97s/it] 85%|████████▌ | 85/100 [17:31<03:23, 13.55s/it]Epoch 85: Train acc/f1 = 0.8811 / 0.8299 / 0.8634 / 0.9498 
                Val acc/f1/spec/sens = 0.8600 / 0.7792 / 0.8919 / 0.9683
                Test acc/f1/spec/sens = 0.4344 / 0.3902 / 0.7500 / 0.3810
 86%|████████▌ | 86/100 [17:42<03:00, 12.86s/it] 87%|████████▋ | 87/100 [17:53<02:36, 12.06s/it] 88%|████████▊ | 88/100 [18:04<02:22, 11.86s/it] 89%|████████▉ | 89/100 [18:14<02:04, 11.36s/it] 90%|█████████ | 90/100 [18:33<02:15, 13.56s/it]Epoch 90: Train acc/f1 = 0.8822 / 0.8295 / 0.8944 / 0.9377 
                Val acc/f1/spec/sens = 0.8600 / 0.7792 / 0.8919 / 0.9683
                Test acc/f1/spec/sens = 0.4344 / 0.3902 / 0.7500 / 0.3810
 91%|█████████ | 91/100 [18:43<01:52, 12.55s/it] 92%|█████████▏| 92/100 [18:54<01:37, 12.16s/it] 93%|█████████▎| 93/100 [19:05<01:20, 11.55s/it] 94%|█████████▍| 94/100 [19:16<01:08, 11.47s/it] 95%|█████████▌| 95/100 [19:34<01:06, 13.36s/it]Epoch 95: Train acc/f1 = 0.8722 / 0.8124 / 0.8820 / 0.9325 
                Val acc/f1/spec/sens = 0.8600 / 0.7792 / 0.8919 / 0.9683
                Test acc/f1/spec/sens = 0.4344 / 0.3902 / 0.7500 / 0.3810
 96%|█████████▌| 96/100 [19:45<00:50, 12.75s/it] 97%|█████████▋| 97/100 [19:55<00:35, 11.99s/it] 98%|█████████▊| 98/100 [20:06<00:23, 11.78s/it] 99%|█████████▉| 99/100 [20:17<00:11, 11.31s/it]100%|██████████| 100/100 [20:35<00:00, 13.56s/it]                                                 Epoch 100: Train acc/f1 = 0.8822 / 0.8307 / 0.8634 / 0.9481 
                Val acc/f1/spec/sens = 0.8600 / 0.7792 / 0.8919 / 0.9683
                Test acc/f1/spec/sens = 0.4344 / 0.3902 / 0.7500 / 0.3810
specificity = 272/322
sensitivity = 545/578
specificity = 33/37
sensitivity = 61/63
specificity = 60/80
sensitivity = 16/42
Trial 2, Cycle 1
Train acc/f1/spec/sens = 0.8756 / 0.8167 / 0.8447 / 0.9429
Val acc/f1/spec/sens = 0.8600 / 0.7792 / 0.8919 / 0.9683
Test acc/f1/spec/sens = 0.4344 / 0.3902 / 0.7500 / 0.3810
>> Finished.
specificity = 60/80
sensitivity = 16/42
Acc, agreement for latest model:  0.4344262295081967 0.4918032786885246
Load best checkpoint for thief model
specificity = 54/80
sensitivity = 18/42
Acc, agreement for best model:  0.4344262295081967 0.5
Trial 1/5 || Cycle 1/1 || Label set size 900 || Test acc 0.4344 || Test agreement 0.5000 || Spec 0.6750 || Sens 0.4286
**************************************************************************************************** 

specificity = 54/80
sensitivity = 18/42
Number of samples  900
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
replacing labeled set labels with victim labels
  0%|          | 0/57 [00:00<?, ?it/s]  2%|▏         | 1/57 [00:00<00:51,  1.09it/s]  4%|▎         | 2/57 [00:01<00:29,  1.85it/s]  5%|▌         | 3/57 [00:01<00:22,  2.36it/s]  7%|▋         | 4/57 [00:01<00:19,  2.76it/s]  9%|▉         | 5/57 [00:02<00:16,  3.07it/s] 11%|█         | 6/57 [00:02<00:15,  3.24it/s] 12%|█▏        | 7/57 [00:02<00:13,  3.65it/s] 14%|█▍        | 8/57 [00:02<00:13,  3.68it/s] 16%|█▌        | 9/57 [00:03<00:12,  3.74it/s] 18%|█▊        | 10/57 [00:03<00:12,  3.89it/s] 19%|█▉        | 11/57 [00:03<00:11,  4.14it/s] 21%|██        | 12/57 [00:03<00:11,  4.00it/s] 23%|██▎       | 13/57 [00:04<00:11,  3.68it/s] 25%|██▍       | 14/57 [00:04<00:11,  3.60it/s] 26%|██▋       | 15/57 [00:04<00:11,  3.64it/s] 28%|██▊       | 16/57 [00:04<00:11,  3.57it/s] 30%|██▉       | 17/57 [00:05<00:11,  3.55it/s] 32%|███▏      | 18/57 [00:05<00:10,  3.62it/s] 33%|███▎      | 19/57 [00:05<00:10,  3.62it/s] 35%|███▌      | 20/57 [00:05<00:10,  3.61it/s] 37%|███▋      | 21/57 [00:06<00:09,  3.67it/s] 39%|███▊      | 22/57 [00:06<00:09,  3.66it/s] 40%|████      | 23/57 [00:06<00:09,  3.65it/s] 42%|████▏     | 24/57 [00:07<00:09,  3.67it/s] 44%|████▍     | 25/57 [00:07<00:08,  3.69it/s] 46%|████▌     | 26/57 [00:07<00:08,  3.73it/s] 47%|████▋     | 27/57 [00:07<00:08,  3.69it/s] 49%|████▉     | 28/57 [00:08<00:07,  3.67it/s] 51%|█████     | 29/57 [00:08<00:07,  3.70it/s] 53%|█████▎    | 30/57 [00:08<00:07,  3.73it/s] 54%|█████▍    | 31/57 [00:08<00:06,  3.74it/s] 56%|█████▌    | 32/57 [00:09<00:06,  3.77it/s] 58%|█████▊    | 33/57 [00:09<00:06,  3.70it/s] 60%|█████▉    | 34/57 [00:09<00:06,  3.72it/s] 61%|██████▏   | 35/57 [00:10<00:05,  3.76it/s] 63%|██████▎   | 36/57 [00:10<00:05,  3.78it/s] 65%|██████▍   | 37/57 [00:10<00:05,  3.79it/s] 67%|██████▋   | 38/57 [00:10<00:05,  3.75it/s] 68%|██████▊   | 39/57 [00:11<00:04,  3.71it/s] 70%|███████   | 40/57 [00:11<00:04,  3.71it/s] 72%|███████▏  | 41/57 [00:11<00:04,  3.77it/s] 74%|███████▎  | 42/57 [00:11<00:03,  3.80it/s] 75%|███████▌  | 43/57 [00:12<00:03,  3.75it/s] 77%|███████▋  | 44/57 [00:12<00:03,  3.79it/s] 79%|███████▉  | 45/57 [00:12<00:03,  3.81it/s] 81%|████████  | 46/57 [00:12<00:02,  3.83it/s] 82%|████████▏ | 47/57 [00:13<00:02,  3.82it/s] 84%|████████▍ | 48/57 [00:13<00:02,  3.86it/s] 86%|████████▌ | 49/57 [00:13<00:01,  4.18it/s] 88%|████████▊ | 50/57 [00:13<00:01,  4.41it/s] 89%|████████▉ | 51/57 [00:14<00:01,  4.39it/s] 91%|█████████ | 52/57 [00:14<00:01,  4.43it/s] 93%|█████████▎| 53/57 [00:14<00:00,  4.44it/s] 95%|█████████▍| 54/57 [00:14<00:00,  4.60it/s] 96%|█████████▋| 55/57 [00:15<00:00,  4.16it/s] 98%|█████████▊| 56/57 [00:15<00:00,  3.89it/s]100%|██████████| 57/57 [00:15<00:00,  3.66it/s]
replacing val labels with victim labels
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:00<00:04,  1.29it/s] 29%|██▊       | 2/7 [00:01<00:02,  2.05it/s] 43%|████▎     | 3/7 [00:01<00:01,  2.57it/s] 57%|█████▋    | 4/7 [00:01<00:01,  2.92it/s] 71%|███████▏  | 5/7 [00:01<00:00,  3.15it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.38it/s]100%|██████████| 7/7 [00:02<00:00,  3.02it/s]Validation set distribution: 
Number of samples  100

{0: 13, 1: 19, 2: 68}
Labeled set distribution: 
Number of samples  900
{0: 98, 1: 215, 2: 587}
odict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias', 'heads.head.weight', 'heads.head.bias'])
thief state:  None
pretrained state:  dict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias'])
Thief model initialized successfully
specificity = 80/80
sensitivity = 0/42
Initial model on target dataset: acc = 0.2541, agreement = 0.2377, f1 = 0.1351, spec = 1.0000, sens = 0.0000
specificity = 32/32
sensitivity = 0/68
Initial model on validation dataset: acc = 0.1300, agreement = 0.1300, f1 = 0.0767, spec = 1.0000, sens = 0.0000
la:  None
>> Train a Model.
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:09<16:29, 10.00s/it]  2%|▏         | 2/100 [00:21<18:03, 11.06s/it]  3%|▎         | 3/100 [00:32<17:14, 10.67s/it]  4%|▍         | 4/100 [00:43<17:27, 10.91s/it]  5%|▌         | 5/100 [01:00<20:59, 13.26s/it]Epoch 5: Train acc/f1 = 0.6544 / 0.2784 / 0.0224 / 0.9949 
                Val acc/f1/spec/sens = 0.6800 / 0.2698 / 0.0000 / 1.0000
                Test acc/f1/spec/sens = 0.3443 / 0.1707 / 0.0000 / 1.0000
  6%|▌         | 6/100 [01:12<19:58, 12.75s/it]  7%|▋         | 7/100 [01:22<18:28, 11.92s/it]  8%|▊         | 8/100 [01:34<18:12, 11.88s/it]  9%|▉         | 9/100 [01:44<17:12, 11.35s/it] 10%|█         | 10/100 [02:03<20:18, 13.53s/it]Epoch 10: Train acc/f1 = 0.6722 / 0.3413 / 0.1150 / 0.9847 
                Val acc/f1/spec/sens = 0.7100 / 0.3651 / 0.1562 / 1.0000
                Test acc/f1/spec/sens = 0.3443 / 0.1718 / 0.0125 / 1.0000
 11%|█         | 11/100 [02:13<18:34, 12.52s/it] 12%|█▏        | 12/100 [02:25<18:08, 12.37s/it] 13%|█▎        | 13/100 [02:35<16:56, 11.68s/it] 14%|█▍        | 14/100 [02:46<16:32, 11.54s/it] 15%|█▌        | 15/100 [03:04<18:56, 13.36s/it]Epoch 15: Train acc/f1 = 0.7478 / 0.6191 / 0.6198 / 0.9063 
                Val acc/f1/spec/sens = 0.7600 / 0.5752 / 0.4375 / 0.9706
                Test acc/f1/spec/sens = 0.4508 / 0.4157 / 0.5500 / 0.8571
 16%|█▌        | 16/100 [03:15<17:53, 12.78s/it] 17%|█▋        | 17/100 [03:25<16:38, 12.03s/it] 18%|█▊        | 18/100 [03:37<16:05, 11.77s/it] 19%|█▉        | 19/100 [03:47<15:14, 11.28s/it] 20%|██        | 20/100 [04:05<18:00, 13.51s/it]Epoch 20: Train acc/f1 = 0.7411 / 0.5726 / 0.4313 / 0.9676 
                Val acc/f1/spec/sens = 0.7600 / 0.5439 / 0.4688 / 0.9853
                Test acc/f1/spec/sens = 0.4098 / 0.3426 / 0.3625 / 0.8571
 21%|██        | 21/100 [04:16<16:32, 12.56s/it] 22%|██▏       | 22/100 [04:28<16:06, 12.39s/it] 23%|██▎       | 23/100 [04:38<15:02, 11.72s/it] 24%|██▍       | 24/100 [04:49<14:39, 11.57s/it] 25%|██▌       | 25/100 [05:07<16:48, 13.44s/it]Epoch 25: Train acc/f1 = 0.8278 / 0.7437 / 0.8019 / 0.9216 
                Val acc/f1/spec/sens = 0.7800 / 0.6092 / 0.6875 / 0.9559
                Test acc/f1/spec/sens = 0.4918 / 0.4922 / 0.7000 / 0.6429
 26%|██▌       | 26/100 [05:19<16:02, 13.01s/it] 27%|██▋       | 27/100 [05:29<14:48, 12.17s/it] 28%|██▊       | 28/100 [05:40<14:13, 11.85s/it] 29%|██▉       | 29/100 [05:51<13:26, 11.36s/it] 30%|███       | 30/100 [06:10<16:13, 13.91s/it]Epoch 30: Train acc/f1 = 0.8289 / 0.7616 / 0.8562 / 0.8961 
                Val acc/f1/spec/sens = 0.7800 / 0.6640 / 0.8125 / 0.8824
                Test acc/f1/spec/sens = 0.4836 / 0.4838 / 0.8000 / 0.4286
 31%|███       | 31/100 [06:21<14:41, 12.78s/it] 32%|███▏      | 32/100 [06:32<14:00, 12.36s/it] 33%|███▎      | 33/100 [06:42<13:06, 11.74s/it] 34%|███▍      | 34/100 [06:53<12:44, 11.59s/it] 35%|███▌      | 35/100 [07:12<14:39, 13.53s/it]Epoch 35: Train acc/f1 = 0.8444 / 0.7654 / 0.7157 / 0.9727 
                Val acc/f1/spec/sens = 0.7600 / 0.5671 / 0.6562 / 0.9559
                Test acc/f1/spec/sens = 0.4754 / 0.4762 / 0.5625 / 0.7143
 36%|███▌      | 36/100 [07:23<13:41, 12.83s/it] 37%|███▋      | 37/100 [07:33<12:39, 12.05s/it] 38%|███▊      | 38/100 [07:44<12:10, 11.78s/it] 39%|███▉      | 39/100 [07:54<11:28, 11.29s/it] 40%|████      | 40/100 [08:13<13:33, 13.55s/it]Epoch 40: Train acc/f1 = 0.8689 / 0.8094 / 0.8147 / 0.9472 
                Val acc/f1/spec/sens = 0.7800 / 0.6120 / 0.6250 / 0.9559
                Test acc/f1/spec/sens = 0.5820 / 0.5837 / 0.7250 / 0.7143
 41%|████      | 41/100 [08:23<12:20, 12.55s/it] 42%|████▏     | 42/100 [08:35<11:46, 12.18s/it] 43%|████▎     | 43/100 [08:45<11:03, 11.63s/it] 44%|████▍     | 44/100 [08:56<10:44, 11.51s/it] 45%|████▌     | 45/100 [09:14<12:22, 13.51s/it]Epoch 45: Train acc/f1 = 0.8867 / 0.8324 / 0.8594 / 0.9574 
                Val acc/f1/spec/sens = 0.7600 / 0.6008 / 0.6875 / 0.9118
                Test acc/f1/spec/sens = 0.5820 / 0.5896 / 0.7625 / 0.5714
 46%|████▌     | 46/100 [09:26<11:39, 12.95s/it] 47%|████▋     | 47/100 [09:36<10:45, 12.17s/it] 48%|████▊     | 48/100 [09:48<10:20, 11.93s/it] 49%|████▉     | 49/100 [09:58<09:45, 11.47s/it] 50%|█████     | 50/100 [10:17<11:29, 13.80s/it]Epoch 50: Train acc/f1 = 0.8844 / 0.8292 / 0.8435 / 0.9557 
                Val acc/f1/spec/sens = 0.7700 / 0.6367 / 0.6562 / 0.9118
                Test acc/f1/spec/sens = 0.5738 / 0.5846 / 0.7625 / 0.5238
 51%|█████     | 51/100 [10:28<10:23, 12.73s/it] 52%|█████▏    | 52/100 [10:39<09:49, 12.29s/it] 53%|█████▎    | 53/100 [10:49<09:07, 11.64s/it] 54%|█████▍    | 54/100 [11:00<08:48, 11.50s/it] 55%|█████▌    | 55/100 [11:18<09:58, 13.29s/it]Epoch 55: Train acc/f1 = 0.8878 / 0.8343 / 0.8914 / 0.9404 
                Val acc/f1/spec/sens = 0.7300 / 0.5730 / 0.6562 / 0.8824
                Test acc/f1/spec/sens = 0.5410 / 0.5497 / 0.8000 / 0.4048
 56%|█████▌    | 56/100 [11:29<09:16, 12.66s/it] 57%|█████▋    | 57/100 [11:39<08:31, 11.90s/it] 58%|█████▊    | 58/100 [11:50<08:11, 11.70s/it] 59%|█████▉    | 59/100 [12:00<07:40, 11.22s/it] 60%|██████    | 60/100 [12:19<08:55, 13.39s/it]Epoch 60: Train acc/f1 = 0.8956 / 0.8398 / 0.8850 / 0.9557 
                Val acc/f1/spec/sens = 0.7400 / 0.6012 / 0.6875 / 0.8676
                Test acc/f1/spec/sens = 0.5738 / 0.5836 / 0.8250 / 0.4048
 61%|██████    | 61/100 [12:29<08:04, 12.41s/it] 62%|██████▏   | 62/100 [12:40<07:36, 12.01s/it] 63%|██████▎   | 63/100 [12:50<07:03, 11.44s/it] 64%|██████▍   | 64/100 [13:01<06:50, 11.41s/it] 65%|██████▌   | 65/100 [13:19<07:42, 13.21s/it]Epoch 65: Train acc/f1 = 0.8822 / 0.8279 / 0.8371 / 0.9506 
                Val acc/f1/spec/sens = 0.7400 / 0.5931 / 0.6562 / 0.8824
                Test acc/f1/spec/sens = 0.5656 / 0.5772 / 0.8125 / 0.4286
 66%|██████▌   | 66/100 [13:30<07:08, 12.61s/it] 67%|██████▋   | 67/100 [13:40<06:32, 11.89s/it] 68%|██████▊   | 68/100 [13:51<06:13, 11.67s/it] 69%|██████▉   | 69/100 [14:01<05:47, 11.19s/it] 70%|███████   | 70/100 [14:20<06:41, 13.39s/it]Epoch 70: Train acc/f1 = 0.8889 / 0.8341 / 0.8818 / 0.9472 
                Val acc/f1/spec/sens = 0.7400 / 0.5931 / 0.6562 / 0.8824
                Test acc/f1/spec/sens = 0.5574 / 0.5687 / 0.8125 / 0.4048
 71%|███████   | 71/100 [14:30<06:00, 12.42s/it] 72%|███████▏  | 72/100 [14:41<05:37, 12.04s/it] 73%|███████▎  | 73/100 [14:52<05:10, 11.50s/it] 74%|███████▍  | 74/100 [15:03<04:57, 11.46s/it] 75%|███████▌  | 75/100 [15:22<05:46, 13.85s/it]Epoch 75: Train acc/f1 = 0.8967 / 0.8543 / 0.8914 / 0.9455 
                Val acc/f1/spec/sens = 0.7400 / 0.5931 / 0.6562 / 0.8824
                Test acc/f1/spec/sens = 0.5574 / 0.5687 / 0.8125 / 0.4048
 76%|███████▌  | 76/100 [15:34<05:14, 13.10s/it] 77%|███████▋  | 77/100 [15:44<04:42, 12.28s/it] 78%|███████▊  | 78/100 [15:56<04:27, 12.18s/it] 79%|███████▉  | 79/100 [16:06<04:05, 11.68s/it] 80%|████████  | 80/100 [16:29<04:57, 14.87s/it]Epoch 80: Train acc/f1 = 0.8822 / 0.8279 / 0.8498 / 0.9489 
                Val acc/f1/spec/sens = 0.7400 / 0.5931 / 0.6562 / 0.8824
                Test acc/f1/spec/sens = 0.5574 / 0.5687 / 0.8125 / 0.4048
 81%|████████  | 81/100 [16:39<04:17, 13.53s/it] 82%|████████▏ | 82/100 [16:50<03:51, 12.86s/it] 83%|████████▎ | 83/100 [17:01<03:25, 12.08s/it] 84%|████████▍ | 84/100 [17:12<03:08, 11.81s/it] 85%|████████▌ | 85/100 [17:29<03:22, 13.53s/it]Epoch 85: Train acc/f1 = 0.8944 / 0.8496 / 0.8690 / 0.9506 
                Val acc/f1/spec/sens = 0.7400 / 0.5931 / 0.6562 / 0.8824
                Test acc/f1/spec/sens = 0.5574 / 0.5687 / 0.8125 / 0.4048
 86%|████████▌ | 86/100 [17:41<02:59, 12.84s/it] 87%|████████▋ | 87/100 [17:51<02:36, 12.07s/it] 88%|████████▊ | 88/100 [18:02<02:22, 11.87s/it] 89%|████████▉ | 89/100 [18:13<02:05, 11.39s/it] 90%|█████████ | 90/100 [18:31<02:15, 13.59s/it]Epoch 90: Train acc/f1 = 0.8933 / 0.8377 / 0.8882 / 0.9506 
                Val acc/f1/spec/sens = 0.7300 / 0.5865 / 0.6562 / 0.8676
                Test acc/f1/spec/sens = 0.5574 / 0.5687 / 0.8125 / 0.4048
 91%|█████████ | 91/100 [18:42<01:53, 12.56s/it] 92%|█████████▏| 92/100 [18:53<01:37, 12.17s/it] 93%|█████████▎| 93/100 [19:03<01:21, 11.62s/it] 94%|█████████▍| 94/100 [19:14<01:09, 11.52s/it] 95%|█████████▌| 95/100 [19:32<01:06, 13.33s/it]Epoch 95: Train acc/f1 = 0.8833 / 0.8364 / 0.8562 / 0.9455 
                Val acc/f1/spec/sens = 0.7300 / 0.5865 / 0.6562 / 0.8676
                Test acc/f1/spec/sens = 0.5574 / 0.5687 / 0.8125 / 0.4048
 96%|█████████▌| 96/100 [19:43<00:50, 12.72s/it] 97%|█████████▋| 97/100 [19:53<00:35, 11.96s/it] 98%|█████████▊| 98/100 [20:05<00:23, 11.74s/it] 99%|█████████▉| 99/100 [20:15<00:11, 11.26s/it]100%|██████████| 100/100 [20:33<00:00, 13.43s/it]                                                 Epoch 100: Train acc/f1 = 0.9011 / 0.8509 / 0.8882 / 0.9574 
                Val acc/f1/spec/sens = 0.7300 / 0.5865 / 0.6562 / 0.8676
                Test acc/f1/spec/sens = 0.5574 / 0.5687 / 0.8125 / 0.4048
specificity = 271/313
sensitivity = 559/587
specificity = 21/32
sensitivity = 59/68
specificity = 65/80
sensitivity = 17/42
Trial 3, Cycle 1
Train acc/f1/spec/sens = 0.8889 / 0.8383 / 0.8658 / 0.9523
Val acc/f1/spec/sens = 0.7300 / 0.5865 / 0.6562 / 0.8676
Test acc/f1/spec/sens = 0.5574 / 0.5687 / 0.8125 / 0.4048
>> Finished.
specificity = 65/80
sensitivity = 17/42
Acc, agreement for latest model:  0.5573770491803278 0.5245901639344263
Load best checkpoint for thief model
specificity = 64/80
sensitivity = 18/42
Acc, agreement for best model:  0.48360655737704916 0.5081967213114754
Trial 2/5 || Cycle 1/1 || Label set size 900 || Test acc 0.4836 || Test agreement 0.5082 || Spec 0.8000 || Sens 0.4286
**************************************************************************************************** 

specificity = 64/80
sensitivity = 18/42
Number of samples  900
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
replacing labeled set labels with victim labels
  0%|          | 0/57 [00:00<?, ?it/s]  2%|▏         | 1/57 [00:00<00:43,  1.28it/s]  4%|▎         | 2/57 [00:01<00:27,  2.01it/s]  5%|▌         | 3/57 [00:01<00:21,  2.56it/s]  7%|▋         | 4/57 [00:01<00:18,  2.91it/s]  9%|▉         | 5/57 [00:01<00:16,  3.12it/s] 11%|█         | 6/57 [00:02<00:15,  3.20it/s] 12%|█▏        | 7/57 [00:02<00:15,  3.32it/s] 14%|█▍        | 8/57 [00:02<00:14,  3.49it/s] 16%|█▌        | 9/57 [00:02<00:12,  3.72it/s] 18%|█▊        | 10/57 [00:03<00:12,  3.84it/s] 19%|█▉        | 11/57 [00:03<00:11,  4.10it/s] 21%|██        | 12/57 [00:03<00:10,  4.24it/s] 23%|██▎       | 13/57 [00:03<00:10,  4.21it/s] 25%|██▍       | 14/57 [00:04<00:09,  4.43it/s] 26%|██▋       | 15/57 [00:04<00:09,  4.59it/s] 28%|██▊       | 16/57 [00:04<00:09,  4.42it/s] 30%|██▉       | 17/57 [00:04<00:09,  4.33it/s] 32%|███▏      | 18/57 [00:05<00:09,  4.15it/s] 33%|███▎      | 19/57 [00:05<00:08,  4.29it/s] 35%|███▌      | 20/57 [00:05<00:08,  4.26it/s] 37%|███▋      | 21/57 [00:05<00:08,  4.12it/s] 39%|███▊      | 22/57 [00:05<00:08,  4.32it/s] 40%|████      | 23/57 [00:06<00:07,  4.53it/s] 42%|████▏     | 24/57 [00:06<00:07,  4.70it/s] 44%|████▍     | 25/57 [00:06<00:06,  4.80it/s] 46%|████▌     | 26/57 [00:06<00:06,  4.86it/s] 47%|████▋     | 27/57 [00:06<00:06,  4.89it/s] 49%|████▉     | 28/57 [00:07<00:05,  4.95it/s] 51%|█████     | 29/57 [00:07<00:05,  4.97it/s] 53%|█████▎    | 30/57 [00:07<00:05,  4.89it/s] 54%|█████▍    | 31/57 [00:07<00:05,  4.76it/s] 56%|█████▌    | 32/57 [00:07<00:05,  4.67it/s] 58%|█████▊    | 33/57 [00:08<00:05,  4.69it/s] 60%|█████▉    | 34/57 [00:08<00:04,  4.77it/s] 61%|██████▏   | 35/57 [00:08<00:04,  4.87it/s] 63%|██████▎   | 36/57 [00:08<00:04,  4.63it/s] 65%|██████▍   | 37/57 [00:09<00:04,  4.29it/s] 67%|██████▋   | 38/57 [00:09<00:04,  4.04it/s] 68%|██████▊   | 39/57 [00:09<00:04,  4.02it/s] 70%|███████   | 40/57 [00:09<00:04,  4.09it/s] 72%|███████▏  | 41/57 [00:10<00:03,  4.33it/s] 74%|███████▎  | 42/57 [00:10<00:03,  4.48it/s] 75%|███████▌  | 43/57 [00:10<00:03,  4.36it/s] 77%|███████▋  | 44/57 [00:10<00:03,  4.31it/s] 79%|███████▉  | 45/57 [00:11<00:02,  4.14it/s] 81%|████████  | 46/57 [00:11<00:02,  4.37it/s] 82%|████████▏ | 47/57 [00:11<00:02,  4.55it/s] 84%|████████▍ | 48/57 [00:11<00:01,  4.62it/s] 86%|████████▌ | 49/57 [00:11<00:01,  4.74it/s] 88%|████████▊ | 50/57 [00:12<00:01,  4.83it/s] 89%|████████▉ | 51/57 [00:12<00:01,  4.90it/s] 91%|█████████ | 52/57 [00:12<00:01,  4.99it/s] 93%|█████████▎| 53/57 [00:12<00:00,  5.02it/s] 95%|█████████▍| 54/57 [00:12<00:00,  5.07it/s] 96%|█████████▋| 55/57 [00:12<00:00,  5.09it/s] 98%|█████████▊| 56/57 [00:13<00:00,  5.06it/s]100%|██████████| 57/57 [00:13<00:00,  4.25it/s]
replacing val labels with victim labels
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:00<00:04,  1.25it/s] 29%|██▊       | 2/7 [00:01<00:02,  2.03it/s] 43%|████▎     | 3/7 [00:01<00:01,  2.54it/s] 57%|█████▋    | 4/7 [00:01<00:01,  2.96it/s] 71%|███████▏  | 5/7 [00:01<00:00,  3.29it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.52it/s]100%|██████████| 7/7 [00:02<00:00,  4.47it/s]100%|██████████| 7/7 [00:02<00:00,  2.99it/s]Validation set distribution: 
Number of samples  100

{0: 19, 1: 24, 2: 57}
Labeled set distribution: 
Number of samples  900
{0: 114, 1: 210, 2: 576}
odict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias', 'heads.head.weight', 'heads.head.bias'])
thief state:  None
pretrained state:  dict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias'])
Thief model initialized successfully
specificity = 80/80
sensitivity = 0/42
Initial model on target dataset: acc = 0.2541, agreement = 0.2377, f1 = 0.1351, spec = 1.0000, sens = 0.0000
specificity = 43/43
sensitivity = 0/57
Initial model on validation dataset: acc = 0.1900, agreement = 0.1900, f1 = 0.1064, spec = 1.0000, sens = 0.0000
la:  None
>> Train a Model.
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:10<16:42, 10.13s/it]  2%|▏         | 2/100 [00:21<18:00, 11.03s/it]  3%|▎         | 3/100 [00:31<17:10, 10.62s/it]  4%|▍         | 4/100 [00:43<17:17, 10.80s/it]  5%|▌         | 5/100 [01:00<20:58, 13.24s/it]Epoch 5: Train acc/f1 = 0.6644 / 0.3833 / 0.1975 / 0.9653 
                Val acc/f1/spec/sens = 0.5700 / 0.2420 / 0.0000 / 1.0000
                Test acc/f1/spec/sens = 0.3525 / 0.1941 / 0.0375 / 1.0000
  6%|▌         | 6/100 [01:12<20:03, 12.80s/it]  7%|▋         | 7/100 [01:22<18:28, 11.92s/it]  8%|▊         | 8/100 [01:34<18:16, 11.92s/it]  9%|▉         | 9/100 [01:44<17:13, 11.36s/it] 10%|█         | 10/100 [02:03<20:18, 13.54s/it]Epoch 10: Train acc/f1 = 0.6933 / 0.4403 / 0.4660 / 0.9201 
                Val acc/f1/spec/sens = 0.6200 / 0.3682 / 0.3256 / 0.9825
                Test acc/f1/spec/sens = 0.3852 / 0.2608 / 0.2625 / 0.9286
 11%|█         | 11/100 [02:13<18:32, 12.50s/it] 12%|█▏        | 12/100 [02:24<17:42, 12.08s/it] 13%|█▎        | 13/100 [02:34<16:39, 11.49s/it] 14%|█▍        | 14/100 [02:45<16:21, 11.41s/it] 15%|█▌        | 15/100 [03:03<18:41, 13.20s/it]Epoch 15: Train acc/f1 = 0.7167 / 0.5470 / 0.4228 / 0.9549 
                Val acc/f1/spec/sens = 0.6400 / 0.4833 / 0.3256 / 0.9474
                Test acc/f1/spec/sens = 0.4180 / 0.3323 / 0.2000 / 0.9762
 16%|█▌        | 16/100 [03:14<17:35, 12.56s/it] 17%|█▋        | 17/100 [03:24<16:21, 11.83s/it] 18%|█▊        | 18/100 [03:36<16:10, 11.84s/it] 19%|█▉        | 19/100 [03:46<15:17, 11.33s/it] 20%|██        | 20/100 [04:05<18:08, 13.60s/it]Epoch 20: Train acc/f1 = 0.7078 / 0.5889 / 0.7160 / 0.8472 
                Val acc/f1/spec/sens = 0.7000 / 0.6210 / 0.7907 / 0.8070
                Test acc/f1/spec/sens = 0.4918 / 0.4702 / 0.8625 / 0.5476
 21%|██        | 21/100 [04:15<16:33, 12.58s/it] 22%|██▏       | 22/100 [04:27<16:06, 12.39s/it] 23%|██▎       | 23/100 [04:37<15:02, 11.72s/it] 24%|██▍       | 24/100 [04:48<14:42, 11.61s/it] 25%|██▌       | 25/100 [05:06<16:40, 13.34s/it]Epoch 25: Train acc/f1 = 0.8000 / 0.7215 / 0.8086 / 0.8872 
                Val acc/f1/spec/sens = 0.6700 / 0.5713 / 0.6744 / 0.8596
                Test acc/f1/spec/sens = 0.5492 / 0.5525 / 0.8125 / 0.6190
 26%|██▌       | 26/100 [05:17<15:39, 12.70s/it] 27%|██▋       | 27/100 [05:27<14:32, 11.95s/it] 28%|██▊       | 28/100 [05:38<14:02, 11.71s/it] 29%|██▉       | 29/100 [05:48<13:17, 11.24s/it] 30%|███       | 30/100 [06:06<15:24, 13.21s/it]Epoch 30: Train acc/f1 = 0.8333 / 0.7566 / 0.7654 / 0.9479 
                Val acc/f1/spec/sens = 0.7400 / 0.6554 / 0.6744 / 0.9123
                Test acc/f1/spec/sens = 0.5000 / 0.4931 / 0.6750 / 0.6429
 31%|███       | 31/100 [06:16<14:08, 12.29s/it] 32%|███▏      | 32/100 [06:28<13:34, 11.97s/it] 33%|███▎      | 33/100 [06:38<12:46, 11.44s/it] 34%|███▍      | 34/100 [06:50<12:46, 11.61s/it] 35%|███▌      | 35/100 [07:07<14:26, 13.34s/it]Epoch 35: Train acc/f1 = 0.8433 / 0.7704 / 0.7438 / 0.9583 
                Val acc/f1/spec/sens = 0.7400 / 0.6729 / 0.6977 / 0.8947
                Test acc/f1/spec/sens = 0.5246 / 0.5170 / 0.6500 / 0.7143
 36%|███▌      | 36/100 [07:18<13:30, 12.67s/it] 37%|███▋      | 37/100 [07:28<12:29, 11.89s/it] 38%|███▊      | 38/100 [07:39<12:02, 11.65s/it] 39%|███▉      | 39/100 [07:50<11:22, 11.19s/it] 40%|████      | 40/100 [08:08<13:24, 13.40s/it]Epoch 40: Train acc/f1 = 0.8467 / 0.7895 / 0.8457 / 0.9149 
                Val acc/f1/spec/sens = 0.7100 / 0.6696 / 0.7907 / 0.7895
                Test acc/f1/spec/sens = 0.5164 / 0.5077 / 0.8250 / 0.4762
 41%|████      | 41/100 [08:18<12:13, 12.44s/it] 42%|████▏     | 42/100 [08:30<11:51, 12.26s/it] 43%|████▎     | 43/100 [08:40<11:03, 11.63s/it] 44%|████▍     | 44/100 [08:51<10:43, 11.49s/it] 45%|████▌     | 45/100 [09:09<12:10, 13.27s/it]Epoch 45: Train acc/f1 = 0.8689 / 0.8183 / 0.8457 / 0.9340 
                Val acc/f1/spec/sens = 0.7300 / 0.6830 / 0.6744 / 0.8596
                Test acc/f1/spec/sens = 0.5492 / 0.5395 / 0.8250 / 0.5476
 46%|████▌     | 46/100 [09:21<11:41, 12.99s/it] 47%|████▋     | 47/100 [09:32<10:45, 12.18s/it] 48%|████▊     | 48/100 [09:43<10:20, 11.94s/it] 49%|████▉     | 49/100 [09:53<09:42, 11.42s/it] 50%|█████     | 50/100 [10:13<11:44, 14.08s/it]Epoch 50: Train acc/f1 = 0.8711 / 0.8158 / 0.8179 / 0.9583 
                Val acc/f1/spec/sens = 0.7400 / 0.6909 / 0.7442 / 0.8596
                Test acc/f1/spec/sens = 0.5328 / 0.5221 / 0.8000 / 0.5476
 51%|█████     | 51/100 [10:24<10:36, 12.99s/it] 52%|█████▏    | 52/100 [10:35<09:57, 12.44s/it] 53%|█████▎    | 53/100 [10:45<09:11, 11.74s/it] 54%|█████▍    | 54/100 [10:56<08:52, 11.57s/it] 55%|█████▌    | 55/100 [11:14<10:01, 13.36s/it]Epoch 55: Train acc/f1 = 0.8689 / 0.8209 / 0.8364 / 0.9427 
                Val acc/f1/spec/sens = 0.7400 / 0.6902 / 0.7907 / 0.8421
                Test acc/f1/spec/sens = 0.5574 / 0.5426 / 0.8250 / 0.5476
 56%|█████▌    | 56/100 [11:25<09:19, 12.72s/it] 57%|█████▋    | 57/100 [11:35<08:36, 12.00s/it] 58%|█████▊    | 58/100 [11:47<08:14, 11.78s/it] 59%|█████▉    | 59/100 [11:57<07:42, 11.28s/it] 60%|██████    | 60/100 [12:16<09:01, 13.53s/it]Epoch 60: Train acc/f1 = 0.8700 / 0.8140 / 0.8735 / 0.9323 
                Val acc/f1/spec/sens = 0.7400 / 0.6941 / 0.7674 / 0.8421
                Test acc/f1/spec/sens = 0.5492 / 0.5360 / 0.8250 / 0.5714
 61%|██████    | 61/100 [12:26<08:08, 12.52s/it] 62%|██████▏   | 62/100 [12:37<07:41, 12.14s/it] 63%|██████▎   | 63/100 [12:47<07:08, 11.59s/it] 64%|██████▍   | 64/100 [12:59<06:53, 11.49s/it] 65%|██████▌   | 65/100 [13:16<07:48, 13.38s/it]Epoch 65: Train acc/f1 = 0.8822 / 0.8389 / 0.8580 / 0.9462 
                Val acc/f1/spec/sens = 0.7400 / 0.6915 / 0.7674 / 0.8421
                Test acc/f1/spec/sens = 0.5574 / 0.5472 / 0.8250 / 0.5714
 66%|██████▌   | 66/100 [13:28<07:13, 12.75s/it] 67%|██████▋   | 67/100 [13:38<06:35, 11.98s/it] 68%|██████▊   | 68/100 [13:49<06:15, 11.74s/it] 69%|██████▉   | 69/100 [13:59<05:49, 11.29s/it] 70%|███████   | 70/100 [14:18<06:48, 13.62s/it]Epoch 70: Train acc/f1 = 0.8911 / 0.8512 / 0.8642 / 0.9462 
                Val acc/f1/spec/sens = 0.7400 / 0.6941 / 0.7674 / 0.8421
                Test acc/f1/spec/sens = 0.5574 / 0.5472 / 0.8250 / 0.5714
 71%|███████   | 71/100 [14:28<06:05, 12.60s/it] 72%|███████▏  | 72/100 [14:40<05:41, 12.18s/it] 73%|███████▎  | 73/100 [14:50<05:12, 11.59s/it] 74%|███████▍  | 74/100 [15:01<04:59, 11.50s/it] 75%|███████▌  | 75/100 [15:21<05:47, 13.92s/it]Epoch 75: Train acc/f1 = 0.8856 / 0.8453 / 0.8735 / 0.9392 
                Val acc/f1/spec/sens = 0.7400 / 0.6941 / 0.7674 / 0.8421
                Test acc/f1/spec/sens = 0.5492 / 0.5403 / 0.8125 / 0.5714
 76%|███████▌  | 76/100 [15:33<05:22, 13.42s/it] 77%|███████▋  | 77/100 [15:43<04:48, 12.54s/it] 78%|███████▊  | 78/100 [15:55<04:27, 12.16s/it] 79%|███████▉  | 79/100 [16:05<04:03, 11.58s/it] 80%|████████  | 80/100 [16:23<04:32, 13.63s/it]Epoch 80: Train acc/f1 = 0.8800 / 0.8308 / 0.8519 / 0.9497 
                Val acc/f1/spec/sens = 0.7400 / 0.6941 / 0.7674 / 0.8421
                Test acc/f1/spec/sens = 0.5492 / 0.5403 / 0.8125 / 0.5714
 81%|████████  | 81/100 [16:33<03:59, 12.58s/it] 82%|████████▏ | 82/100 [16:45<03:38, 12.15s/it] 83%|████████▎ | 83/100 [16:55<03:16, 11.54s/it] 84%|████████▍ | 84/100 [17:06<03:02, 11.43s/it] 85%|████████▌ | 85/100 [17:23<03:18, 13.22s/it]Epoch 85: Train acc/f1 = 0.8811 / 0.8331 / 0.8519 / 0.9479 
                Val acc/f1/spec/sens = 0.7400 / 0.6915 / 0.7674 / 0.8421
                Test acc/f1/spec/sens = 0.5492 / 0.5403 / 0.8125 / 0.5714
 86%|████████▌ | 86/100 [17:35<02:56, 12.62s/it] 87%|████████▋ | 87/100 [17:45<02:34, 11.90s/it] 88%|████████▊ | 88/100 [17:56<02:20, 11.68s/it] 89%|████████▉ | 89/100 [18:06<02:03, 11.22s/it] 90%|█████████ | 90/100 [18:24<02:13, 13.37s/it]Epoch 90: Train acc/f1 = 0.8733 / 0.8206 / 0.8488 / 0.9410 
                Val acc/f1/spec/sens = 0.7400 / 0.6915 / 0.7674 / 0.8421
                Test acc/f1/spec/sens = 0.5574 / 0.5472 / 0.8250 / 0.5714
 91%|█████████ | 91/100 [18:35<01:51, 12.40s/it] 92%|█████████▏| 92/100 [18:46<01:36, 12.05s/it] 93%|█████████▎| 93/100 [18:56<01:20, 11.52s/it] 94%|█████████▍| 94/100 [19:07<01:08, 11.44s/it] 95%|█████████▌| 95/100 [19:25<01:06, 13.25s/it]Epoch 95: Train acc/f1 = 0.8856 / 0.8432 / 0.8735 / 0.9410 
                Val acc/f1/spec/sens = 0.7400 / 0.6915 / 0.7674 / 0.8421
                Test acc/f1/spec/sens = 0.5492 / 0.5403 / 0.8125 / 0.5714
 96%|█████████▌| 96/100 [19:36<00:50, 12.68s/it] 97%|█████████▋| 97/100 [19:46<00:35, 11.92s/it] 98%|█████████▊| 98/100 [19:58<00:23, 11.70s/it] 99%|█████████▉| 99/100 [20:08<00:11, 11.22s/it]100%|██████████| 100/100 [20:26<00:00, 13.46s/it]                                                 Epoch 100: Train acc/f1 = 0.8744 / 0.8318 / 0.8333 / 0.9375 
                Val acc/f1/spec/sens = 0.7400 / 0.6941 / 0.7674 / 0.8421
                Test acc/f1/spec/sens = 0.5492 / 0.5403 / 0.8125 / 0.5714
specificity = 272/324
sensitivity = 547/576
specificity = 33/43
sensitivity = 48/57
specificity = 65/80
sensitivity = 24/42
Trial 4, Cycle 1
Train acc/f1/spec/sens = 0.8756 / 0.8270 / 0.8395 / 0.9497
Val acc/f1/spec/sens = 0.7400 / 0.6941 / 0.7674 / 0.8421
Test acc/f1/spec/sens = 0.5492 / 0.5403 / 0.8125 / 0.5714
>> Finished.
specificity = 65/80
sensitivity = 24/42
Acc, agreement for latest model:  0.5491803278688525 0.5327868852459017
Load best checkpoint for thief model
specificity = 64/80
sensitivity = 24/42
Acc, agreement for best model:  0.5409836065573771 0.5409836065573771
Trial 3/5 || Cycle 1/1 || Label set size 900 || Test acc 0.5410 || Test agreement 0.5410 || Spec 0.8000 || Sens 0.5714
**************************************************************************************************** 

specificity = 64/80
sensitivity = 24/42
Number of samples  900
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
/home/deepankar/scratch/MSA_Medical/all_names.pkl
Num of videos 64 frames 15800
replacing labeled set labels with victim labels
  0%|          | 0/57 [00:00<?, ?it/s]  2%|▏         | 1/57 [00:00<00:47,  1.19it/s]  4%|▎         | 2/57 [00:01<00:28,  1.95it/s]  5%|▌         | 3/57 [00:01<00:21,  2.47it/s]  7%|▋         | 4/57 [00:01<00:18,  2.82it/s]  9%|▉         | 5/57 [00:01<00:15,  3.33it/s] 11%|█         | 6/57 [00:02<00:13,  3.68it/s] 12%|█▏        | 7/57 [00:02<00:12,  4.03it/s] 14%|█▍        | 8/57 [00:02<00:11,  4.34it/s] 16%|█▌        | 9/57 [00:02<00:10,  4.54it/s] 18%|█▊        | 10/57 [00:02<00:10,  4.42it/s] 19%|█▉        | 11/57 [00:03<00:10,  4.60it/s] 21%|██        | 12/57 [00:03<00:09,  4.75it/s] 23%|██▎       | 13/57 [00:03<00:09,  4.79it/s] 25%|██▍       | 14/57 [00:03<00:08,  4.88it/s] 26%|██▋       | 15/57 [00:03<00:08,  4.93it/s] 28%|██▊       | 16/57 [00:04<00:08,  4.97it/s] 30%|██▉       | 17/57 [00:04<00:08,  4.99it/s] 32%|███▏      | 18/57 [00:04<00:07,  5.05it/s] 33%|███▎      | 19/57 [00:04<00:07,  5.06it/s] 35%|███▌      | 20/57 [00:04<00:07,  5.02it/s] 37%|███▋      | 21/57 [00:05<00:07,  5.06it/s] 39%|███▊      | 22/57 [00:05<00:06,  5.03it/s] 40%|████      | 23/57 [00:05<00:06,  5.00it/s] 42%|████▏     | 24/57 [00:05<00:06,  4.98it/s] 44%|████▍     | 25/57 [00:05<00:06,  5.02it/s] 46%|████▌     | 26/57 [00:06<00:06,  5.09it/s] 47%|████▋     | 27/57 [00:06<00:05,  5.10it/s] 49%|████▉     | 28/57 [00:06<00:05,  5.12it/s] 51%|█████     | 29/57 [00:06<00:05,  5.12it/s] 53%|█████▎    | 30/57 [00:06<00:05,  5.14it/s] 54%|█████▍    | 31/57 [00:07<00:05,  5.11it/s] 56%|█████▌    | 32/57 [00:07<00:04,  5.13it/s] 58%|█████▊    | 33/57 [00:07<00:04,  5.13it/s] 60%|█████▉    | 34/57 [00:07<00:04,  5.13it/s] 61%|██████▏   | 35/57 [00:07<00:04,  5.04it/s] 63%|██████▎   | 36/57 [00:08<00:04,  5.07it/s] 65%|██████▍   | 37/57 [00:08<00:03,  5.09it/s] 67%|██████▋   | 38/57 [00:08<00:03,  5.10it/s] 68%|██████▊   | 39/57 [00:08<00:03,  5.12it/s] 70%|███████   | 40/57 [00:08<00:03,  5.09it/s] 72%|███████▏  | 41/57 [00:09<00:03,  4.92it/s] 74%|███████▎  | 42/57 [00:09<00:03,  4.88it/s] 75%|███████▌  | 43/57 [00:09<00:02,  4.97it/s] 77%|███████▋  | 44/57 [00:09<00:02,  5.02it/s] 79%|███████▉  | 45/57 [00:09<00:02,  4.99it/s] 81%|████████  | 46/57 [00:10<00:02,  4.83it/s] 82%|████████▏ | 47/57 [00:10<00:02,  4.74it/s] 84%|████████▍ | 48/57 [00:10<00:01,  4.83it/s] 86%|████████▌ | 49/57 [00:10<00:01,  4.85it/s] 88%|████████▊ | 50/57 [00:10<00:01,  4.96it/s] 89%|████████▉ | 51/57 [00:11<00:01,  4.93it/s] 91%|█████████ | 52/57 [00:11<00:01,  4.95it/s] 93%|█████████▎| 53/57 [00:11<00:00,  5.02it/s] 95%|█████████▍| 54/57 [00:11<00:00,  5.04it/s] 96%|█████████▋| 55/57 [00:11<00:00,  5.00it/s] 98%|█████████▊| 56/57 [00:12<00:00,  5.02it/s]100%|██████████| 57/57 [00:12<00:00,  4.65it/s]
replacing val labels with victim labels
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:00<00:04,  1.28it/s] 29%|██▊       | 2/7 [00:01<00:02,  2.08it/s] 43%|████▎     | 3/7 [00:01<00:01,  2.58it/s] 57%|█████▋    | 4/7 [00:01<00:01,  2.93it/s] 71%|███████▏  | 5/7 [00:01<00:00,  3.17it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.39it/s]100%|██████████| 7/7 [00:02<00:00,  2.99it/s]Validation set distribution: 
Number of samples  100

{0: 11, 1: 20, 2: 69}
Labeled set distribution: 
Number of samples  900
{0: 101, 1: 218, 2: 581}
odict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias', 'heads.head.weight', 'heads.head.bias'])
thief state:  None
pretrained state:  dict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias'])
Thief model initialized successfully
specificity = 80/80
sensitivity = 0/42
Initial model on target dataset: acc = 0.2541, agreement = 0.2377, f1 = 0.1351, spec = 1.0000, sens = 0.0000
specificity = 31/31
sensitivity = 0/69
Initial model on validation dataset: acc = 0.1100, agreement = 0.1100, f1 = 0.0661, spec = 1.0000, sens = 0.0000
la:  None
>> Train a Model.
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:10<16:33, 10.04s/it]  2%|▏         | 2/100 [00:21<18:00, 11.02s/it]  3%|▎         | 3/100 [00:31<17:11, 10.63s/it]  4%|▍         | 4/100 [00:43<17:52, 11.18s/it]  5%|▌         | 5/100 [01:01<21:14, 13.41s/it]Epoch 5: Train acc/f1 = 0.7022 / 0.4531 / 0.3480 / 0.9501 
                Val acc/f1/spec/sens = 0.7800 / 0.6187 / 0.5161 / 0.9420
                Test acc/f1/spec/sens = 0.3525 / 0.1954 / 0.0250 / 0.9762
  6%|▌         | 6/100 [01:12<19:46, 12.63s/it]  7%|▋         | 7/100 [01:22<18:17, 11.80s/it]  8%|▊         | 8/100 [01:33<17:44, 11.57s/it]  9%|▉         | 9/100 [01:43<16:50, 11.10s/it] 10%|█         | 10/100 [02:01<19:50, 13.23s/it]Epoch 10: Train acc/f1 = 0.7378 / 0.4999 / 0.4013 / 0.9639 
                Val acc/f1/spec/sens = 0.7600 / 0.5167 / 0.4194 / 0.9855
                Test acc/f1/spec/sens = 0.3607 / 0.2098 / 0.0750 / 0.9762
 11%|█         | 11/100 [02:11<18:14, 12.30s/it] 12%|█▏        | 12/100 [02:23<17:49, 12.15s/it] 13%|█▎        | 13/100 [02:33<16:43, 11.53s/it] 14%|█▍        | 14/100 [02:44<16:19, 11.39s/it] 15%|█▌        | 15/100 [03:01<18:27, 13.03s/it]Epoch 15: Train acc/f1 = 0.7400 / 0.5852 / 0.4295 / 0.9656 
                Val acc/f1/spec/sens = 0.8100 / 0.5930 / 0.7097 / 0.9275
                Test acc/f1/spec/sens = 0.4016 / 0.2959 / 0.1375 / 1.0000
 16%|█▌        | 16/100 [03:13<17:46, 12.70s/it] 17%|█▋        | 17/100 [03:23<16:28, 11.91s/it] 18%|█▊        | 18/100 [03:35<16:18, 11.94s/it] 19%|█▉        | 19/100 [03:45<15:23, 11.40s/it] 20%|██        | 20/100 [04:04<18:15, 13.70s/it]Epoch 20: Train acc/f1 = 0.7622 / 0.6648 / 0.6458 / 0.8985 
                Val acc/f1/spec/sens = 0.8100 / 0.6876 / 0.7419 / 0.9275
                Test acc/f1/spec/sens = 0.4426 / 0.4049 / 0.4500 / 0.7619
 21%|██        | 21/100 [04:15<16:38, 12.64s/it] 22%|██▏       | 22/100 [04:26<16:07, 12.41s/it] 23%|██▎       | 23/100 [04:36<15:01, 11.71s/it] 24%|██▍       | 24/100 [04:49<15:05, 11.92s/it] 25%|██▌       | 25/100 [05:07<17:06, 13.69s/it]Epoch 25: Train acc/f1 = 0.8289 / 0.7506 / 0.8056 / 0.9122 
                Val acc/f1/spec/sens = 0.8700 / 0.7840 / 0.8387 / 0.9420
                Test acc/f1/spec/sens = 0.4918 / 0.4693 / 0.5375 / 0.8095
 26%|██▌       | 26/100 [05:18<15:54, 12.89s/it] 27%|██▋       | 27/100 [05:28<14:41, 12.08s/it] 28%|██▊       | 28/100 [05:39<14:08, 11.78s/it] 29%|██▉       | 29/100 [05:49<13:20, 11.27s/it] 30%|███       | 30/100 [06:09<16:03, 13.76s/it]Epoch 30: Train acc/f1 = 0.8544 / 0.7856 / 0.8245 / 0.9312 
                Val acc/f1/spec/sens = 0.8800 / 0.8100 / 0.8710 / 0.9275
                Test acc/f1/spec/sens = 0.5164 / 0.4866 / 0.5375 / 0.9048
 31%|███       | 31/100 [06:19<14:35, 12.69s/it] 32%|███▏      | 32/100 [06:30<13:52, 12.24s/it] 33%|███▎      | 33/100 [06:40<12:57, 11.61s/it] 34%|███▍      | 34/100 [06:51<12:37, 11.48s/it] 35%|███▌      | 35/100 [07:08<14:15, 13.16s/it]Epoch 35: Train acc/f1 = 0.8767 / 0.8213 / 0.8276 / 0.9535 
                Val acc/f1/spec/sens = 0.8700 / 0.8052 / 0.8710 / 0.9130
                Test acc/f1/spec/sens = 0.5246 / 0.5053 / 0.5625 / 0.8333
 36%|███▌      | 36/100 [07:20<13:38, 12.79s/it] 37%|███▋      | 37/100 [07:30<12:34, 11.97s/it] 38%|███▊      | 38/100 [07:42<12:07, 11.73s/it] 39%|███▉      | 39/100 [07:52<11:27, 11.26s/it] 40%|████      | 40/100 [08:10<13:20, 13.35s/it]Epoch 40: Train acc/f1 = 0.8589 / 0.8019 / 0.7680 / 0.9518 
                Val acc/f1/spec/sens = 0.8600 / 0.7607 / 0.8065 / 0.9565
                Test acc/f1/spec/sens = 0.5410 / 0.5150 / 0.5250 / 0.9286
 41%|████      | 41/100 [08:20<12:11, 12.40s/it] 42%|████▏     | 42/100 [08:31<11:38, 12.04s/it] 43%|████▎     | 43/100 [08:42<10:54, 11.47s/it] 44%|████▍     | 44/100 [08:53<10:38, 11.40s/it] 45%|████▌     | 45/100 [09:11<12:15, 13.38s/it]Epoch 45: Train acc/f1 = 0.8844 / 0.8446 / 0.8809 / 0.9312 
                Val acc/f1/spec/sens = 0.8500 / 0.7514 / 0.8065 / 0.9420
                Test acc/f1/spec/sens = 0.5246 / 0.5057 / 0.6125 / 0.8571
 46%|████▌     | 46/100 [09:22<11:31, 12.81s/it] 47%|████▋     | 47/100 [09:33<10:38, 12.05s/it] 48%|████▊     | 48/100 [09:44<10:18, 11.89s/it] 49%|████▉     | 49/100 [09:54<09:42, 11.43s/it] 50%|█████     | 50/100 [10:14<11:36, 13.93s/it]Epoch 50: Train acc/f1 = 0.8800 / 0.8287 / 0.8589 / 0.9380 
                Val acc/f1/spec/sens = 0.8600 / 0.7658 / 0.8387 / 0.9420
                Test acc/f1/spec/sens = 0.5410 / 0.5218 / 0.6250 / 0.8571
 51%|█████     | 51/100 [10:24<10:29, 12.84s/it] 52%|█████▏    | 52/100 [10:36<09:54, 12.39s/it] 53%|█████▎    | 53/100 [10:46<09:12, 11.75s/it] 54%|█████▍    | 54/100 [10:57<08:53, 11.60s/it] 55%|█████▌    | 55/100 [11:15<10:04, 13.44s/it]Epoch 55: Train acc/f1 = 0.9011 / 0.8685 / 0.8683 / 0.9432 
                Val acc/f1/spec/sens = 0.8500 / 0.7455 / 0.8387 / 0.9420
                Test acc/f1/spec/sens = 0.5410 / 0.5222 / 0.6000 / 0.8810
 56%|█████▌    | 56/100 [11:26<09:24, 12.82s/it] 57%|█████▋    | 57/100 [11:37<08:37, 12.04s/it] 58%|█████▊    | 58/100 [11:48<08:15, 11.79s/it] 59%|█████▉    | 59/100 [11:58<07:42, 11.29s/it] 60%|██████    | 60/100 [12:16<08:57, 13.44s/it]Epoch 60: Train acc/f1 = 0.8767 / 0.8335 / 0.8652 / 0.9277 
                Val acc/f1/spec/sens = 0.8600 / 0.7562 / 0.8387 / 0.9565
                Test acc/f1/spec/sens = 0.5492 / 0.5314 / 0.6125 / 0.8571
 61%|██████    | 61/100 [12:27<08:05, 12.46s/it] 62%|██████▏   | 62/100 [12:38<07:39, 12.09s/it] 63%|██████▎   | 63/100 [12:48<07:05, 11.50s/it] 64%|██████▍   | 64/100 [12:59<06:51, 11.44s/it] 65%|██████▌   | 65/100 [13:16<07:40, 13.17s/it]Epoch 65: Train acc/f1 = 0.8878 / 0.8442 / 0.8746 / 0.9380 
                Val acc/f1/spec/sens = 0.8600 / 0.7562 / 0.8387 / 0.9565
                Test acc/f1/spec/sens = 0.5574 / 0.5373 / 0.6125 / 0.8810
 66%|██████▌   | 66/100 [13:28<07:07, 12.58s/it] 67%|██████▋   | 67/100 [13:38<06:32, 11.90s/it] 68%|██████▊   | 68/100 [13:49<06:14, 11.72s/it] 69%|██████▉   | 69/100 [13:59<05:48, 11.25s/it] 70%|███████   | 70/100 [14:18<06:43, 13.44s/it]Epoch 70: Train acc/f1 = 0.8789 / 0.8373 / 0.8401 / 0.9363 
                Val acc/f1/spec/sens = 0.8500 / 0.7455 / 0.8387 / 0.9420
                Test acc/f1/spec/sens = 0.5574 / 0.5373 / 0.6125 / 0.8810
 71%|███████   | 71/100 [14:28<06:01, 12.46s/it] 72%|███████▏  | 72/100 [14:39<05:38, 12.11s/it] 73%|███████▎  | 73/100 [14:50<05:12, 11.56s/it] 74%|███████▍  | 74/100 [15:01<04:57, 11.44s/it] 75%|███████▌  | 75/100 [15:18<05:31, 13.26s/it]Epoch 75: Train acc/f1 = 0.9000 / 0.8539 / 0.8934 / 0.9518 
                Val acc/f1/spec/sens = 0.8600 / 0.7562 / 0.8387 / 0.9565
                Test acc/f1/spec/sens = 0.5492 / 0.5288 / 0.6000 / 0.8810
 76%|███████▌  | 76/100 [15:30<05:03, 12.64s/it] 77%|███████▋  | 77/100 [15:40<04:34, 11.92s/it] 78%|███████▊  | 78/100 [15:51<04:17, 11.70s/it] 79%|███████▉  | 79/100 [16:01<03:56, 11.26s/it] 80%|████████  | 80/100 [16:20<04:29, 13.46s/it]Epoch 80: Train acc/f1 = 0.8811 / 0.8319 / 0.8558 / 0.9398 
                Val acc/f1/spec/sens = 0.8500 / 0.7455 / 0.8387 / 0.9420
                Test acc/f1/spec/sens = 0.5492 / 0.5314 / 0.6125 / 0.8571
 81%|████████  | 81/100 [16:30<03:57, 12.48s/it] 82%|████████▏ | 82/100 [16:41<03:37, 12.11s/it] 83%|████████▎ | 83/100 [16:51<03:16, 11.55s/it] 84%|████████▍ | 84/100 [17:03<03:03, 11.46s/it] 85%|████████▌ | 85/100 [17:20<03:17, 13.18s/it]Epoch 85: Train acc/f1 = 0.8756 / 0.8335 / 0.8809 / 0.9191 
                Val acc/f1/spec/sens = 0.8500 / 0.7455 / 0.8387 / 0.9420
                Test acc/f1/spec/sens = 0.5492 / 0.5314 / 0.6125 / 0.8571
 86%|████████▌ | 86/100 [17:31<02:56, 12.59s/it] 87%|████████▋ | 87/100 [17:41<02:34, 11.89s/it] 88%|████████▊ | 88/100 [17:53<02:20, 11.71s/it] 89%|████████▉ | 89/100 [18:03<02:03, 11.23s/it] 90%|█████████ | 90/100 [18:21<02:14, 13.44s/it]Epoch 90: Train acc/f1 = 0.9067 / 0.8589 / 0.8934 / 0.9621 
                Val acc/f1/spec/sens = 0.8500 / 0.7455 / 0.8387 / 0.9420
                Test acc/f1/spec/sens = 0.5410 / 0.5231 / 0.6000 / 0.8571
 91%|█████████ | 91/100 [18:32<01:52, 12.47s/it] 92%|█████████▏| 92/100 [18:43<01:36, 12.07s/it] 93%|█████████▎| 93/100 [18:53<01:20, 11.52s/it] 94%|█████████▍| 94/100 [19:04<01:08, 11.44s/it] 95%|█████████▌| 95/100 [19:22<01:06, 13.30s/it]Epoch 95: Train acc/f1 = 0.8867 / 0.8458 / 0.8558 / 0.9449 
                Val acc/f1/spec/sens = 0.8500 / 0.7455 / 0.8387 / 0.9420
                Test acc/f1/spec/sens = 0.5410 / 0.5231 / 0.6000 / 0.8571
 96%|█████████▌| 96/100 [19:33<00:50, 12.66s/it] 97%|█████████▋| 97/100 [19:43<00:35, 11.91s/it] 98%|█████████▊| 98/100 [19:55<00:23, 11.76s/it] 99%|█████████▉| 99/100 [20:05<00:11, 11.34s/it]100%|██████████| 100/100 [20:23<00:00, 13.49s/it]                                                 Epoch 100: Train acc/f1 = 0.8856 / 0.8359 / 0.8903 / 0.9329 
                Val acc/f1/spec/sens = 0.8500 / 0.7455 / 0.8387 / 0.9420
                Test acc/f1/spec/sens = 0.5410 / 0.5231 / 0.6000 / 0.8571
specificity = 276/319
sensitivity = 550/581
specificity = 26/31
sensitivity = 65/69
specificity = 48/80
sensitivity = 36/42
Trial 5, Cycle 1
Train acc/f1/spec/sens = 0.8911 / 0.8451 / 0.8652 / 0.9466
Val acc/f1/spec/sens = 0.8500 / 0.7455 / 0.8387 / 0.9420
Test acc/f1/spec/sens = 0.5410 / 0.5231 / 0.6000 / 0.8571
>> Finished.
specificity = 48/80
sensitivity = 36/42
Acc, agreement for latest model:  0.5409836065573771 0.5655737704918032
Load best checkpoint for thief model
specificity = 49/80
sensitivity = 32/42
Acc, agreement for best model:  0.5163934426229508 0.5655737704918032
Trial 4/5 || Cycle 1/1 || Label set size 900 || Test acc 0.5164 || Test agreement 0.5656 || Spec 0.6125 || Sens 0.7619
**************************************************************************************************** 

specificity = 49/80
sensitivity = 32/42
Number of samples  900
0.5344262295081967 0.02612684827952331
        acc       agr    spec      sens                label dist
0  0.532787  0.557377  0.8000  0.523810  {0: 111, 1: 200, 2: 589}
1  0.434426  0.500000  0.6750  0.428571  {0: 102, 1: 220, 2: 578}
2  0.483607  0.508197  0.8000  0.428571   {0: 98, 1: 215, 2: 587}
3  0.540984  0.540984  0.8000  0.571429  {0: 114, 1: 210, 2: 576}
4  0.516393  0.565574  0.6125  0.761905  {0: 101, 1: 218, 2: 581}
Results saved to  /home/deepankar/scratch/MSA_Medical/results_1k/gbusg_radformer/GBUSV_vit/SGD/1000_val100/random_v1_transforms
