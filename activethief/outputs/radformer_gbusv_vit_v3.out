nohup: ignoring input
[24/02/27 14:01:47] [conf.py:  298]: PyTorch Version: torch=1.11.0, cuda=11.3, cudnn=8200
[24/02/27 14:01:47] [conf.py:  300]: ACTIVE:
  ADDENDUM: 0
  ALPHA: 0.2
  AUGMENT: None
  BETA: 1.0
  BUDGET: 5000
  CUTMIX_PROB: 0.0
  CYCLES: 1
  INITIAL: 4500
  LA: False
  METHOD: random
  PRETRAINED_PATH: /home/ankita/mnt/data_msa_medical/ckpts/vit_b_16-imagenet1k.pth
  TEMP: 1.0
  TRO: 1.0
  USE_PRETRAINED: True
  VAL: 500
AM:
  SGR: 1000
  THRESHOLD: 0.5
CUDNN_BENCHMARK: True
DS_SEED: 123
EDM:
  HASH: /home/harsh_s/scratch/msacopy/exp/hash/alpha.pt
  NUM_MODELS: 5
  PATH1: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T0.pt
  PATH2: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T1.pt
  PATH3: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T2.pt
  PATH4: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T3.pt
  PATH5: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T4.pt
GR:
  EPSILON: 0.1
  SUR_PATH: /home/harsh_s/scratch/msacopy/GRAD2/batch_training/outputs/trained_models/imagenet_cifar10_to_cifar10_surrogate_10epochs.pt
LOG_DEST: radformer_vit_gbusv_240227_140147.txt
LOG_TIME: 240227_140147
METHOD_NAME: v3
OUT_DIR: /home/ankita/mnt/data_msa_medical/results_ankita
PL:
  CLASS_BLNC: 10
  ITERATIONS: 20
  KAPPA_N: 0.005
  KAPPA_P: 0.05
  NO_PROGRESS: False
  NO_UNCERTAINTY: False
  TAU_N: 0.05
  TAU_P: 0.7
  TEMP_NL: 2.0
RNG_SEED: 1
SAVE_DIR: /home/ankita/mnt/data_msa_medical/results_ankita/gbusg_radformer/GBUSV_vit/SGD/5000_val500/random_v3
THIEF:
  ARCH: vit
  DATASET: GBUSV
  DATA_ROOT: /home/ankita/mnt/data_msa_medical/GBUSV-Shared
  HARD_LABELS: True
  NUM_TRAIN: 1281167
  SUBSET: 128116
TRAIN:
  BATCH: 16
  EPOCH: 100
  GAMMA: 0.1
  LR: 0.001
  MILESTONES: [20, 40, 60, 80]
  MOMENTUM: 0.9
  OPTIMIZER: SGD
  WDECAY: 0.0005
VICTIM:
  ARCH: radformer
  DATASET: gbusg
  DATA_ROOT: /home/ankita/mnt/data_msa_medical/GBCU-Shared
  HEIGHT: 224
  PATH: /home/ankita/mnt/data_msa_medical/victim_models/radformer/radformer.pkl
  PATHIN: /home/harsh_s/scratch/msacopy/ckpts/cifar10-resnet32-inaccurate/checkpoint.pth.tar
  WIDTH: 224
Loaded target dataset of size 122 with 3 classes
target model keys:  695
checkpoint keys:  695
specificity = 72/80
sensitivity = 39/42

Target model acc = 0.9016393442622951
Val-Acc: 0.9016 Val-Spec: 0.9000 Val-Sens: 0.9286
/home/ankita/mnt/data_msa_medical/GBUSV-Shared/all_names.pkl
Num of videos 64 frames 15800
/home/ankita/mnt/data_msa_medical/GBUSV-Shared/all_names.pkl
Num of videos 64 frames 15800
replacing labeled set labels with victim labels
  0%|          | 0/282 [00:00<?, ?it/s]  0%|          | 1/282 [00:00<03:27,  1.36it/s]  1%|          | 2/282 [00:01<02:10,  2.15it/s]  1%|          | 3/282 [00:01<01:44,  2.67it/s]  1%|▏         | 4/282 [00:01<01:32,  2.99it/s]  2%|▏         | 5/282 [00:01<01:32,  3.00it/s]  2%|▏         | 6/282 [00:02<01:29,  3.09it/s]  2%|▏         | 7/282 [00:02<01:24,  3.25it/s]  3%|▎         | 8/282 [00:02<01:26,  3.15it/s]  3%|▎         | 9/282 [00:03<01:22,  3.30it/s]  4%|▎         | 10/282 [00:03<01:19,  3.42it/s]  4%|▍         | 11/282 [00:03<01:19,  3.42it/s]  4%|▍         | 12/282 [00:03<01:16,  3.54it/s]  5%|▍         | 13/282 [00:04<01:14,  3.61it/s]  5%|▍         | 14/282 [00:04<01:13,  3.67it/s]  5%|▌         | 15/282 [00:04<01:11,  3.75it/s]  6%|▌         | 16/282 [00:04<01:10,  3.77it/s]  6%|▌         | 17/282 [00:05<01:09,  3.84it/s]  6%|▋         | 18/282 [00:05<01:08,  3.85it/s]  7%|▋         | 19/282 [00:05<01:07,  3.88it/s]  7%|▋         | 20/282 [00:05<01:06,  3.92it/s]  7%|▋         | 21/282 [00:06<01:06,  3.93it/s]  8%|▊         | 22/282 [00:06<01:05,  3.94it/s]  8%|▊         | 23/282 [00:06<01:06,  3.90it/s]  9%|▊         | 24/282 [00:06<01:07,  3.84it/s]  9%|▉         | 25/282 [00:07<01:06,  3.86it/s]  9%|▉         | 26/282 [00:07<01:05,  3.91it/s] 10%|▉         | 27/282 [00:07<01:05,  3.91it/s] 10%|▉         | 28/282 [00:07<01:01,  4.16it/s] 10%|█         | 29/282 [00:08<00:57,  4.40it/s] 11%|█         | 30/282 [00:08<00:57,  4.39it/s] 11%|█         | 31/282 [00:08<00:55,  4.54it/s] 11%|█▏        | 32/282 [00:08<00:53,  4.66it/s] 12%|█▏        | 33/282 [00:08<00:52,  4.78it/s] 12%|█▏        | 34/282 [00:09<00:55,  4.43it/s] 12%|█▏        | 35/282 [00:09<00:57,  4.26it/s] 13%|█▎        | 36/282 [00:09<00:59,  4.16it/s] 13%|█▎        | 37/282 [00:09<00:56,  4.34it/s] 13%|█▎        | 38/282 [00:10<00:56,  4.35it/s] 14%|█▍        | 39/282 [00:10<00:53,  4.56it/s] 14%|█▍        | 40/282 [00:10<00:51,  4.71it/s] 15%|█▍        | 41/282 [00:10<00:50,  4.81it/s] 15%|█▍        | 42/282 [00:10<00:51,  4.67it/s] 15%|█▌        | 43/282 [00:11<00:52,  4.59it/s] 16%|█▌        | 44/282 [00:11<00:50,  4.74it/s] 16%|█▌        | 45/282 [00:11<00:48,  4.89it/s] 16%|█▋        | 46/282 [00:11<00:51,  4.56it/s] 17%|█▋        | 47/282 [00:12<00:53,  4.37it/s] 17%|█▋        | 48/282 [00:12<00:56,  4.17it/s] 17%|█▋        | 49/282 [00:12<00:53,  4.38it/s] 18%|█▊        | 50/282 [00:12<00:54,  4.24it/s] 18%|█▊        | 51/282 [00:13<00:51,  4.45it/s] 18%|█▊        | 52/282 [00:13<00:49,  4.65it/s] 19%|█▉        | 53/282 [00:13<00:48,  4.75it/s] 19%|█▉        | 54/282 [00:13<00:47,  4.85it/s] 20%|█▉        | 55/282 [00:13<00:45,  4.94it/s] 20%|█▉        | 56/282 [00:14<00:47,  4.79it/s] 20%|██        | 57/282 [00:14<00:46,  4.87it/s] 21%|██        | 58/282 [00:14<00:45,  4.93it/s] 21%|██        | 59/282 [00:14<00:44,  5.00it/s] 21%|██▏       | 60/282 [00:14<00:48,  4.62it/s] 22%|██▏       | 61/282 [00:15<00:50,  4.40it/s] 22%|██▏       | 62/282 [00:15<00:51,  4.30it/s] 22%|██▏       | 63/282 [00:15<00:48,  4.48it/s] 23%|██▎       | 64/282 [00:15<00:46,  4.67it/s] 23%|██▎       | 65/282 [00:15<00:45,  4.80it/s] 23%|██▎       | 66/282 [00:16<00:44,  4.87it/s] 24%|██▍       | 67/282 [00:16<00:43,  4.96it/s] 24%|██▍       | 68/282 [00:16<00:42,  5.00it/s] 24%|██▍       | 69/282 [00:16<00:42,  4.99it/s] 25%|██▍       | 70/282 [00:16<00:42,  5.01it/s] 25%|██▌       | 71/282 [00:17<00:42,  5.01it/s] 26%|██▌       | 72/282 [00:17<00:41,  5.08it/s] 26%|██▌       | 73/282 [00:17<00:41,  5.08it/s] 26%|██▌       | 74/282 [00:17<00:40,  5.10it/s] 27%|██▋       | 75/282 [00:17<00:40,  5.14it/s] 27%|██▋       | 76/282 [00:18<00:40,  5.12it/s] 27%|██▋       | 77/282 [00:18<00:39,  5.13it/s] 28%|██▊       | 78/282 [00:18<00:39,  5.17it/s] 28%|██▊       | 79/282 [00:18<00:40,  5.06it/s] 28%|██▊       | 80/282 [00:18<00:39,  5.10it/s] 29%|██▊       | 81/282 [00:19<00:39,  5.14it/s] 29%|██▉       | 82/282 [00:19<00:39,  5.09it/s] 29%|██▉       | 83/282 [00:19<00:38,  5.14it/s] 30%|██▉       | 84/282 [00:19<00:38,  5.17it/s] 30%|███       | 85/282 [00:19<00:38,  5.18it/s] 30%|███       | 86/282 [00:20<00:37,  5.16it/s] 31%|███       | 87/282 [00:20<00:37,  5.13it/s] 31%|███       | 88/282 [00:20<00:37,  5.14it/s] 32%|███▏      | 89/282 [00:20<00:37,  5.12it/s] 32%|███▏      | 90/282 [00:20<00:38,  5.03it/s] 32%|███▏      | 91/282 [00:21<00:41,  4.62it/s] 33%|███▎      | 92/282 [00:21<00:43,  4.40it/s] 33%|███▎      | 93/282 [00:21<00:44,  4.25it/s] 33%|███▎      | 94/282 [00:21<00:45,  4.11it/s] 34%|███▎      | 95/282 [00:22<00:45,  4.08it/s] 34%|███▍      | 96/282 [00:22<00:46,  4.01it/s] 34%|███▍      | 97/282 [00:22<00:47,  3.92it/s] 35%|███▍      | 98/282 [00:22<00:47,  3.90it/s] 35%|███▌      | 99/282 [00:23<00:46,  3.90it/s] 35%|███▌      | 100/282 [00:23<00:46,  3.90it/s] 36%|███▌      | 101/282 [00:23<00:46,  3.86it/s] 36%|███▌      | 102/282 [00:23<00:46,  3.84it/s] 37%|███▋      | 103/282 [00:24<00:46,  3.87it/s] 37%|███▋      | 104/282 [00:24<00:46,  3.84it/s] 37%|███▋      | 105/282 [00:24<00:45,  3.88it/s] 38%|███▊      | 106/282 [00:24<00:44,  3.91it/s] 38%|███▊      | 107/282 [00:25<00:44,  3.91it/s] 38%|███▊      | 108/282 [00:25<00:44,  3.90it/s] 39%|███▊      | 109/282 [00:25<00:43,  3.95it/s] 39%|███▉      | 110/282 [00:25<00:41,  4.17it/s] 39%|███▉      | 111/282 [00:26<00:39,  4.35it/s] 40%|███▉      | 112/282 [00:26<00:39,  4.29it/s] 40%|████      | 113/282 [00:26<00:37,  4.52it/s] 40%|████      | 114/282 [00:26<00:38,  4.36it/s] 41%|████      | 115/282 [00:27<00:38,  4.37it/s] 41%|████      | 116/282 [00:27<00:36,  4.56it/s] 41%|████▏     | 117/282 [00:27<00:37,  4.38it/s] 42%|████▏     | 118/282 [00:27<00:37,  4.40it/s] 42%|████▏     | 119/282 [00:27<00:35,  4.60it/s] 43%|████▎     | 120/282 [00:28<00:34,  4.70it/s] 43%|████▎     | 121/282 [00:28<00:35,  4.56it/s] 43%|████▎     | 122/282 [00:28<00:34,  4.68it/s] 44%|████▎     | 123/282 [00:28<00:33,  4.80it/s] 44%|████▍     | 124/282 [00:29<00:35,  4.45it/s] 44%|████▍     | 125/282 [00:29<00:36,  4.30it/s] 45%|████▍     | 126/282 [00:29<00:37,  4.20it/s] 45%|████▌     | 127/282 [00:29<00:37,  4.10it/s] 45%|████▌     | 128/282 [00:30<00:38,  4.01it/s] 46%|████▌     | 129/282 [00:30<00:38,  3.99it/s] 46%|████▌     | 130/282 [00:30<00:37,  4.01it/s] 46%|████▋     | 131/282 [00:30<00:37,  3.99it/s] 47%|████▋     | 132/282 [00:31<00:39,  3.77it/s] 47%|████▋     | 133/282 [00:31<00:41,  3.62it/s] 48%|████▊     | 134/282 [00:31<00:40,  3.65it/s] 48%|████▊     | 135/282 [00:31<00:37,  3.96it/s] 48%|████▊     | 136/282 [00:32<00:36,  4.04it/s] 49%|████▊     | 137/282 [00:32<00:39,  3.71it/s] 49%|████▉     | 138/282 [00:32<00:38,  3.75it/s] 49%|████▉     | 139/282 [00:32<00:37,  3.77it/s] 50%|████▉     | 140/282 [00:33<00:34,  4.09it/s] 50%|█████     | 141/282 [00:33<00:36,  3.84it/s] 50%|█████     | 142/282 [00:33<00:33,  4.13it/s] 51%|█████     | 143/282 [00:33<00:31,  4.39it/s] 51%|█████     | 144/282 [00:34<00:29,  4.60it/s] 51%|█████▏    | 145/282 [00:34<00:30,  4.49it/s] 52%|█████▏    | 146/282 [00:34<00:29,  4.67it/s] 52%|█████▏    | 147/282 [00:34<00:28,  4.77it/s] 52%|█████▏    | 148/282 [00:34<00:27,  4.79it/s] 53%|█████▎    | 149/282 [00:35<00:28,  4.66it/s] 53%|█████▎    | 150/282 [00:35<00:27,  4.77it/s] 54%|█████▎    | 151/282 [00:35<00:26,  4.86it/s] 54%|█████▍    | 152/282 [00:35<00:26,  4.90it/s] 54%|█████▍    | 153/282 [00:35<00:27,  4.64it/s] 55%|█████▍    | 154/282 [00:36<00:27,  4.73it/s] 55%|█████▍    | 155/282 [00:36<00:28,  4.40it/s] 55%|█████▌    | 156/282 [00:36<00:27,  4.55it/s] 56%|█████▌    | 157/282 [00:36<00:26,  4.66it/s] 56%|█████▌    | 158/282 [00:37<00:26,  4.75it/s] 56%|█████▋    | 159/282 [00:37<00:25,  4.78it/s] 57%|█████▋    | 160/282 [00:37<00:25,  4.75it/s] 57%|█████▋    | 161/282 [00:37<00:25,  4.78it/s] 57%|█████▋    | 162/282 [00:37<00:24,  4.82it/s] 58%|█████▊    | 163/282 [00:38<00:24,  4.85it/s] 58%|█████▊    | 164/282 [00:38<00:23,  4.92it/s] 59%|█████▊    | 165/282 [00:38<00:23,  4.99it/s] 59%|█████▉    | 166/282 [00:38<00:23,  5.03it/s] 59%|█████▉    | 167/282 [00:38<00:25,  4.49it/s] 60%|█████▉    | 168/282 [00:39<00:26,  4.29it/s] 60%|█████▉    | 169/282 [00:39<00:27,  4.16it/s] 60%|██████    | 170/282 [00:39<00:28,  3.95it/s] 61%|██████    | 171/282 [00:39<00:28,  3.95it/s] 61%|██████    | 172/282 [00:40<00:30,  3.58it/s] 61%|██████▏   | 173/282 [00:40<00:32,  3.31it/s] 62%|██████▏   | 174/282 [00:40<00:32,  3.37it/s] 62%|██████▏   | 175/282 [00:41<00:30,  3.51it/s] 62%|██████▏   | 176/282 [00:41<00:30,  3.53it/s] 63%|██████▎   | 177/282 [00:41<00:29,  3.51it/s] 63%|██████▎   | 178/282 [00:42<00:29,  3.58it/s] 63%|██████▎   | 179/282 [00:42<00:30,  3.40it/s] 64%|██████▍   | 180/282 [00:42<00:31,  3.29it/s] 64%|██████▍   | 181/282 [00:43<00:32,  3.11it/s] 65%|██████▍   | 182/282 [00:43<00:30,  3.31it/s] 65%|██████▍   | 183/282 [00:43<00:29,  3.39it/s] 65%|██████▌   | 184/282 [00:43<00:27,  3.54it/s] 66%|██████▌   | 185/282 [00:44<00:24,  3.90it/s] 66%|██████▌   | 186/282 [00:44<00:22,  4.19it/s] 66%|██████▋   | 187/282 [00:44<00:22,  4.25it/s] 67%|██████▋   | 188/282 [00:44<00:21,  4.46it/s] 67%|██████▋   | 189/282 [00:44<00:20,  4.64it/s] 67%|██████▋   | 190/282 [00:45<00:19,  4.77it/s] 68%|██████▊   | 191/282 [00:45<00:18,  4.85it/s] 68%|██████▊   | 192/282 [00:45<00:18,  4.92it/s] 68%|██████▊   | 193/282 [00:45<00:18,  4.93it/s] 69%|██████▉   | 194/282 [00:45<00:17,  4.89it/s] 69%|██████▉   | 195/282 [00:46<00:17,  4.89it/s] 70%|██████▉   | 196/282 [00:46<00:17,  4.91it/s] 70%|██████▉   | 197/282 [00:46<00:17,  4.95it/s] 70%|███████   | 198/282 [00:46<00:16,  5.02it/s] 71%|███████   | 199/282 [00:46<00:16,  4.99it/s] 71%|███████   | 200/282 [00:47<00:16,  4.91it/s] 71%|███████▏  | 201/282 [00:47<00:18,  4.49it/s] 72%|███████▏  | 202/282 [00:47<00:17,  4.61it/s] 72%|███████▏  | 203/282 [00:47<00:17,  4.58it/s] 72%|███████▏  | 204/282 [00:48<00:17,  4.36it/s] 73%|███████▎  | 205/282 [00:48<00:18,  4.22it/s] 73%|███████▎  | 206/282 [00:48<00:17,  4.47it/s] 73%|███████▎  | 207/282 [00:48<00:16,  4.42it/s] 74%|███████▍  | 208/282 [00:48<00:17,  4.29it/s] 74%|███████▍  | 209/282 [00:49<00:16,  4.50it/s] 74%|███████▍  | 210/282 [00:49<00:16,  4.29it/s] 75%|███████▍  | 211/282 [00:49<00:15,  4.51it/s] 75%|███████▌  | 212/282 [00:49<00:15,  4.65it/s] 76%|███████▌  | 213/282 [00:49<00:14,  4.75it/s] 76%|███████▌  | 214/282 [00:50<00:15,  4.48it/s] 76%|███████▌  | 215/282 [00:50<00:15,  4.42it/s] 77%|███████▋  | 216/282 [00:50<00:14,  4.61it/s] 77%|███████▋  | 217/282 [00:50<00:14,  4.52it/s] 77%|███████▋  | 218/282 [00:51<00:15,  4.21it/s] 78%|███████▊  | 219/282 [00:51<00:15,  4.08it/s] 78%|███████▊  | 220/282 [00:51<00:15,  4.01it/s] 78%|███████▊  | 221/282 [00:51<00:15,  4.01it/s] 79%|███████▊  | 222/282 [00:52<00:14,  4.28it/s] 79%|███████▉  | 223/282 [00:52<00:14,  4.09it/s] 79%|███████▉  | 224/282 [00:52<00:13,  4.22it/s] 80%|███████▉  | 225/282 [00:52<00:12,  4.46it/s] 80%|████████  | 226/282 [00:53<00:12,  4.65it/s] 80%|████████  | 227/282 [00:53<00:11,  4.78it/s] 81%|████████  | 228/282 [00:53<00:11,  4.88it/s] 81%|████████  | 229/282 [00:53<00:10,  4.88it/s] 82%|████████▏ | 230/282 [00:53<00:10,  4.96it/s] 82%|████████▏ | 231/282 [00:54<00:10,  5.01it/s] 82%|████████▏ | 232/282 [00:54<00:09,  5.04it/s] 83%|████████▎ | 233/282 [00:54<00:09,  5.06it/s] 83%|████████▎ | 234/282 [00:54<00:10,  4.68it/s] 83%|████████▎ | 235/282 [00:54<00:09,  4.80it/s] 84%|████████▎ | 236/282 [00:55<00:09,  4.85it/s] 84%|████████▍ | 237/282 [00:55<00:09,  4.60it/s] 84%|████████▍ | 238/282 [00:55<00:09,  4.67it/s] 85%|████████▍ | 239/282 [00:55<00:09,  4.77it/s] 85%|████████▌ | 240/282 [00:55<00:09,  4.47it/s] 85%|████████▌ | 241/282 [00:56<00:08,  4.63it/s] 86%|████████▌ | 242/282 [00:56<00:08,  4.76it/s] 86%|████████▌ | 243/282 [00:56<00:08,  4.49it/s] 87%|████████▋ | 244/282 [00:56<00:08,  4.68it/s] 87%|████████▋ | 245/282 [00:56<00:07,  4.78it/s] 87%|████████▋ | 246/282 [00:57<00:07,  4.57it/s] 88%|████████▊ | 247/282 [00:57<00:08,  4.34it/s] 88%|████████▊ | 248/282 [00:57<00:08,  4.22it/s] 88%|████████▊ | 249/282 [00:57<00:07,  4.13it/s] 89%|████████▊ | 250/282 [00:58<00:07,  4.07it/s] 89%|████████▉ | 251/282 [00:58<00:07,  3.98it/s] 89%|████████▉ | 252/282 [00:58<00:07,  3.98it/s] 90%|████████▉ | 253/282 [00:59<00:07,  3.96it/s] 90%|█████████ | 254/282 [00:59<00:07,  3.91it/s] 90%|█████████ | 255/282 [00:59<00:06,  3.92it/s] 91%|█████████ | 256/282 [00:59<00:06,  3.91it/s] 91%|█████████ | 257/282 [01:00<00:06,  3.92it/s] 91%|█████████▏| 258/282 [01:00<00:06,  3.92it/s] 92%|█████████▏| 259/282 [01:00<00:05,  3.92it/s] 92%|█████████▏| 260/282 [01:00<00:05,  3.89it/s] 93%|█████████▎| 261/282 [01:01<00:05,  3.88it/s] 93%|█████████▎| 262/282 [01:01<00:05,  3.92it/s] 93%|█████████▎| 263/282 [01:01<00:04,  3.87it/s] 94%|█████████▎| 264/282 [01:01<00:04,  3.75it/s] 94%|█████████▍| 265/282 [01:02<00:04,  3.53it/s] 94%|█████████▍| 266/282 [01:02<00:04,  3.46it/s] 95%|█████████▍| 267/282 [01:02<00:04,  3.61it/s] 95%|█████████▌| 268/282 [01:02<00:03,  3.91it/s] 95%|█████████▌| 269/282 [01:03<00:03,  3.67it/s] 96%|█████████▌| 270/282 [01:03<00:03,  3.78it/s] 96%|█████████▌| 271/282 [01:03<00:02,  4.10it/s] 96%|█████████▋| 272/282 [01:03<00:02,  4.38it/s] 97%|█████████▋| 273/282 [01:04<00:01,  4.57it/s] 97%|█████████▋| 274/282 [01:04<00:01,  4.72it/s] 98%|█████████▊| 275/282 [01:04<00:01,  4.81it/s] 98%|█████████▊| 276/282 [01:04<00:01,  4.94it/s] 98%|█████████▊| 277/282 [01:04<00:00,  5.02it/s] 99%|█████████▊| 278/282 [01:05<00:00,  5.05it/s] 99%|█████████▉| 279/282 [01:05<00:00,  5.05it/s] 99%|█████████▉| 280/282 [01:05<00:00,  5.08it/s]100%|█████████▉| 281/282 [01:05<00:00,  5.09it/s]100%|██████████| 282/282 [01:05<00:00,  4.28it/s]
replacing val labels with victim labels
  0%|          | 0/32 [00:00<?, ?it/s]  3%|▎         | 1/32 [00:00<00:20,  1.52it/s]  6%|▋         | 2/32 [00:00<00:12,  2.37it/s]  9%|▉         | 3/32 [00:01<00:09,  2.91it/s] 12%|█▎        | 4/32 [00:01<00:08,  3.24it/s] 16%|█▌        | 5/32 [00:01<00:07,  3.48it/s] 19%|█▉        | 6/32 [00:01<00:07,  3.64it/s] 22%|██▏       | 7/32 [00:02<00:06,  3.72it/s] 25%|██▌       | 8/32 [00:02<00:06,  3.80it/s] 28%|██▊       | 9/32 [00:02<00:06,  3.83it/s] 31%|███▏      | 10/32 [00:02<00:05,  3.85it/s] 34%|███▍      | 11/32 [00:03<00:05,  3.84it/s] 38%|███▊      | 12/32 [00:03<00:05,  3.86it/s] 41%|████      | 13/32 [00:03<00:04,  3.84it/s] 44%|████▍     | 14/32 [00:03<00:04,  3.92it/s] 47%|████▋     | 15/32 [00:04<00:04,  3.91it/s] 50%|█████     | 16/32 [00:04<00:04,  3.86it/s] 53%|█████▎    | 17/32 [00:04<00:03,  3.88it/s] 56%|█████▋    | 18/32 [00:05<00:03,  3.87it/s] 59%|█████▉    | 19/32 [00:05<00:03,  3.79it/s] 62%|██████▎   | 20/32 [00:05<00:03,  3.77it/s] 66%|██████▌   | 21/32 [00:05<00:02,  3.82it/s] 69%|██████▉   | 22/32 [00:06<00:02,  3.87it/s] 72%|███████▏  | 23/32 [00:06<00:02,  3.88it/s] 75%|███████▌  | 24/32 [00:06<00:02,  3.93it/s] 78%|███████▊  | 25/32 [00:06<00:01,  3.90it/s] 81%|████████▏ | 26/32 [00:07<00:01,  3.91it/s] 84%|████████▍ | 27/32 [00:07<00:01,  3.91it/s] 88%|████████▊ | 28/32 [00:07<00:01,  3.90it/s] 91%|█████████ | 29/32 [00:07<00:00,  3.92it/s] 94%|█████████▍| 30/32 [00:08<00:00,  3.90it/s] 97%|█████████▋| 31/32 [00:08<00:00,  3.85it/s]100%|██████████| 32/32 [00:08<00:00,  3.74it/s]Validation set distribution: 
Number of samples  500

{0: 74, 1: 123, 2: 303}
Labeled set distribution: 
Number of samples  4500
{0: 581, 1: 1040, 2: 2879}
odict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias', 'heads.head.weight', 'heads.head.bias'])
thief state:  None
pretrained state:  dict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias'])
Thief model initialized successfully
specificity = 80/80
sensitivity = 0/42
Initial model on target dataset: acc = 0.2541, agreement = 0.2377, f1 = 0.1351, spec = 1.0000, sens = 0.0000
specificity = 197/197
sensitivity = 0/303
Initial model on validation dataset: acc = 0.1480, agreement = 0.1480, f1 = 0.0859, spec = 1.0000, sens = 0.0000
la:  None
>> Train a Model.
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:47<1:18:53, 47.82s/it]  2%|▏         | 2/100 [01:41<1:23:44, 51.27s/it]  3%|▎         | 3/100 [02:29<1:20:35, 49.85s/it]  4%|▍         | 4/100 [03:23<1:22:06, 51.31s/it]  5%|▌         | 5/100 [04:32<1:31:31, 57.81s/it]Epoch 5: Train acc/f1 = 0.8729 / 0.8296 / 0.8149 / 0.9503 
                Val acc/f1/spec/sens = 0.8600 / 0.8327 / 0.9086 / 0.8878
                Test acc/f1/spec/sens = 0.6475 / 0.6593 / 0.6500 / 0.8333
  6%|▌         | 6/100 [05:23<1:26:49, 55.42s/it]  7%|▋         | 7/100 [06:11<1:22:20, 53.12s/it]  8%|▊         | 8/100 [07:05<1:21:59, 53.48s/it]  9%|▉         | 9/100 [07:54<1:18:40, 51.88s/it] 10%|█         | 10/100 [09:05<1:26:58, 57.99s/it]Epoch 10: Train acc/f1 = 0.8896 / 0.8497 / 0.9044 / 0.9323 
                Val acc/f1/spec/sens = 0.8760 / 0.8452 / 0.9137 / 0.9142
                Test acc/f1/spec/sens = 0.7459 / 0.7541 / 0.8000 / 0.7857
 11%|█         | 11/100 [09:54<1:21:39, 55.05s/it] 12%|█▏        | 12/100 [10:48<1:20:20, 54.77s/it] 13%|█▎        | 13/100 [11:37<1:16:39, 52.87s/it] 14%|█▍        | 14/100 [12:27<1:14:57, 52.30s/it] 15%|█▌        | 15/100 [13:37<1:21:33, 57.58s/it]Epoch 15: Train acc/f1 = 0.9160 / 0.8912 / 0.8902 / 0.9573 
                Val acc/f1/spec/sens = 0.8740 / 0.8343 / 0.8731 / 0.9472
                Test acc/f1/spec/sens = 0.6803 / 0.6814 / 0.8625 / 0.5714
 16%|█▌        | 16/100 [14:31<1:19:09, 56.54s/it] 17%|█▋        | 17/100 [15:20<1:14:53, 54.13s/it] 18%|█▊        | 18/100 [16:11<1:12:48, 53.28s/it] 19%|█▉        | 19/100 [17:00<1:09:59, 51.85s/it] 20%|██        | 20/100 [18:14<1:18:04, 58.55s/it]Epoch 20: Train acc/f1 = 0.9140 / 0.8835 / 0.8470 / 0.9795 
                Val acc/f1/spec/sens = 0.8720 / 0.8182 / 0.8579 / 0.9571
                Test acc/f1/spec/sens = 0.5984 / 0.5758 / 0.6500 / 0.8095
 21%|██        | 21/100 [19:03<1:13:12, 55.60s/it] 22%|██▏       | 22/100 [19:57<1:11:49, 55.25s/it] 23%|██▎       | 23/100 [20:46<1:08:19, 53.24s/it] 24%|██▍       | 24/100 [21:37<1:06:39, 52.63s/it] 25%|██▌       | 25/100 [22:47<1:12:16, 57.82s/it]Epoch 25: Train acc/f1 = 0.9567 / 0.9415 / 0.9562 / 0.9753 
                Val acc/f1/spec/sens = 0.8920 / 0.8598 / 0.8985 / 0.9406
                Test acc/f1/spec/sens = 0.6967 / 0.6938 / 0.8000 / 0.7381
 26%|██▌       | 26/100 [23:38<1:08:48, 55.79s/it] 27%|██▋       | 27/100 [24:26<1:05:13, 53.61s/it] 28%|██▊       | 28/100 [25:21<1:04:37, 53.85s/it] 29%|██▉       | 29/100 [26:09<1:01:49, 52.25s/it] 30%|███       | 30/100 [27:25<1:09:03, 59.19s/it]Epoch 30: Train acc/f1 = 0.9613 / 0.9492 / 0.9445 / 0.9844 
                Val acc/f1/spec/sens = 0.9080 / 0.8799 / 0.8934 / 0.9604
                Test acc/f1/spec/sens = 0.6639 / 0.6578 / 0.7625 / 0.7619
 31%|███       | 31/100 [28:13<1:04:20, 55.95s/it] 32%|███▏      | 32/100 [29:04<1:01:49, 54.56s/it] 33%|███▎      | 33/100 [29:53<58:55, 52.76s/it]   34%|███▍      | 34/100 [30:47<58:34, 53.25s/it] 35%|███▌      | 35/100 [31:57<1:03:07, 58.27s/it]Epoch 35: Train acc/f1 = 0.9664 / 0.9585 / 0.9568 / 0.9823 
                Val acc/f1/spec/sens = 0.9060 / 0.8804 / 0.8934 / 0.9538
                Test acc/f1/spec/sens = 0.6967 / 0.6855 / 0.8125 / 0.7857
 36%|███▌      | 36/100 [32:52<1:00:51, 57.06s/it] 37%|███▋      | 37/100 [33:40<57:14, 54.52s/it]   38%|███▊      | 38/100 [34:31<55:20, 53.56s/it] 39%|███▉      | 39/100 [35:20<52:54, 52.04s/it] 40%|████      | 40/100 [36:36<59:16, 59.27s/it]Epoch 40: Train acc/f1 = 0.9720 / 0.9634 / 0.9605 / 0.9885 
                Val acc/f1/spec/sens = 0.9100 / 0.8859 / 0.8985 / 0.9571
                Test acc/f1/spec/sens = 0.6639 / 0.6569 / 0.8000 / 0.6905
 41%|████      | 41/100 [37:25<55:04, 56.02s/it] 42%|████▏     | 42/100 [38:20<53:58, 55.83s/it] 43%|████▎     | 43/100 [39:16<53:12, 56.00s/it] 44%|████▍     | 44/100 [40:08<51:01, 54.67s/it] 45%|████▌     | 45/100 [41:19<54:35, 59.56s/it]Epoch 45: Train acc/f1 = 0.9780 / 0.9715 / 0.9729 / 0.9878 
                Val acc/f1/spec/sens = 0.9060 / 0.8817 / 0.8985 / 0.9505
                Test acc/f1/spec/sens = 0.6721 / 0.6732 / 0.8000 / 0.6905
 46%|████▌     | 46/100 [42:10<51:21, 57.06s/it] 47%|████▋     | 47/100 [42:59<48:07, 54.48s/it] 48%|████▊     | 48/100 [43:50<46:23, 53.53s/it] 49%|████▉     | 49/100 [44:38<44:11, 51.98s/it] 50%|█████     | 50/100 [45:51<48:23, 58.08s/it]Epoch 50: Train acc/f1 = 0.9747 / 0.9667 / 0.9685 / 0.9882 
                Val acc/f1/spec/sens = 0.9040 / 0.8771 / 0.8934 / 0.9538
                Test acc/f1/spec/sens = 0.6557 / 0.6507 / 0.8000 / 0.6905
 51%|█████     | 51/100 [46:39<45:04, 55.20s/it] 52%|█████▏    | 52/100 [47:30<43:13, 54.03s/it] 53%|█████▎    | 53/100 [48:19<41:00, 52.35s/it] 54%|█████▍    | 54/100 [49:10<39:55, 52.07s/it] 55%|█████▌    | 55/100 [50:20<43:01, 57.37s/it]Epoch 55: Train acc/f1 = 0.9716 / 0.9641 / 0.9729 / 0.9795 
                Val acc/f1/spec/sens = 0.9060 / 0.8804 / 0.8934 / 0.9538
                Test acc/f1/spec/sens = 0.6721 / 0.6732 / 0.8000 / 0.6905
 56%|█████▌    | 56/100 [51:12<40:52, 55.73s/it] 57%|█████▋    | 57/100 [52:01<38:27, 53.65s/it] 58%|█████▊    | 58/100 [52:52<37:10, 53.11s/it] 59%|█████▉    | 59/100 [53:41<35:22, 51.78s/it] 60%|██████    | 60/100 [54:54<38:39, 57.98s/it]Epoch 60: Train acc/f1 = 0.9744 / 0.9668 / 0.9722 / 0.9844 
                Val acc/f1/spec/sens = 0.9040 / 0.8770 / 0.8883 / 0.9571
                Test acc/f1/spec/sens = 0.6803 / 0.6804 / 0.8000 / 0.7143
 61%|██████    | 61/100 [55:42<35:49, 55.11s/it] 62%|██████▏   | 62/100 [56:33<34:10, 53.97s/it] 63%|██████▎   | 63/100 [57:22<32:15, 52.32s/it] 64%|██████▍   | 64/100 [58:13<31:15, 52.10s/it] 65%|██████▌   | 65/100 [59:22<33:22, 57.20s/it]Epoch 65: Train acc/f1 = 0.9736 / 0.9656 / 0.9692 / 0.9861 
                Val acc/f1/spec/sens = 0.9020 / 0.8744 / 0.8883 / 0.9538
                Test acc/f1/spec/sens = 0.6803 / 0.6804 / 0.8000 / 0.7143
 66%|██████▌   | 66/100 [1:00:14<31:23, 55.41s/it] 67%|██████▋   | 67/100 [1:01:02<29:18, 53.30s/it] 68%|██████▊   | 68/100 [1:01:54<28:09, 52.79s/it] 69%|██████▉   | 69/100 [1:02:42<26:37, 51.53s/it] 70%|███████   | 70/100 [1:03:55<28:55, 57.84s/it]Epoch 70: Train acc/f1 = 0.9767 / 0.9708 / 0.9704 / 0.9868 
                Val acc/f1/spec/sens = 0.9040 / 0.8782 / 0.8883 / 0.9538
                Test acc/f1/spec/sens = 0.6803 / 0.6804 / 0.8000 / 0.7143
 71%|███████   | 71/100 [1:04:43<26:35, 55.03s/it] 72%|███████▏  | 72/100 [1:05:35<25:10, 53.95s/it] 73%|███████▎  | 73/100 [1:06:23<23:32, 52.33s/it] 74%|███████▍  | 74/100 [1:07:15<22:32, 52.02s/it] 75%|███████▌  | 75/100 [1:08:26<24:02, 57.70s/it]Epoch 75: Train acc/f1 = 0.9753 / 0.9673 / 0.9747 / 0.9844 
                Val acc/f1/spec/sens = 0.9040 / 0.8782 / 0.8883 / 0.9538
                Test acc/f1/spec/sens = 0.6803 / 0.6804 / 0.8000 / 0.7143
 76%|███████▌  | 76/100 [1:09:17<22:18, 55.76s/it] 77%|███████▋  | 77/100 [1:10:05<20:30, 53.52s/it] 78%|███████▊  | 78/100 [1:10:56<19:23, 52.86s/it] 79%|███████▉  | 79/100 [1:11:45<18:01, 51.52s/it] 80%|████████  | 80/100 [1:12:58<19:19, 57.99s/it]Epoch 80: Train acc/f1 = 0.9749 / 0.9680 / 0.9766 / 0.9819 
                Val acc/f1/spec/sens = 0.9040 / 0.8782 / 0.8883 / 0.9538
                Test acc/f1/spec/sens = 0.6803 / 0.6804 / 0.8000 / 0.7143
 81%|████████  | 81/100 [1:13:47<17:28, 55.20s/it] 82%|████████▏ | 82/100 [1:14:38<16:13, 54.06s/it] 83%|████████▎ | 83/100 [1:15:26<14:50, 52.39s/it] 84%|████████▍ | 84/100 [1:16:18<13:53, 52.10s/it] 85%|████████▌ | 85/100 [1:17:27<14:20, 57.36s/it]Epoch 85: Train acc/f1 = 0.9733 / 0.9642 / 0.9747 / 0.9844 
                Val acc/f1/spec/sens = 0.9040 / 0.8782 / 0.8883 / 0.9538
                Test acc/f1/spec/sens = 0.6803 / 0.6804 / 0.8000 / 0.7143
 86%|████████▌ | 86/100 [1:18:19<12:57, 55.51s/it] 87%|████████▋ | 87/100 [1:19:07<11:34, 53.42s/it] 88%|████████▊ | 88/100 [1:19:59<10:34, 52.87s/it] 89%|████████▉ | 89/100 [1:20:47<09:27, 51.58s/it] 90%|█████████ | 90/100 [1:22:00<09:39, 57.91s/it]Epoch 90: Train acc/f1 = 0.9747 / 0.9672 / 0.9729 / 0.9851 
                Val acc/f1/spec/sens = 0.9040 / 0.8782 / 0.8883 / 0.9538
                Test acc/f1/spec/sens = 0.6803 / 0.6804 / 0.8000 / 0.7143
 91%|█████████ | 91/100 [1:22:49<08:16, 55.12s/it] 92%|█████████▏| 92/100 [1:23:40<07:12, 54.01s/it] 93%|█████████▎| 93/100 [1:24:29<06:06, 52.35s/it] 94%|█████████▍| 94/100 [1:25:20<05:12, 52.09s/it] 95%|█████████▌| 95/100 [1:26:30<04:46, 57.32s/it]Epoch 95: Train acc/f1 = 0.9782 / 0.9712 / 0.9747 / 0.9875 
                Val acc/f1/spec/sens = 0.9040 / 0.8782 / 0.8883 / 0.9538
                Test acc/f1/spec/sens = 0.6803 / 0.6804 / 0.8000 / 0.7143
 96%|█████████▌| 96/100 [1:27:21<03:41, 55.46s/it] 97%|█████████▋| 97/100 [1:28:09<02:40, 53.39s/it] 98%|█████████▊| 98/100 [1:29:01<01:45, 52.82s/it] 99%|█████████▉| 99/100 [1:29:49<00:51, 51.53s/it]100%|██████████| 100/100 [1:31:02<00:00, 57.82s/it]                                                   Epoch 100: Train acc/f1 = 0.9731 / 0.9640 / 0.9766 / 0.9823 
                Val acc/f1/spec/sens = 0.9040 / 0.8782 / 0.8883 / 0.9538
                Test acc/f1/spec/sens = 0.6803 / 0.6804 / 0.8000 / 0.7143
specificity = 1576/1621
sensitivity = 2837/2879
specificity = 175/197
sensitivity = 289/303
specificity = 64/80
sensitivity = 30/42
Trial 1, Cycle 1
Train acc/f1/spec/sens = 0.9744 / 0.9660 / 0.9722 / 0.9854
Val acc/f1/spec/sens = 0.9040 / 0.8782 / 0.8883 / 0.9538
Test acc/f1/spec/sens = 0.6803 / 0.6804 / 0.8000 / 0.7143
>> Finished.
specificity = 64/80
sensitivity = 30/42
Acc, agreement for latest model:  0.680327868852459 0.6967213114754098
Load best checkpoint for thief model
specificity = 64/80
sensitivity = 29/42
Acc, agreement for best model:  0.6639344262295082 0.680327868852459
Trial 0/1 || Cycle 1/1 || Label set size 4500 || Test acc 0.6639 || Test agreement 0.6803 || Spec 0.8000 || Sens 0.6905
**************************************************************************************************** 

specificity = 64/80
sensitivity = 29/42
Number of samples  4500
0.680327868852459 0.0
        acc       agr  spec      sens                  label dist
0  0.663934  0.680328   0.8  0.690476  {0: 581, 1: 1040, 2: 2879}
Results saved to  /home/ankita/mnt/data_msa_medical/results_ankita/gbusg_radformer/GBUSV_vit/SGD/5000_val500/random_v3
