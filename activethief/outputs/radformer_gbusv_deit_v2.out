nohup: ignoring input
[24/02/24 14:09:24] [conf.py:  298]: PyTorch Version: torch=1.11.0, cuda=11.3, cudnn=8200
[24/02/24 14:09:24] [conf.py:  300]: ACTIVE:
  ADDENDUM: 0
  ALPHA: 0.2
  AUGMENT: None
  BETA: 1.0
  BUDGET: 5000
  CUTMIX_PROB: 0.0
  CYCLES: 1
  INITIAL: 4500
  LA: False
  METHOD: random
  PRETRAINED_PATH: /home/ankita/mnt/data_msa_medical/ckpts/deit_base_patch16_224-b5f2ef4d.pth
  TEMP: 1.0
  TRO: 1.0
  USE_PRETRAINED: True
  VAL: 500
AM:
  SGR: 1000
  THRESHOLD: 0.5
CUDNN_BENCHMARK: True
DS_SEED: 123
EDM:
  HASH: /home/harsh_s/scratch/msacopy/exp/hash/alpha.pt
  NUM_MODELS: 5
  PATH1: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T0.pt
  PATH2: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T1.pt
  PATH3: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T2.pt
  PATH4: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T3.pt
  PATH5: /home/harsh_s/scratch/msacopy/exp/cifar10/alpha/T4.pt
GR:
  EPSILON: 0.1
  SUR_PATH: /home/harsh_s/scratch/msacopy/GRAD2/batch_training/outputs/trained_models/imagenet_cifar10_to_cifar10_surrogate_10epochs.pt
LOG_DEST: radformer_deit_gbusv_240224_140924.txt
LOG_TIME: 240224_140924
METHOD_NAME: v2
OUT_DIR: /home/ankita/mnt/data_msa_medical/results_ankita
PL:
  CLASS_BLNC: 10
  ITERATIONS: 20
  KAPPA_N: 0.005
  KAPPA_P: 0.05
  NO_PROGRESS: False
  NO_UNCERTAINTY: False
  TAU_N: 0.05
  TAU_P: 0.7
  TEMP_NL: 2.0
RNG_SEED: 1
SAVE_DIR: /home/ankita/mnt/data_msa_medical/results_ankita/gbusg_radformer/GBUSV_deit/SGD/5000_val500/random_v2
THIEF:
  ARCH: deit
  DATASET: GBUSV
  DATA_ROOT: /home/ankita/mnt/data_msa_medical/GBUSV-Shared
  HARD_LABELS: True
  NUM_TRAIN: 1281167
  SUBSET: 128116
TRAIN:
  BATCH: 64
  EPOCH: 100
  GAMMA: 0.1
  LR: 0.005
  MILESTONES: [20, 40, 60, 80]
  MOMENTUM: 0.9
  OPTIMIZER: SGD
  WDECAY: 0.0005
VICTIM:
  ARCH: radformer
  DATASET: gbusg
  DATA_ROOT: /home/ankita/mnt/data_msa_medical/GBCU-Shared
  HEIGHT: 224
  PATH: /home/ankita/mnt/data_msa_medical/victim_models/radformer/radformer.pkl
  PATHIN: /home/harsh_s/scratch/msacopy/ckpts/cifar10-resnet32-inaccurate/checkpoint.pth.tar
  WIDTH: 224
Loaded target dataset of size 122 with 3 classes
target model keys:  695
checkpoint keys:  695
specificity = 72/80
sensitivity = 39/42

Target model acc = 0.9016393442622951
Val-Acc: 0.9016 Val-Spec: 0.9000 Val-Sens: 0.9286
/home/ankita/mnt/data_msa_medical/GBUSV-Shared/all_names.pkl
Num of videos 64 frames 15800
/home/ankita/mnt/data_msa_medical/GBUSV-Shared/all_names.pkl
Num of videos 64 frames 15800
replacing labeled set labels with victim labels
  0%|          | 0/71 [00:00<?, ?it/s]  1%|▏         | 1/71 [00:02<02:26,  2.10s/it]  3%|▎         | 2/71 [00:03<01:56,  1.69s/it]  4%|▍         | 3/71 [00:04<01:46,  1.57s/it]  6%|▌         | 4/71 [00:06<01:37,  1.45s/it]  7%|▋         | 5/71 [00:07<01:30,  1.37s/it]  8%|▊         | 6/71 [00:08<01:27,  1.34s/it] 10%|▉         | 7/71 [00:10<01:27,  1.36s/it] 11%|█▏        | 8/71 [00:11<01:26,  1.37s/it] 13%|█▎        | 9/71 [00:12<01:25,  1.38s/it] 14%|█▍        | 10/71 [00:14<01:25,  1.40s/it] 15%|█▌        | 11/71 [00:15<01:24,  1.40s/it] 17%|█▋        | 12/71 [00:17<01:22,  1.40s/it] 18%|█▊        | 13/71 [00:18<01:21,  1.40s/it] 20%|█▉        | 14/71 [00:19<01:19,  1.40s/it] 21%|██        | 15/71 [00:21<01:19,  1.41s/it] 23%|██▎       | 16/71 [00:22<01:17,  1.41s/it] 24%|██▍       | 17/71 [00:24<01:14,  1.38s/it] 25%|██▌       | 18/71 [00:25<01:09,  1.32s/it] 27%|██▋       | 19/71 [00:26<01:06,  1.27s/it] 28%|██▊       | 20/71 [00:27<01:04,  1.26s/it] 30%|██▉       | 21/71 [00:29<01:05,  1.30s/it] 31%|███       | 22/71 [00:30<01:02,  1.28s/it] 32%|███▏      | 23/71 [00:31<00:58,  1.22s/it] 34%|███▍      | 24/71 [00:32<01:01,  1.30s/it] 35%|███▌      | 25/71 [00:34<00:58,  1.27s/it] 37%|███▋      | 26/71 [00:35<00:58,  1.31s/it] 38%|███▊      | 27/71 [00:36<00:58,  1.33s/it] 39%|███▉      | 28/71 [00:38<00:57,  1.35s/it] 41%|████      | 29/71 [00:39<00:55,  1.32s/it] 42%|████▏     | 30/71 [00:40<00:54,  1.34s/it] 44%|████▎     | 31/71 [00:42<00:53,  1.33s/it] 45%|████▌     | 32/71 [00:43<00:52,  1.34s/it] 46%|████▋     | 33/71 [00:44<00:50,  1.34s/it] 48%|████▊     | 34/71 [00:46<00:50,  1.37s/it] 49%|████▉     | 35/71 [00:47<00:47,  1.33s/it] 51%|█████     | 36/71 [00:48<00:46,  1.34s/it] 52%|█████▏    | 37/71 [00:50<00:43,  1.29s/it] 54%|█████▎    | 38/71 [00:51<00:43,  1.31s/it] 55%|█████▍    | 39/71 [00:52<00:41,  1.29s/it] 56%|█████▋    | 40/71 [00:54<00:41,  1.33s/it] 58%|█████▊    | 41/71 [00:55<00:40,  1.35s/it] 59%|█████▉    | 42/71 [00:56<00:37,  1.28s/it] 61%|██████    | 43/71 [00:58<00:36,  1.32s/it] 62%|██████▏   | 44/71 [00:59<00:37,  1.38s/it] 63%|██████▎   | 45/71 [01:01<00:36,  1.40s/it] 65%|██████▍   | 46/71 [01:02<00:32,  1.32s/it] 66%|██████▌   | 47/71 [01:03<00:31,  1.33s/it] 68%|██████▊   | 48/71 [01:04<00:31,  1.35s/it] 69%|██████▉   | 49/71 [01:06<00:30,  1.37s/it] 70%|███████   | 50/71 [01:07<00:28,  1.38s/it] 72%|███████▏  | 51/71 [01:09<00:27,  1.39s/it] 73%|███████▎  | 52/71 [01:10<00:26,  1.39s/it] 75%|███████▍  | 53/71 [01:11<00:24,  1.34s/it] 76%|███████▌  | 54/71 [01:12<00:21,  1.29s/it] 77%|███████▋  | 55/71 [01:14<00:20,  1.26s/it] 79%|███████▉  | 56/71 [01:15<00:19,  1.31s/it] 80%|████████  | 57/71 [01:16<00:18,  1.33s/it] 82%|████████▏ | 58/71 [01:18<00:17,  1.36s/it] 83%|████████▎ | 59/71 [01:19<00:16,  1.38s/it] 85%|████████▍ | 60/71 [01:21<00:15,  1.40s/it] 86%|████████▌ | 61/71 [01:22<00:14,  1.41s/it] 87%|████████▋ | 62/71 [01:23<00:12,  1.35s/it] 89%|████████▊ | 63/71 [01:25<00:10,  1.30s/it] 90%|█████████ | 64/71 [01:26<00:08,  1.27s/it] 92%|█████████▏| 65/71 [01:27<00:07,  1.26s/it] 93%|█████████▎| 66/71 [01:28<00:06,  1.32s/it] 94%|█████████▍| 67/71 [01:30<00:05,  1.36s/it] 96%|█████████▌| 68/71 [01:31<00:03,  1.33s/it] 97%|█████████▋| 69/71 [01:33<00:02,  1.36s/it] 99%|█████████▊| 70/71 [01:34<00:01,  1.37s/it]100%|██████████| 71/71 [01:34<00:00,  1.10s/it]100%|██████████| 71/71 [01:35<00:00,  1.34s/it]
replacing val labels with victim labels
  0%|          | 0/8 [00:00<?, ?it/s] 12%|█▎        | 1/8 [00:02<00:14,  2.14s/it] 25%|██▌       | 2/8 [00:03<00:10,  1.69s/it] 38%|███▊      | 3/8 [00:04<00:07,  1.54s/it] 50%|█████     | 4/8 [00:06<00:05,  1.48s/it] 62%|██████▎   | 5/8 [00:07<00:04,  1.44s/it] 75%|███████▌  | 6/8 [00:08<00:02,  1.41s/it] 88%|████████▊ | 7/8 [00:10<00:01,  1.41s/it]100%|██████████| 8/8 [00:11<00:00,  1.32s/it]100%|██████████| 8/8 [00:11<00:00,  1.45s/it]Validation set distribution: 
Number of samples  500

{0: 74, 1: 123, 2: 303}
Labeled set distribution: 
Number of samples  4500
{0: 581, 1: 1040, 2: 2879}
odict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias'])
thief state:  None
pretrained state:  dict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias'])
Thief model initialized successfully
specificity = 78/80
sensitivity = 1/42
Initial model on target dataset: acc = 0.3770, agreement = 0.3361, f1 = 0.1955, spec = 0.9750, sens = 0.0238
Using cache found in /home/ankita/.cache/torch/hub/facebookresearch_deit_main
specificity = 194/197
sensitivity = 7/303
Initial model on validation dataset: acc = 0.2460, agreement = 0.2460, f1 = 0.1421, spec = 0.9848, sens = 0.0231
la:  None
>> Train a Model.
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [01:39<2:44:04, 99.44s/it]  2%|▏         | 2/100 [03:25<2:49:11, 103.58s/it]  3%|▎         | 3/100 [05:05<2:44:37, 101.83s/it]  4%|▍         | 4/100 [06:52<2:45:53, 103.68s/it]  5%|▌         | 5/100 [09:07<3:02:26, 115.23s/it]Epoch 5: Train acc/f1 = 0.9662 / 0.9579 / 0.9790 / 0.9698 
                Val acc/f1/spec/sens = 0.8620 / 0.8317 / 0.8376 / 0.9274
                Test acc/f1/spec/sens = 0.5820 / 0.5571 / 0.6250 / 0.8810
  6%|▌         | 6/100 [10:55<2:56:22, 112.58s/it]  7%|▋         | 7/100 [12:35<2:47:59, 108.39s/it]  8%|▊         | 8/100 [14:22<2:45:48, 108.13s/it]  9%|▉         | 9/100 [16:01<2:39:33, 105.20s/it] 10%|█         | 10/100 [18:20<2:53:39, 115.78s/it]Epoch 10: Train acc/f1 = 0.9911 / 0.9881 / 0.9846 / 0.9976 
                Val acc/f1/spec/sens = 0.8780 / 0.8439 / 0.8325 / 0.9571
                Test acc/f1/spec/sens = 0.5410 / 0.5053 / 0.5625 / 0.8810
 11%|█         | 11/100 [19:59<2:43:52, 110.47s/it] 12%|█▏        | 12/100 [21:43<2:39:14, 108.57s/it] 13%|█▎        | 13/100 [23:21<2:32:55, 105.47s/it] 14%|█▍        | 14/100 [25:09<2:31:53, 105.97s/it] 15%|█▌        | 15/100 [27:23<2:42:09, 114.46s/it]Epoch 15: Train acc/f1 = 0.9982 / 0.9976 / 0.9981 / 0.9986 
                Val acc/f1/spec/sens = 0.8940 / 0.8672 / 0.8376 / 0.9670
                Test acc/f1/spec/sens = 0.5820 / 0.5758 / 0.5500 / 0.9048
 16%|█▌        | 16/100 [29:07<2:35:50, 111.32s/it] 17%|█▋        | 17/100 [30:45<2:28:33, 107.39s/it] 18%|█▊        | 18/100 [32:29<2:25:15, 106.29s/it] 19%|█▉        | 19/100 [34:07<2:20:11, 103.85s/it] 20%|██        | 20/100 [36:29<2:33:59, 115.50s/it]Epoch 20: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8820 / 0.8507 / 0.8579 / 0.9439
                Test acc/f1/spec/sens = 0.6557 / 0.6549 / 0.6625 / 0.8810
 21%|██        | 21/100 [38:10<2:26:02, 110.91s/it] 22%|██▏       | 22/100 [39:53<2:21:05, 108.53s/it] 23%|██▎       | 23/100 [41:32<2:15:40, 105.72s/it] 24%|██▍       | 24/100 [43:15<2:12:58, 104.98s/it] 25%|██▌       | 25/100 [45:34<2:23:58, 115.17s/it]Epoch 25: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8840 / 0.8529 / 0.8629 / 0.9439
                Test acc/f1/spec/sens = 0.6393 / 0.6430 / 0.6750 / 0.8095
 26%|██▌       | 26/100 [47:13<2:16:10, 110.41s/it] 27%|██▋       | 27/100 [48:52<2:10:11, 107.01s/it] 28%|██▊       | 28/100 [50:36<2:07:01, 105.85s/it] 29%|██▉       | 29/100 [52:15<2:03:00, 103.95s/it] 30%|███       | 30/100 [54:38<2:15:01, 115.74s/it]Epoch 30: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8840 / 0.8529 / 0.8629 / 0.9439
                Test acc/f1/spec/sens = 0.6393 / 0.6430 / 0.6750 / 0.8095
 31%|███       | 31/100 [56:12<2:05:36, 109.23s/it] 32%|███▏      | 32/100 [57:56<2:01:46, 107.44s/it] 33%|███▎      | 33/100 [59:36<1:57:40, 105.38s/it] 34%|███▍      | 34/100 [1:01:21<1:55:35, 105.08s/it] 35%|███▌      | 35/100 [1:03:37<2:04:06, 114.56s/it]Epoch 35: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8840 / 0.8529 / 0.8629 / 0.9439
                Test acc/f1/spec/sens = 0.6393 / 0.6430 / 0.6750 / 0.8095
 36%|███▌      | 36/100 [1:05:20<1:58:18, 110.91s/it] 37%|███▋      | 37/100 [1:06:55<1:51:38, 106.33s/it] 38%|███▊      | 38/100 [1:08:39<1:49:08, 105.62s/it] 39%|███▉      | 39/100 [1:10:17<1:45:07, 103.39s/it] 40%|████      | 40/100 [1:12:41<1:55:27, 115.46s/it]Epoch 40: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8840 / 0.8529 / 0.8629 / 0.9439
                Test acc/f1/spec/sens = 0.6393 / 0.6430 / 0.6750 / 0.8095
 41%|████      | 41/100 [1:14:20<1:48:32, 110.39s/it] 42%|████▏     | 42/100 [1:15:59<1:43:29, 107.07s/it] 43%|████▎     | 43/100 [1:17:38<1:39:19, 104.55s/it] 44%|████▍     | 44/100 [1:19:22<1:37:30, 104.47s/it] 45%|████▌     | 45/100 [1:21:41<1:45:16, 114.85s/it]Epoch 45: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8840 / 0.8529 / 0.8629 / 0.9439
                Test acc/f1/spec/sens = 0.6393 / 0.6430 / 0.6750 / 0.8095
 46%|████▌     | 46/100 [1:23:26<1:40:36, 111.79s/it] 47%|████▋     | 47/100 [1:25:03<1:35:02, 107.59s/it] 48%|████▊     | 48/100 [1:26:45<1:31:45, 105.88s/it] 49%|████▉     | 49/100 [1:28:25<1:28:25, 104.03s/it] 50%|█████     | 50/100 [1:30:47<1:36:10, 115.41s/it]Epoch 50: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8840 / 0.8529 / 0.8629 / 0.9439
                Test acc/f1/spec/sens = 0.6393 / 0.6430 / 0.6750 / 0.8095
 51%|█████     | 51/100 [1:32:27<1:30:29, 110.80s/it] 52%|█████▏    | 52/100 [1:34:11<1:27:01, 108.79s/it] 53%|█████▎    | 53/100 [1:35:45<1:21:43, 104.33s/it] 54%|█████▍    | 54/100 [1:37:28<1:19:43, 103.99s/it] 55%|█████▌    | 55/100 [1:39:47<1:25:46, 114.37s/it]Epoch 55: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8840 / 0.8529 / 0.8629 / 0.9439
                Test acc/f1/spec/sens = 0.6393 / 0.6430 / 0.6750 / 0.8095
 56%|█████▌    | 56/100 [1:41:30<1:21:24, 111.01s/it] 57%|█████▋    | 57/100 [1:43:09<1:17:00, 107.46s/it] 58%|█████▊    | 58/100 [1:44:50<1:13:47, 105.40s/it] 59%|█████▉    | 59/100 [1:46:28<1:10:37, 103.35s/it] 60%|██████    | 60/100 [1:48:50<1:16:34, 114.86s/it]Epoch 60: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8840 / 0.8529 / 0.8629 / 0.9439
                Test acc/f1/spec/sens = 0.6393 / 0.6430 / 0.6750 / 0.8095
 61%|██████    | 61/100 [1:50:29<1:11:37, 110.19s/it] 62%|██████▏   | 62/100 [1:52:13<1:08:30, 108.16s/it] 63%|██████▎   | 63/100 [1:53:53<1:05:14, 105.80s/it] 64%|██████▍   | 64/100 [1:55:32<1:02:13, 103.71s/it] 65%|██████▌   | 65/100 [1:57:50<1:06:31, 114.03s/it]Epoch 65: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8840 / 0.8529 / 0.8629 / 0.9439
                Test acc/f1/spec/sens = 0.6393 / 0.6430 / 0.6750 / 0.8095
 66%|██████▌   | 66/100 [1:59:35<1:03:00, 111.20s/it] 67%|██████▋   | 67/100 [2:01:14<59:08, 107.52s/it]   68%|██████▊   | 68/100 [2:02:58<56:53, 106.68s/it] 69%|██████▉   | 69/100 [2:04:33<53:11, 102.95s/it] 70%|███████   | 70/100 [2:06:56<57:36, 115.23s/it]Epoch 70: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8840 / 0.8529 / 0.8629 / 0.9439
                Test acc/f1/spec/sens = 0.6393 / 0.6430 / 0.6750 / 0.8095
 71%|███████   | 71/100 [2:08:35<53:16, 110.21s/it] 72%|███████▏  | 72/100 [2:10:19<50:33, 108.32s/it] 73%|███████▎  | 73/100 [2:11:57<47:24, 105.36s/it] 74%|███████▍  | 74/100 [2:13:41<45:28, 104.92s/it] 75%|███████▌  | 75/100 [2:15:56<47:26, 113.87s/it]Epoch 75: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8840 / 0.8529 / 0.8629 / 0.9439
                Test acc/f1/spec/sens = 0.6393 / 0.6430 / 0.6750 / 0.8095
 76%|███████▌  | 76/100 [2:17:39<44:11, 110.49s/it] 77%|███████▋  | 77/100 [2:19:17<41:00, 106.98s/it] 78%|███████▊  | 78/100 [2:21:00<38:44, 105.67s/it] 79%|███████▉  | 79/100 [2:22:39<36:14, 103.57s/it] 80%|████████  | 80/100 [2:24:53<37:38, 112.95s/it]Epoch 80: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8840 / 0.8529 / 0.8629 / 0.9439
                Test acc/f1/spec/sens = 0.6393 / 0.6430 / 0.6750 / 0.8095
 81%|████████  | 81/100 [2:25:50<30:22, 95.91s/it]  82%|████████▏ | 82/100 [2:26:37<24:23, 81.31s/it] 83%|████████▎ | 83/100 [2:27:21<19:55, 70.30s/it] 84%|████████▍ | 84/100 [2:28:09<16:54, 63.39s/it] 85%|████████▌ | 85/100 [2:29:13<15:55, 63.67s/it]Epoch 85: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8840 / 0.8529 / 0.8629 / 0.9439
                Test acc/f1/spec/sens = 0.6393 / 0.6430 / 0.6750 / 0.8095
 86%|████████▌ | 86/100 [2:30:00<13:41, 58.69s/it] 87%|████████▋ | 87/100 [2:30:45<11:48, 54.49s/it] 88%|████████▊ | 88/100 [2:31:32<10:28, 52.37s/it] 89%|████████▉ | 89/100 [2:32:17<09:10, 50.04s/it] 90%|█████████ | 90/100 [2:33:24<09:11, 55.15s/it]Epoch 90: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8840 / 0.8529 / 0.8629 / 0.9439
                Test acc/f1/spec/sens = 0.6393 / 0.6430 / 0.6750 / 0.8095
 91%|█████████ | 91/100 [2:34:09<07:47, 52.00s/it] 92%|█████████▏| 92/100 [2:34:56<06:44, 50.58s/it] 93%|█████████▎| 93/100 [2:35:40<05:41, 48.80s/it] 94%|█████████▍| 94/100 [2:36:28<04:50, 48.34s/it] 95%|█████████▌| 95/100 [2:37:32<04:25, 53.19s/it]Epoch 95: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8840 / 0.8529 / 0.8629 / 0.9439
                Test acc/f1/spec/sens = 0.6393 / 0.6430 / 0.6750 / 0.8095
 96%|█████████▌| 96/100 [2:38:19<03:25, 51.40s/it] 97%|█████████▋| 97/100 [2:39:04<02:28, 49.35s/it] 98%|█████████▊| 98/100 [2:39:51<01:37, 48.71s/it] 99%|█████████▉| 99/100 [2:40:36<00:47, 47.49s/it]100%|██████████| 100/100 [2:41:43<00:00, 53.33s/it]                                                   Epoch 100: Train acc/f1 = 1.0000 / 1.0000 / 1.0000 / 1.0000 
                Val acc/f1/spec/sens = 0.8840 / 0.8529 / 0.8629 / 0.9439
                Test acc/f1/spec/sens = 0.6393 / 0.6430 / 0.6750 / 0.8095
specificity = 1621/1621
sensitivity = 2879/2879
specificity = 170/197
sensitivity = 286/303
specificity = 54/80
sensitivity = 34/42
Trial 1, Cycle 1
Train acc/f1/spec/sens = 1.0000 / 1.0000 / 1.0000 / 1.0000
Val acc/f1/spec/sens = 0.8840 / 0.8529 / 0.8629 / 0.9439
Test acc/f1/spec/sens = 0.6393 / 0.6430 / 0.6750 / 0.8095
>> Finished.
specificity = 54/80
sensitivity = 34/42
Acc, agreement for latest model:  0.639344262295082 0.680327868852459
Load best checkpoint for thief model
specificity = 44/80
sensitivity = 40/42
Acc, agreement for best model:  0.6229508196721312 0.6885245901639344
Trial 0/1 || Cycle 1/1 || Label set size 4500 || Test acc 0.6230 || Test agreement 0.6885 || Spec 0.5500 || Sens 0.9524
**************************************************************************************************** 

specificity = 44/80
sensitivity = 40/42
Number of samples  4500
0.6885245901639344 0.0
        acc       agr  spec      sens                  label dist
0  0.622951  0.688525  0.55  0.952381  {0: 581, 1: 1040, 2: 2879}
Results saved to  /home/ankita/mnt/data_msa_medical/results_ankita/gbusg_radformer/GBUSV_deit/SGD/5000_val500/random_v2
